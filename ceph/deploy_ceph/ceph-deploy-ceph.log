[2016-07-15 13:48:31,053][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 13:48:31,053][ceph_deploy.cli][INFO  ] Invoked (1.5.34): /usr/bin/ceph-deploy rgw create ceph21
[2016-07-15 13:48:31,053][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 13:48:31,054][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 13:48:31,054][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 13:48:31,054][ceph_deploy.cli][INFO  ]  rgw                           : [('ceph21', 'rgw.ceph21')]
[2016-07-15 13:48:31,054][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 13:48:31,054][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-15 13:48:31,055][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 13:48:31,055][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f1b16fa68c0>
[2016-07-15 13:48:31,055][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 13:48:31,055][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f1b17867668>
[2016-07-15 13:48:31,055][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 13:48:31,055][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 13:48:31,056][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts ceph21:rgw.ceph21
[2016-07-15 13:48:31,056][ceph_deploy][ERROR ] RuntimeError: bootstrap-rgw keyring not found; run 'gatherkeys'

[2016-07-15 13:55:35,499][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 13:55:35,500][ceph_deploy.cli][INFO  ] Invoked (1.5.34): /usr/bin/ceph-deploy purge ceph21
[2016-07-15 13:55:35,500][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 13:55:35,500][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 13:55:35,500][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 13:55:35,500][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 13:55:35,501][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 13:55:35,501][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f922df80cb0>
[2016-07-15 13:55:35,501][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 13:55:35,501][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-15 13:55:35,501][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f922e889140>
[2016-07-15 13:55:35,501][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 13:55:35,501][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 13:55:35,501][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 13:55:35,501][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 13:55:35,502][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph21
[2016-07-15 13:55:35,502][ceph_deploy.install][DEBUG ] Detecting platform for host ceph21 ...
[2016-07-15 13:55:36,175][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 13:55:36,176][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 13:55:36,192][ceph21][DEBUG ] detect machine type
[2016-07-15 13:55:36,196][ceph21][DEBUG ] find the location of an executable
[2016-07-15 13:55:36,198][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 13:55:36,209][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 13:55:36,209][ceph21][INFO  ] Purging Ceph on ceph21
[2016-07-15 13:55:36,210][ceph21][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 13:55:36,229][ceph21][DEBUG ] Reading package lists...
[2016-07-15 13:55:36,543][ceph21][DEBUG ] Building dependency tree...
[2016-07-15 13:55:36,544][ceph21][DEBUG ] Reading state information...
[2016-07-15 13:55:36,658][ceph21][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 13:55:36,658][ceph21][DEBUG ] You might want to run 'apt-get -f install' to correct these:
[2016-07-15 13:55:36,658][ceph21][DEBUG ] The following packages have unmet dependencies:
[2016-07-15 13:55:36,658][ceph21][DEBUG ]  ceph-test : Depends: ceph-common but it is not going to be installed
[2016-07-15 13:55:36,659][ceph21][DEBUG ]  librgw2 : Depends: librados2 (= 10.2.0-1) but 0.94.5-1 is to be installed
[2016-07-15 13:55:36,659][ceph21][DEBUG ]  rest-bench : Depends: ceph-common but it is not going to be installed
[2016-07-15 13:55:36,659][ceph21][WARNING] E: Unmet dependencies. Try 'apt-get -f install' with no packages (or specify a solution).
[2016-07-15 13:55:36,659][ceph21][ERROR ] RuntimeError: command returned non-zero exit status: 100
[2016-07-15 13:55:36,659][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw

[2016-07-15 14:04:41,040][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 14:04:41,041][ceph_deploy.cli][INFO  ] Invoked (1.5.34): /usr/bin/ceph-deploy rgw create ceph21
[2016-07-15 14:04:41,041][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 14:04:41,041][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 14:04:41,041][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 14:04:41,041][ceph_deploy.cli][INFO  ]  rgw                           : [('ceph21', 'rgw.ceph21')]
[2016-07-15 14:04:41,041][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 14:04:41,041][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-15 14:04:41,041][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 14:04:41,041][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa6253078c0>
[2016-07-15 14:04:41,042][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 14:04:41,042][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7fa625bc8668>
[2016-07-15 14:04:41,042][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 14:04:41,042][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 14:04:41,043][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts ceph21:rgw.ceph21
[2016-07-15 14:04:41,043][ceph_deploy][ERROR ] RuntimeError: bootstrap-rgw keyring not found; run 'gatherkeys'

[2016-07-15 14:07:07,316][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 14:07:07,316][ceph_deploy.cli][INFO  ] Invoked (1.5.34): /usr/bin/ceph-deploy rgw create ceph21
[2016-07-15 14:07:07,316][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 14:07:07,316][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 14:07:07,317][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 14:07:07,317][ceph_deploy.cli][INFO  ]  rgw                           : [('ceph21', 'rgw.ceph21')]
[2016-07-15 14:07:07,317][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 14:07:07,317][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-15 14:07:07,317][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 14:07:07,317][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0641d9b8c0>
[2016-07-15 14:07:07,317][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 14:07:07,317][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f064265c668>
[2016-07-15 14:07:07,317][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 14:07:07,317][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 14:07:07,318][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts ceph21:rgw.ceph21
[2016-07-15 14:07:07,318][ceph_deploy][ERROR ] RuntimeError: bootstrap-rgw keyring not found; run 'gatherkeys'

[2016-07-15 14:15:00,022][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 14:15:00,022][ceph_deploy.cli][INFO  ] Invoked (1.5.34): /usr/bin/ceph-deploy mon create-initial
[2016-07-15 14:15:00,023][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 14:15:00,023][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 14:15:00,023][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 14:15:00,023][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 14:15:00,023][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2016-07-15 14:15:00,023][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 14:15:00,023][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f04c2ec04d0>
[2016-07-15 14:15:00,023][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 14:15:00,023][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f04c3321938>
[2016-07-15 14:15:00,023][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 14:15:00,023][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 14:15:00,023][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2016-07-15 14:15:00,025][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts ceph21
[2016-07-15 14:15:00,025][ceph_deploy.mon][DEBUG ] detecting platform for host ceph21 ...
[2016-07-15 14:15:00,722][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:15:00,724][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:15:00,740][ceph21][DEBUG ] detect machine type
[2016-07-15 14:15:00,744][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:15:00,746][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:15:00,757][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:15:00,758][ceph_deploy.mon][INFO  ] distro info: Ubuntu 14.04 trusty
[2016-07-15 14:15:00,758][ceph21][DEBUG ] determining if provided host has same hostname in remote
[2016-07-15 14:15:00,759][ceph21][DEBUG ] get remote short hostname
[2016-07-15 14:15:00,759][ceph21][DEBUG ] deploying mon to ceph21
[2016-07-15 14:15:00,760][ceph21][DEBUG ] get remote short hostname
[2016-07-15 14:15:00,761][ceph21][DEBUG ] remote hostname: ceph21
[2016-07-15 14:15:00,763][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 14:15:00,765][ceph21][DEBUG ] create the mon path if it does not exist
[2016-07-15 14:15:00,766][ceph21][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-15 14:15:00,767][ceph21][DEBUG ] create a done file to avoid re-doing the mon deployment
[2016-07-15 14:15:00,768][ceph21][DEBUG ] create the init path if it does not exist
[2016-07-15 14:15:00,770][ceph21][INFO  ] Running command: initctl emit ceph-mon cluster=ceph id=ceph21
[2016-07-15 14:15:02,785][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 14:15:02,850][ceph21][DEBUG ] ********************************************************************************
[2016-07-15 14:15:02,850][ceph21][DEBUG ] status for monitor: mon.ceph21
[2016-07-15 14:15:02,850][ceph21][DEBUG ] {
[2016-07-15 14:15:02,851][ceph21][DEBUG ]   "election_epoch": 2, 
[2016-07-15 14:15:02,851][ceph21][DEBUG ]   "extra_probe_peers": [], 
[2016-07-15 14:15:02,851][ceph21][DEBUG ]   "monmap": {
[2016-07-15 14:15:02,851][ceph21][DEBUG ]     "created": "0.000000", 
[2016-07-15 14:15:02,851][ceph21][DEBUG ]     "epoch": 1, 
[2016-07-15 14:15:02,851][ceph21][DEBUG ]     "fsid": "6c05988c-d4bd-4081-b0b7-8ead34d54e55", 
[2016-07-15 14:15:02,852][ceph21][DEBUG ]     "modified": "0.000000", 
[2016-07-15 14:15:02,852][ceph21][DEBUG ]     "mons": [
[2016-07-15 14:15:02,852][ceph21][DEBUG ]       {
[2016-07-15 14:15:02,852][ceph21][DEBUG ]         "addr": "10.1.0.44:6789/0", 
[2016-07-15 14:15:02,852][ceph21][DEBUG ]         "name": "ceph21", 
[2016-07-15 14:15:02,852][ceph21][DEBUG ]         "rank": 0
[2016-07-15 14:15:02,852][ceph21][DEBUG ]       }
[2016-07-15 14:15:02,852][ceph21][DEBUG ]     ]
[2016-07-15 14:15:02,852][ceph21][DEBUG ]   }, 
[2016-07-15 14:15:02,853][ceph21][DEBUG ]   "name": "ceph21", 
[2016-07-15 14:15:02,853][ceph21][DEBUG ]   "outside_quorum": [], 
[2016-07-15 14:15:02,853][ceph21][DEBUG ]   "quorum": [
[2016-07-15 14:15:02,853][ceph21][DEBUG ]     0
[2016-07-15 14:15:02,853][ceph21][DEBUG ]   ], 
[2016-07-15 14:15:02,853][ceph21][DEBUG ]   "rank": 0, 
[2016-07-15 14:15:02,854][ceph21][DEBUG ]   "state": "leader", 
[2016-07-15 14:15:02,854][ceph21][DEBUG ]   "sync_provider": []
[2016-07-15 14:15:02,854][ceph21][DEBUG ] }
[2016-07-15 14:15:02,854][ceph21][DEBUG ] ********************************************************************************
[2016-07-15 14:15:02,854][ceph21][INFO  ] monitor: mon.ceph21 is running
[2016-07-15 14:15:02,856][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 14:15:02,921][ceph_deploy.mon][INFO  ] processing monitor mon.ceph21
[2016-07-15 14:15:03,610][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:15:03,611][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:15:03,628][ceph21][DEBUG ] detect machine type
[2016-07-15 14:15:03,632][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:15:03,635][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:15:03,644][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:15:03,646][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 14:15:03,711][ceph_deploy.mon][INFO  ] mon.ceph21 monitor has reached quorum!
[2016-07-15 14:15:03,712][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2016-07-15 14:15:03,712][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2016-07-15 14:15:03,713][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmp8cEb7X
[2016-07-15 14:15:04,373][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:15:04,374][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:15:04,390][ceph21][DEBUG ] detect machine type
[2016-07-15 14:15:04,394][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:15:04,396][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:15:04,405][ceph21][DEBUG ] get remote short hostname
[2016-07-15 14:15:04,405][ceph21][DEBUG ] fetch remote file
[2016-07-15 14:15:04,406][ceph_deploy.gatherkeys][WARNING] No mon key found in host: ceph21
[2016-07-15 14:15:04,406][ceph_deploy.gatherkeys][ERROR ] Failed to connect to host:ceph21
[2016-07-15 14:15:04,406][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmp8cEb7X
[2016-07-15 14:15:04,407][ceph_deploy][ERROR ] RuntimeError: Failed to connect any mon

[2016-07-15 14:15:48,817][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 14:15:48,817][ceph_deploy.cli][INFO  ] Invoked (1.5.34): /usr/bin/ceph-deploy purge ceph21
[2016-07-15 14:15:48,817][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 14:15:48,817][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 14:15:48,817][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 14:15:48,817][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 14:15:48,817][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 14:15:48,818][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe681fbbcb0>
[2016-07-15 14:15:48,818][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 14:15:48,818][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-15 14:15:48,818][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fe6828c4140>
[2016-07-15 14:15:48,818][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 14:15:48,818][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 14:15:48,818][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 14:15:48,818][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 14:15:48,818][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph21
[2016-07-15 14:15:48,818][ceph_deploy.install][DEBUG ] Detecting platform for host ceph21 ...
[2016-07-15 14:15:49,514][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:15:49,514][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:15:49,531][ceph21][DEBUG ] detect machine type
[2016-07-15 14:15:49,536][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:15:49,538][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:15:49,558][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 14:15:49,558][ceph21][INFO  ] Purging Ceph on ceph21
[2016-07-15 14:15:49,560][ceph21][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 14:15:50,078][ceph21][DEBUG ] Reading package lists...
[2016-07-15 14:15:50,392][ceph21][DEBUG ] Building dependency tree...
[2016-07-15 14:15:50,393][ceph21][DEBUG ] Reading state information...
[2016-07-15 14:15:50,507][ceph21][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 14:15:50,507][ceph21][DEBUG ] You might want to run 'apt-get -f install' to correct these:
[2016-07-15 14:15:50,507][ceph21][DEBUG ] The following packages have unmet dependencies:
[2016-07-15 14:15:50,508][ceph21][DEBUG ]  ceph-test : Depends: ceph-common but it is not going to be installed
[2016-07-15 14:15:50,508][ceph21][DEBUG ]  librgw2 : Depends: librados2 (= 10.2.0-1) but 0.94.5-1 is to be installed
[2016-07-15 14:15:50,508][ceph21][DEBUG ]  rest-bench : Depends: ceph-common but it is not going to be installed
[2016-07-15 14:15:50,508][ceph21][WARNING] E: Unmet dependencies. Try 'apt-get -f install' with no packages (or specify a solution).
[2016-07-15 14:15:50,509][ceph21][ERROR ] RuntimeError: command returned non-zero exit status: 100
[2016-07-15 14:15:50,509][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw

[2016-07-15 14:15:59,388][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 14:15:59,388][ceph_deploy.cli][INFO  ] Invoked (1.5.34): /usr/bin/ceph-deploy purgedata ceph21
[2016-07-15 14:15:59,388][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 14:15:59,388][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 14:15:59,388][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 14:15:59,389][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 14:15:59,389][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 14:15:59,389][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9d16452368>
[2016-07-15 14:15:59,389][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 14:15:59,389][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-15 14:15:59,389][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f9d16d521b8>
[2016-07-15 14:15:59,389][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 14:15:59,389][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 14:15:59,389][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph21
[2016-07-15 14:16:00,082][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:16:00,082][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:16:00,099][ceph21][DEBUG ] detect machine type
[2016-07-15 14:16:00,103][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:16:00,106][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:16:00,117][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:16:00,118][ceph_deploy.install][ERROR ] Ceph is still installed on: ['ceph21']
[2016-07-15 14:16:00,118][ceph_deploy][ERROR ] RuntimeError: refusing to purge data while Ceph is still installed

[2016-07-15 14:22:39,864][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 14:22:39,865][ceph_deploy.cli][INFO  ] Invoked (1.5.34): /usr/bin/ceph-deploy purge ceph21
[2016-07-15 14:22:39,865][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 14:22:39,865][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 14:22:39,865][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 14:22:39,866][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 14:22:39,866][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 14:22:39,866][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f906cb72cb0>
[2016-07-15 14:22:39,866][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 14:22:39,866][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-15 14:22:39,866][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f906d47b140>
[2016-07-15 14:22:39,866][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 14:22:39,866][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 14:22:39,867][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 14:22:39,867][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 14:22:39,867][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph21
[2016-07-15 14:22:39,867][ceph_deploy.install][DEBUG ] Detecting platform for host ceph21 ...
[2016-07-15 14:22:40,541][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:22:40,542][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:22:40,559][ceph21][DEBUG ] detect machine type
[2016-07-15 14:22:40,563][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:22:40,566][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:22:40,577][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 14:22:40,577][ceph21][INFO  ] Purging Ceph on ceph21
[2016-07-15 14:22:40,579][ceph21][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 14:22:40,946][ceph21][DEBUG ] Reading package lists...
[2016-07-15 14:22:41,261][ceph21][DEBUG ] Building dependency tree...
[2016-07-15 14:22:41,262][ceph21][DEBUG ] Reading state information...
[2016-07-15 14:22:41,526][ceph21][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 14:22:41,527][ceph21][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 14:22:41,527][ceph21][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 14:22:41,527][ceph21][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 14:22:41,527][ceph21][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 14:22:41,527][ceph21][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-15 14:22:41,527][ceph21][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libnspr4
[2016-07-15 14:22:41,527][ceph21][DEBUG ]   libnss3 libnss3-nssdb libxslt1.1 xmlstarlet
[2016-07-15 14:22:41,527][ceph21][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-15 14:22:41,527][ceph21][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 216 not upgraded.
[2016-07-15 14:22:48,143][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 14:22:48,144][ceph_deploy.cli][INFO  ] Invoked (1.5.34): /usr/bin/ceph-deploy purgedata ceph21
[2016-07-15 14:22:48,144][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 14:22:48,144][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 14:22:48,144][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 14:22:48,144][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 14:22:48,144][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 14:22:48,144][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8d81661368>
[2016-07-15 14:22:48,144][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 14:22:48,145][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-15 14:22:48,145][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f8d81f611b8>
[2016-07-15 14:22:48,145][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 14:22:48,145][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 14:22:48,145][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph21
[2016-07-15 14:22:48,822][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:22:48,823][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:22:48,839][ceph21][DEBUG ] detect machine type
[2016-07-15 14:22:48,843][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:22:48,845][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:22:48,864][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:22:49,527][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:22:49,528][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:22:49,544][ceph21][DEBUG ] detect machine type
[2016-07-15 14:22:49,548][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:22:49,551][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:22:49,559][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 14:22:49,560][ceph21][INFO  ] purging data on ceph21
[2016-07-15 14:22:49,561][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 14:22:49,571][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 14:23:00,258][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 14:23:00,259][ceph_deploy.cli][INFO  ] Invoked (1.5.34): /usr/bin/ceph-deploy purge ceph22 ceph23
[2016-07-15 14:23:00,259][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 14:23:00,259][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 14:23:00,259][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 14:23:00,259][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 14:23:00,260][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 14:23:00,260][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fafa8313cb0>
[2016-07-15 14:23:00,260][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 14:23:00,260][ceph_deploy.cli][INFO  ]  host                          : ['ceph22', 'ceph23']
[2016-07-15 14:23:00,260][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fafa8c1c140>
[2016-07-15 14:23:00,260][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 14:23:00,260][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 14:23:00,260][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 14:23:00,260][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 14:23:00,261][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph22 ceph23
[2016-07-15 14:23:00,261][ceph_deploy.install][DEBUG ] Detecting platform for host ceph22 ...
[2016-07-15 14:23:00,951][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 14:23:00,952][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 14:23:00,969][ceph22][DEBUG ] detect machine type
[2016-07-15 14:23:00,974][ceph22][DEBUG ] find the location of an executable
[2016-07-15 14:23:00,977][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:23:00,996][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 14:23:00,996][ceph22][INFO  ] Purging Ceph on ceph22
[2016-07-15 14:23:00,998][ceph22][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 14:23:01,264][ceph22][DEBUG ] Reading package lists...
[2016-07-15 14:23:01,579][ceph22][DEBUG ] Building dependency tree...
[2016-07-15 14:23:01,579][ceph22][DEBUG ] Reading state information...
[2016-07-15 14:23:01,843][ceph22][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 14:23:01,844][ceph22][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 14:23:01,844][ceph22][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 14:23:01,844][ceph22][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 14:23:01,844][ceph22][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 14:23:01,844][ceph22][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 218 not upgraded.
[2016-07-15 14:23:01,845][ceph_deploy.install][DEBUG ] Detecting platform for host ceph23 ...
[2016-07-15 14:23:02,518][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 14:23:02,519][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 14:23:02,536][ceph23][DEBUG ] detect machine type
[2016-07-15 14:23:02,539][ceph23][DEBUG ] find the location of an executable
[2016-07-15 14:23:02,541][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:23:02,550][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 14:23:02,550][ceph23][INFO  ] Purging Ceph on ceph23
[2016-07-15 14:23:02,552][ceph23][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 14:23:02,570][ceph23][DEBUG ] Reading package lists...
[2016-07-15 14:23:02,885][ceph23][DEBUG ] Building dependency tree...
[2016-07-15 14:23:02,885][ceph23][DEBUG ] Reading state information...
[2016-07-15 14:23:03,099][ceph23][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 14:23:03,100][ceph23][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 14:23:03,100][ceph23][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 14:23:03,100][ceph23][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 14:23:03,100][ceph23][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 14:23:03,101][ceph23][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-15 14:23:03,101][ceph23][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libxslt1.1
[2016-07-15 14:23:03,101][ceph23][DEBUG ]   xmlstarlet
[2016-07-15 14:23:03,101][ceph23][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-15 14:23:03,165][ceph23][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 218 not upgraded.
[2016-07-15 14:23:07,790][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 14:23:07,790][ceph_deploy.cli][INFO  ] Invoked (1.5.34): /usr/bin/ceph-deploy purgedata ceph22 ceph23
[2016-07-15 14:23:07,790][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 14:23:07,791][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 14:23:07,791][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 14:23:07,791][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 14:23:07,791][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 14:23:07,791][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f532ff1f368>
[2016-07-15 14:23:07,791][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 14:23:07,791][ceph_deploy.cli][INFO  ]  host                          : ['ceph22', 'ceph23']
[2016-07-15 14:23:07,791][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f533081f1b8>
[2016-07-15 14:23:07,791][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 14:23:07,791][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 14:23:07,791][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph22 ceph23
[2016-07-15 14:23:08,487][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 14:23:08,488][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 14:23:08,506][ceph22][DEBUG ] detect machine type
[2016-07-15 14:23:08,510][ceph22][DEBUG ] find the location of an executable
[2016-07-15 14:23:08,512][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:23:08,531][ceph22][DEBUG ] find the location of an executable
[2016-07-15 14:23:09,205][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 14:23:09,206][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 14:23:09,223][ceph23][DEBUG ] detect machine type
[2016-07-15 14:23:09,227][ceph23][DEBUG ] find the location of an executable
[2016-07-15 14:23:09,229][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:23:09,247][ceph23][DEBUG ] find the location of an executable
[2016-07-15 14:23:09,935][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 14:23:09,935][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 14:23:09,951][ceph22][DEBUG ] detect machine type
[2016-07-15 14:23:09,955][ceph22][DEBUG ] find the location of an executable
[2016-07-15 14:23:09,958][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:23:09,966][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 14:23:09,967][ceph22][INFO  ] purging data on ceph22
[2016-07-15 14:23:09,968][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 14:23:09,977][ceph22][WARNING] OSDs may still be mounted, trying to unmount them
[2016-07-15 14:23:09,979][ceph22][INFO  ] Running command: find /var/lib/ceph -mindepth 1 -maxdepth 2 -type d -exec umount {} ;
[2016-07-15 14:23:09,990][ceph22][WARNING] umount: /var/lib/ceph/osd: not mounted
[2016-07-15 14:23:10,055][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 14:23:10,067][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 14:23:10,785][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 14:23:10,786][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 14:23:10,803][ceph23][DEBUG ] detect machine type
[2016-07-15 14:23:10,806][ceph23][DEBUG ] find the location of an executable
[2016-07-15 14:23:10,808][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:23:10,817][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 14:23:10,817][ceph23][INFO  ] purging data on ceph23
[2016-07-15 14:23:10,818][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 14:23:10,828][ceph23][WARNING] OSDs may still be mounted, trying to unmount them
[2016-07-15 14:23:10,829][ceph23][INFO  ] Running command: find /var/lib/ceph -mindepth 1 -maxdepth 2 -type d -exec umount {} ;
[2016-07-15 14:23:10,848][ceph23][WARNING] umount: /var/lib/ceph/osd: not mounted
[2016-07-15 14:23:10,913][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 14:23:10,925][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 14:25:57,030][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 14:25:57,031][ceph_deploy.cli][INFO  ] Invoked (1.5.34): /usr/bin/ceph-deploy new ceph21
[2016-07-15 14:25:57,031][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 14:25:57,031][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 14:25:57,031][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f68caf79398>
[2016-07-15 14:25:57,031][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 14:25:57,032][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 14:25:57,032][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 14:25:57,032][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f68cab1b1b8>
[2016-07-15 14:25:57,032][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 14:25:57,032][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2016-07-15 14:25:57,032][ceph_deploy.cli][INFO  ]  mon                           : ['ceph21']
[2016-07-15 14:25:57,032][ceph_deploy.cli][INFO  ]  public_network                : None
[2016-07-15 14:25:57,032][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 14:25:57,032][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2016-07-15 14:25:57,033][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 14:25:57,033][ceph_deploy.cli][INFO  ]  fsid                          : None
[2016-07-15 14:25:57,033][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2016-07-15 14:25:57,033][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2016-07-15 14:25:57,061][ceph21][DEBUG ] connected to host: cephAdmin 
[2016-07-15 14:25:57,066][ceph21][INFO  ] Running command: ssh -CT -o BatchMode=yes ceph21
[2016-07-15 14:25:58,133][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:25:58,134][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:25:58,151][ceph21][DEBUG ] detect machine type
[2016-07-15 14:25:58,155][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:25:58,157][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:25:58,174][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:25:58,177][ceph21][INFO  ] Running command: /bin/ip link show
[2016-07-15 14:25:58,187][ceph21][INFO  ] Running command: /bin/ip addr show
[2016-07-15 14:25:58,197][ceph21][DEBUG ] IP addresses found: ['10.1.0.44']
[2016-07-15 14:25:58,197][ceph_deploy.new][DEBUG ] Resolving host ceph21
[2016-07-15 14:25:58,197][ceph_deploy.new][DEBUG ] Monitor ceph21 at 10.1.0.44
[2016-07-15 14:25:58,198][ceph_deploy.new][DEBUG ] Monitor initial members are ['ceph21']
[2016-07-15 14:25:58,198][ceph_deploy.new][DEBUG ] Monitor addrs are ['10.1.0.44']
[2016-07-15 14:25:58,198][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2016-07-15 14:25:58,198][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2016-07-15 14:25:58,198][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2016-07-15 14:27:29,399][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 14:27:29,400][ceph_deploy.cli][INFO  ] Invoked (1.5.34): /usr/bin/ceph-deploy mon create-initial
[2016-07-15 14:27:29,400][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 14:27:29,400][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 14:27:29,400][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 14:27:29,400][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 14:27:29,400][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2016-07-15 14:27:29,400][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 14:27:29,400][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6e74f334d0>
[2016-07-15 14:27:29,400][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 14:27:29,400][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f6e75394938>
[2016-07-15 14:27:29,401][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 14:27:29,401][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 14:27:29,401][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2016-07-15 14:27:29,403][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts ceph21
[2016-07-15 14:27:29,403][ceph_deploy.mon][DEBUG ] detecting platform for host ceph21 ...
[2016-07-15 14:27:30,110][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:27:30,112][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:27:30,128][ceph21][DEBUG ] detect machine type
[2016-07-15 14:27:30,132][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:27:30,135][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:27:30,155][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:27:30,156][ceph_deploy.mon][INFO  ] distro info: Ubuntu 14.04 trusty
[2016-07-15 14:27:30,156][ceph21][DEBUG ] determining if provided host has same hostname in remote
[2016-07-15 14:27:30,156][ceph21][DEBUG ] get remote short hostname
[2016-07-15 14:27:30,157][ceph21][DEBUG ] deploying mon to ceph21
[2016-07-15 14:27:30,157][ceph21][DEBUG ] get remote short hostname
[2016-07-15 14:27:30,158][ceph21][DEBUG ] remote hostname: ceph21
[2016-07-15 14:27:30,161][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 14:27:30,163][ceph21][DEBUG ] create the mon path if it does not exist
[2016-07-15 14:27:30,164][ceph21][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-15 14:27:30,164][ceph21][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-15 14:27:30,165][ceph21][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 14:27:30,165][ceph21][DEBUG ] create the monitor keyring file
[2016-07-15 14:27:30,168][ceph21][INFO  ] Running command: ceph-mon --cluster ceph --mkfs -i ceph21 --keyring /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 14:27:30,203][ceph21][DEBUG ] ceph-mon: mon.noname-a 10.1.0.44:6789/0 is local, renaming to mon.ceph21
[2016-07-15 14:27:30,203][ceph21][DEBUG ] ceph-mon: set fsid to cfac042c-3d50-4384-a648-f2d07466b1a3
[2016-07-15 14:27:30,204][ceph21][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-ceph21 for mon.ceph21
[2016-07-15 14:27:30,204][ceph21][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 14:27:30,213][ceph21][DEBUG ] create a done file to avoid re-doing the mon deployment
[2016-07-15 14:27:30,215][ceph21][DEBUG ] create the init path if it does not exist
[2016-07-15 14:27:30,217][ceph21][INFO  ] Running command: initctl emit ceph-mon cluster=ceph id=ceph21
[2016-07-15 14:27:32,240][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 14:27:32,305][ceph21][DEBUG ] ********************************************************************************
[2016-07-15 14:27:32,306][ceph21][DEBUG ] status for monitor: mon.ceph21
[2016-07-15 14:27:32,306][ceph21][DEBUG ] {
[2016-07-15 14:27:32,306][ceph21][DEBUG ]   "election_epoch": 2, 
[2016-07-15 14:27:32,306][ceph21][DEBUG ]   "extra_probe_peers": [], 
[2016-07-15 14:27:32,306][ceph21][DEBUG ]   "monmap": {
[2016-07-15 14:27:32,306][ceph21][DEBUG ]     "created": "0.000000", 
[2016-07-15 14:27:32,306][ceph21][DEBUG ]     "epoch": 1, 
[2016-07-15 14:27:32,306][ceph21][DEBUG ]     "fsid": "cfac042c-3d50-4384-a648-f2d07466b1a3", 
[2016-07-15 14:27:32,306][ceph21][DEBUG ]     "modified": "0.000000", 
[2016-07-15 14:27:32,306][ceph21][DEBUG ]     "mons": [
[2016-07-15 14:27:32,307][ceph21][DEBUG ]       {
[2016-07-15 14:27:32,307][ceph21][DEBUG ]         "addr": "10.1.0.44:6789/0", 
[2016-07-15 14:27:32,307][ceph21][DEBUG ]         "name": "ceph21", 
[2016-07-15 14:27:32,307][ceph21][DEBUG ]         "rank": 0
[2016-07-15 14:27:32,307][ceph21][DEBUG ]       }
[2016-07-15 14:27:32,307][ceph21][DEBUG ]     ]
[2016-07-15 14:27:32,307][ceph21][DEBUG ]   }, 
[2016-07-15 14:27:32,307][ceph21][DEBUG ]   "name": "ceph21", 
[2016-07-15 14:27:32,307][ceph21][DEBUG ]   "outside_quorum": [], 
[2016-07-15 14:27:32,307][ceph21][DEBUG ]   "quorum": [
[2016-07-15 14:27:32,307][ceph21][DEBUG ]     0
[2016-07-15 14:27:32,307][ceph21][DEBUG ]   ], 
[2016-07-15 14:27:32,307][ceph21][DEBUG ]   "rank": 0, 
[2016-07-15 14:27:32,308][ceph21][DEBUG ]   "state": "leader", 
[2016-07-15 14:27:32,308][ceph21][DEBUG ]   "sync_provider": []
[2016-07-15 14:27:32,308][ceph21][DEBUG ] }
[2016-07-15 14:27:32,308][ceph21][DEBUG ] ********************************************************************************
[2016-07-15 14:27:32,308][ceph21][INFO  ] monitor: mon.ceph21 is running
[2016-07-15 14:27:32,310][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 14:27:32,384][ceph_deploy.mon][INFO  ] processing monitor mon.ceph21
[2016-07-15 14:27:33,065][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:27:33,066][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:27:33,082][ceph21][DEBUG ] detect machine type
[2016-07-15 14:27:33,086][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:27:33,089][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:27:33,106][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:27:33,109][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 14:27:33,174][ceph_deploy.mon][INFO  ] mon.ceph21 monitor has reached quorum!
[2016-07-15 14:27:33,175][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2016-07-15 14:27:33,175][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2016-07-15 14:27:33,175][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpvvP77g
[2016-07-15 14:27:33,861][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:27:33,862][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:27:33,879][ceph21][DEBUG ] detect machine type
[2016-07-15 14:27:33,883][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:27:33,886][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:27:33,904][ceph21][DEBUG ] get remote short hostname
[2016-07-15 14:27:33,905][ceph21][DEBUG ] fetch remote file
[2016-07-15 14:27:33,906][ceph_deploy.gatherkeys][WARNING] No mon key found in host: ceph21
[2016-07-15 14:27:33,906][ceph_deploy.gatherkeys][ERROR ] Failed to connect to host:ceph21
[2016-07-15 14:27:33,906][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpvvP77g
[2016-07-15 14:27:33,907][ceph_deploy][ERROR ] RuntimeError: Failed to connect any mon

[2016-07-15 14:42:25,959][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 14:42:26,052][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy mon create-initial
[2016-07-15 14:42:26,052][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 14:42:26,052][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 14:42:26,052][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 14:42:26,052][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 14:42:26,053][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2016-07-15 14:42:26,053][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 14:42:26,053][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9392579290>
[2016-07-15 14:42:26,053][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 14:42:26,053][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f939255a6e0>
[2016-07-15 14:42:26,053][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 14:42:26,054][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 14:42:26,054][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2016-07-15 14:42:26,056][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts ceph21
[2016-07-15 14:42:26,056][ceph_deploy.mon][DEBUG ] detecting platform for host ceph21 ...
[2016-07-15 14:42:26,759][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:42:26,760][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:42:26,777][ceph21][DEBUG ] detect machine type
[2016-07-15 14:42:26,780][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:42:26,783][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:42:26,794][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:42:26,795][ceph_deploy.mon][INFO  ] distro info: Ubuntu 14.04 trusty
[2016-07-15 14:42:26,795][ceph21][DEBUG ] determining if provided host has same hostname in remote
[2016-07-15 14:42:26,796][ceph21][DEBUG ] get remote short hostname
[2016-07-15 14:42:26,796][ceph21][DEBUG ] deploying mon to ceph21
[2016-07-15 14:42:26,797][ceph21][DEBUG ] get remote short hostname
[2016-07-15 14:42:26,798][ceph21][DEBUG ] remote hostname: ceph21
[2016-07-15 14:42:26,800][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 14:42:26,803][ceph_deploy.mon][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2016-07-15 14:42:26,803][ceph_deploy][ERROR ] GenericError: Failed to create 1 monitors

[2016-07-15 14:44:05,458][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 14:44:05,459][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph21 ceph22 ceph23
[2016-07-15 14:44:05,459][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 14:44:05,459][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 14:44:05,459][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 14:44:05,459][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 14:44:05,459][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 14:44:05,459][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8b6021bb00>
[2016-07-15 14:44:05,459][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 14:44:05,459][ceph_deploy.cli][INFO  ]  host                          : ['ceph21', 'ceph22', 'ceph23']
[2016-07-15 14:44:05,459][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f8b60b331b8>
[2016-07-15 14:44:05,460][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 14:44:05,460][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 14:44:05,460][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 14:44:05,460][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 14:44:05,460][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph21 ceph22 ceph23
[2016-07-15 14:44:05,460][ceph_deploy.install][DEBUG ] Detecting platform for host ceph21 ...
[2016-07-15 14:44:06,141][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:44:06,142][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:44:06,158][ceph21][DEBUG ] detect machine type
[2016-07-15 14:44:06,162][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:44:06,164][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:44:06,175][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 14:44:06,176][ceph21][INFO  ] Purging Ceph on ceph21
[2016-07-15 14:44:06,177][ceph21][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 14:44:06,545][ceph21][DEBUG ] Reading package lists...
[2016-07-15 14:44:06,860][ceph21][DEBUG ] Building dependency tree...
[2016-07-15 14:44:06,860][ceph21][DEBUG ] Reading state information...
[2016-07-15 14:44:07,024][ceph21][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 14:44:07,025][ceph21][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-15 14:44:07,025][ceph21][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libnspr4
[2016-07-15 14:44:07,025][ceph21][DEBUG ]   libnss3 libnss3-nssdb libxslt1.1 xmlstarlet
[2016-07-15 14:44:07,025][ceph21][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-15 14:44:07,089][ceph21][DEBUG ] The following packages will be REMOVED:
[2016-07-15 14:44:07,089][ceph21][DEBUG ]   ceph* ceph-common* ceph-mds* ceph-test* radosgw* rest-bench*
[2016-07-15 14:44:07,253][ceph21][DEBUG ] 0 upgraded, 0 newly installed, 6 to remove and 227 not upgraded.
[2016-07-15 14:44:07,254][ceph21][DEBUG ] After this operation, 304 MB disk space will be freed.
[2016-07-15 14:44:07,254][ceph21][DEBUG ] (Reading database ... 71882 files and directories currently installed.)
[2016-07-15 14:44:07,255][ceph21][DEBUG ] Removing ceph-mds (0.94.5-1) ...
[2016-07-15 14:44:07,271][ceph21][DEBUG ] ceph-mds-all stop/waiting
[2016-07-15 14:44:07,303][ceph21][DEBUG ] /etc/init.d/ceph: ceph conf /etc/ceph/ceph.conf not found; system is not configured.
[2016-07-15 14:44:07,318][ceph21][DEBUG ] Purging configuration files for ceph-mds (0.94.5-1) ...
[2016-07-15 14:44:07,382][ceph21][DEBUG ] Removing ceph (0.94.5-1) ...
[2016-07-15 14:44:07,383][ceph21][DEBUG ] ceph-all stop/waiting
[2016-07-15 14:44:07,398][ceph21][DEBUG ] /etc/init.d/ceph: ceph conf /etc/ceph/ceph.conf not found; system is not configured.
[2016-07-15 14:44:07,512][ceph21][DEBUG ] Purging configuration files for ceph (0.94.5-1) ...
[2016-07-15 14:44:07,512][ceph21][WARNING] dpkg: warning: while removing ceph, directory '/var/lib/ceph/bootstrap-mds' not empty so not removed
[2016-07-15 14:44:07,513][ceph21][WARNING] dpkg: warning: while removing ceph, directory '/var/lib/ceph/bootstrap-osd' not empty so not removed
[2016-07-15 14:44:07,513][ceph21][WARNING] dpkg: warning: while removing ceph, directory '/var/lib/ceph/mon' not empty so not removed
[2016-07-15 14:44:07,528][ceph21][DEBUG ] Removing ceph-test (0.94.5-1) ...
[2016-07-15 14:44:07,642][ceph21][DEBUG ] Removing radosgw (0.94.5-1) ...
[2016-07-15 14:44:07,643][ceph21][WARNING] stop: Unknown instance: 
[2016-07-15 14:44:07,658][ceph21][DEBUG ] Purging configuration files for radosgw (0.94.5-1) ...
[2016-07-15 14:44:07,690][ceph21][WARNING] dpkg: warning: while removing radosgw, directory '/var/lib/ceph' not empty so not removed
[2016-07-15 14:44:07,706][ceph21][DEBUG ] Removing rest-bench (0.94.5-1) ...
[2016-07-15 14:44:07,770][ceph21][DEBUG ] Removing ceph-common (0.94.5-1) ...
[2016-07-15 14:44:07,834][ceph21][DEBUG ] Purging configuration files for ceph-common (0.94.5-1) ...
[2016-07-15 14:44:07,841][ceph21][DEBUG ] Processing triggers for man-db (2.6.7.1-1) ...
[2016-07-15 14:44:08,106][ceph21][DEBUG ] Processing triggers for libc-bin (2.19-0ubuntu6) ...
[2016-07-15 14:44:08,571][ceph_deploy.install][DEBUG ] Detecting platform for host ceph22 ...
[2016-07-15 14:44:09,244][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 14:44:09,245][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 14:44:09,260][ceph22][DEBUG ] detect machine type
[2016-07-15 14:44:09,264][ceph22][DEBUG ] find the location of an executable
[2016-07-15 14:44:09,266][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:44:09,275][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 14:44:09,275][ceph22][INFO  ] Purging Ceph on ceph22
[2016-07-15 14:44:09,276][ceph22][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 14:44:09,744][ceph22][DEBUG ] Reading package lists...
[2016-07-15 14:44:10,058][ceph22][DEBUG ] Building dependency tree...
[2016-07-15 14:44:10,059][ceph22][DEBUG ] Reading state information...
[2016-07-15 14:44:10,423][ceph22][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 14:44:10,423][ceph22][DEBUG ] The following packages will be REMOVED:
[2016-07-15 14:44:10,423][ceph22][DEBUG ]   ceph* ceph-common* ceph-mds* ceph-test* radosgw* rest-bench*
[2016-07-15 14:44:10,587][ceph22][DEBUG ] 0 upgraded, 0 newly installed, 6 to remove and 218 not upgraded.
[2016-07-15 14:44:10,588][ceph22][DEBUG ] After this operation, 304 MB disk space will be freed.
[2016-07-15 14:44:10,589][ceph22][DEBUG ] (Reading database ... 71874 files and directories currently installed.)
[2016-07-15 14:44:10,596][ceph22][DEBUG ] Removing ceph-mds (0.94.5-1) ...
[2016-07-15 14:44:10,612][ceph22][DEBUG ] ceph-mds-all stop/waiting
[2016-07-15 14:44:10,644][ceph22][DEBUG ] /etc/init.d/ceph: ceph conf /etc/ceph/ceph.conf not found; system is not configured.
[2016-07-15 14:44:10,644][ceph22][DEBUG ] Purging configuration files for ceph-mds (0.94.5-1) ...
[2016-07-15 14:44:10,676][ceph22][DEBUG ] Removing ceph (0.94.5-1) ...
[2016-07-15 14:44:10,707][ceph22][DEBUG ] ceph-all stop/waiting
[2016-07-15 14:44:10,723][ceph22][DEBUG ] /etc/init.d/ceph: ceph conf /etc/ceph/ceph.conf not found; system is not configured.
[2016-07-15 14:44:10,837][ceph22][DEBUG ] Purging configuration files for ceph (0.94.5-1) ...
[2016-07-15 14:44:10,838][ceph22][WARNING] dpkg: warning: while removing ceph, directory '/var/lib/ceph/tmp' not empty so not removed
[2016-07-15 14:44:10,853][ceph22][DEBUG ] Removing ceph-test (0.94.5-1) ...
[2016-07-15 14:44:10,917][ceph22][DEBUG ] Removing radosgw (0.94.5-1) ...
[2016-07-15 14:44:10,917][ceph22][WARNING] stop: Unknown instance: 
[2016-07-15 14:44:10,981][ceph22][DEBUG ] Purging configuration files for radosgw (0.94.5-1) ...
[2016-07-15 14:44:10,981][ceph22][WARNING] dpkg: warning: while removing radosgw, directory '/var/lib/ceph' not empty so not removed
[2016-07-15 14:44:10,997][ceph22][DEBUG ] Removing rest-bench (0.94.5-1) ...
[2016-07-15 14:44:11,029][ceph22][DEBUG ] Removing ceph-common (0.94.5-1) ...
[2016-07-15 14:44:11,143][ceph22][DEBUG ] Purging configuration files for ceph-common (0.94.5-1) ...
[2016-07-15 14:44:11,143][ceph22][DEBUG ] Processing triggers for man-db (2.6.7.1-1) ...
[2016-07-15 14:44:11,357][ceph22][DEBUG ] Processing triggers for libc-bin (2.19-0ubuntu6) ...
[2016-07-15 14:44:11,723][ceph_deploy.install][DEBUG ] Detecting platform for host ceph23 ...
[2016-07-15 14:44:12,429][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 14:44:12,429][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 14:44:12,450][ceph23][DEBUG ] detect machine type
[2016-07-15 14:44:12,454][ceph23][DEBUG ] find the location of an executable
[2016-07-15 14:44:12,457][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:44:12,466][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 14:44:12,466][ceph23][INFO  ] Purging Ceph on ceph23
[2016-07-15 14:44:12,467][ceph23][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 14:44:12,835][ceph23][DEBUG ] Reading package lists...
[2016-07-15 14:44:13,149][ceph23][DEBUG ] Building dependency tree...
[2016-07-15 14:44:13,149][ceph23][DEBUG ] Reading state information...
[2016-07-15 14:44:13,416][ceph23][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 14:44:13,416][ceph23][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-15 14:44:13,417][ceph23][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libxslt1.1
[2016-07-15 14:44:13,417][ceph23][DEBUG ]   xmlstarlet
[2016-07-15 14:44:13,417][ceph23][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-15 14:44:13,581][ceph23][DEBUG ] The following packages will be REMOVED:
[2016-07-15 14:44:13,581][ceph23][DEBUG ]   ceph* ceph-common* ceph-mds* ceph-test* radosgw* rest-bench*
[2016-07-15 14:44:13,695][ceph23][DEBUG ] 0 upgraded, 0 newly installed, 6 to remove and 229 not upgraded.
[2016-07-15 14:44:13,696][ceph23][DEBUG ] After this operation, 304 MB disk space will be freed.
[2016-07-15 14:44:13,727][ceph23][DEBUG ] (Reading database ... 71874 files and directories currently installed.)
[2016-07-15 14:44:13,727][ceph23][DEBUG ] Removing ceph-mds (0.94.5-1) ...
[2016-07-15 14:44:13,735][ceph23][DEBUG ] ceph-mds-all stop/waiting
[2016-07-15 14:44:13,766][ceph23][DEBUG ] /etc/init.d/ceph: ceph conf /etc/ceph/ceph.conf not found; system is not configured.
[2016-07-15 14:44:13,782][ceph23][DEBUG ] Purging configuration files for ceph-mds (0.94.5-1) ...
[2016-07-15 14:44:13,847][ceph23][DEBUG ] Removing ceph (0.94.5-1) ...
[2016-07-15 14:44:13,850][ceph23][DEBUG ] ceph-all stop/waiting
[2016-07-15 14:44:13,882][ceph23][DEBUG ] /etc/init.d/ceph: ceph conf /etc/ceph/ceph.conf not found; system is not configured.
[2016-07-15 14:44:13,996][ceph23][DEBUG ] Purging configuration files for ceph (0.94.5-1) ...
[2016-07-15 14:44:13,996][ceph23][WARNING] dpkg: warning: while removing ceph, directory '/var/lib/ceph/tmp' not empty so not removed
[2016-07-15 14:44:14,012][ceph23][DEBUG ] Removing ceph-test (0.94.5-1) ...
[2016-07-15 14:44:14,126][ceph23][DEBUG ] Removing radosgw (0.94.5-1) ...
[2016-07-15 14:44:14,126][ceph23][WARNING] stop: Unknown instance: 
[2016-07-15 14:44:14,158][ceph23][DEBUG ] Purging configuration files for radosgw (0.94.5-1) ...
[2016-07-15 14:44:14,190][ceph23][WARNING] dpkg: warning: while removing radosgw, directory '/var/lib/ceph' not empty so not removed
[2016-07-15 14:44:14,205][ceph23][DEBUG ] Removing rest-bench (0.94.5-1) ...
[2016-07-15 14:44:14,269][ceph23][DEBUG ] Removing ceph-common (0.94.5-1) ...
[2016-07-15 14:44:14,333][ceph23][DEBUG ] Purging configuration files for ceph-common (0.94.5-1) ...
[2016-07-15 14:44:14,350][ceph23][DEBUG ] Processing triggers for man-db (2.6.7.1-1) ...
[2016-07-15 14:44:14,614][ceph23][DEBUG ] Processing triggers for libc-bin (2.19-0ubuntu6) ...
[2016-07-15 14:44:26,025][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 14:44:26,025][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph21 ceph22 ceph23
[2016-07-15 14:44:26,025][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 14:44:26,025][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 14:44:26,025][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 14:44:26,025][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 14:44:26,026][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 14:44:26,026][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fef6c0401b8>
[2016-07-15 14:44:26,026][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 14:44:26,026][ceph_deploy.cli][INFO  ]  host                          : ['ceph21', 'ceph22', 'ceph23']
[2016-07-15 14:44:26,026][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7fef6c950230>
[2016-07-15 14:44:26,026][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 14:44:26,026][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 14:44:26,026][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph21 ceph22 ceph23
[2016-07-15 14:44:26,687][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:44:26,688][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:44:26,704][ceph21][DEBUG ] detect machine type
[2016-07-15 14:44:26,708][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:44:26,710][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:44:26,721][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:44:27,391][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 14:44:27,392][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 14:44:27,408][ceph22][DEBUG ] detect machine type
[2016-07-15 14:44:27,412][ceph22][DEBUG ] find the location of an executable
[2016-07-15 14:44:27,415][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:44:27,423][ceph22][DEBUG ] find the location of an executable
[2016-07-15 14:44:28,134][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 14:44:28,135][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 14:44:28,152][ceph23][DEBUG ] detect machine type
[2016-07-15 14:44:28,156][ceph23][DEBUG ] find the location of an executable
[2016-07-15 14:44:28,158][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:44:28,168][ceph23][DEBUG ] find the location of an executable
[2016-07-15 14:44:28,842][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:44:28,843][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:44:28,859][ceph21][DEBUG ] detect machine type
[2016-07-15 14:44:28,864][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:44:28,866][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:44:28,875][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 14:44:28,875][ceph21][INFO  ] purging data on ceph21
[2016-07-15 14:44:28,877][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 14:44:28,888][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 14:44:29,605][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 14:44:29,606][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 14:44:29,623][ceph22][DEBUG ] detect machine type
[2016-07-15 14:44:29,627][ceph22][DEBUG ] find the location of an executable
[2016-07-15 14:44:29,629][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:44:29,638][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 14:44:29,638][ceph22][INFO  ] purging data on ceph22
[2016-07-15 14:44:29,640][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 14:44:29,650][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 14:44:30,349][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 14:44:30,350][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 14:44:30,368][ceph23][DEBUG ] detect machine type
[2016-07-15 14:44:30,372][ceph23][DEBUG ] find the location of an executable
[2016-07-15 14:44:30,374][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:44:30,383][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 14:44:30,383][ceph23][INFO  ] purging data on ceph23
[2016-07-15 14:44:30,384][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 14:44:30,395][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 14:45:52,792][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 14:45:52,792][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy new ceph21
[2016-07-15 14:45:52,793][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 14:45:52,793][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 14:45:52,793][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f6d574c0410>
[2016-07-15 14:45:52,793][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 14:45:52,793][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 14:45:52,793][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 14:45:52,793][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6d56c22ef0>
[2016-07-15 14:45:52,793][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 14:45:52,793][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2016-07-15 14:45:52,793][ceph_deploy.cli][INFO  ]  mon                           : ['ceph21']
[2016-07-15 14:45:52,793][ceph_deploy.cli][INFO  ]  public_network                : None
[2016-07-15 14:45:52,793][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 14:45:52,794][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2016-07-15 14:45:52,794][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 14:45:52,794][ceph_deploy.cli][INFO  ]  fsid                          : None
[2016-07-15 14:45:52,794][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2016-07-15 14:45:52,794][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2016-07-15 14:45:52,822][ceph21][DEBUG ] connected to host: cephAdmin 
[2016-07-15 14:45:52,827][ceph21][INFO  ] Running command: ssh -CT -o BatchMode=yes ceph21
[2016-07-15 14:45:53,806][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:45:53,807][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:45:53,824][ceph21][DEBUG ] detect machine type
[2016-07-15 14:45:53,828][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:45:53,831][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:45:53,848][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:45:53,851][ceph21][INFO  ] Running command: /bin/ip link show
[2016-07-15 14:45:53,862][ceph21][INFO  ] Running command: /bin/ip addr show
[2016-07-15 14:45:53,871][ceph21][DEBUG ] IP addresses found: ['10.1.0.44']
[2016-07-15 14:45:53,872][ceph_deploy.new][DEBUG ] Resolving host ceph21
[2016-07-15 14:45:53,872][ceph_deploy.new][DEBUG ] Monitor ceph21 at 10.1.0.44
[2016-07-15 14:45:53,872][ceph_deploy.new][DEBUG ] Monitor initial members are ['ceph21']
[2016-07-15 14:45:53,873][ceph_deploy.new][DEBUG ] Monitor addrs are ['10.1.0.44']
[2016-07-15 14:45:53,873][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2016-07-15 14:45:53,873][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2016-07-15 14:45:53,873][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2016-07-15 14:47:04,276][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 14:47:04,276][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy mon create-initial
[2016-07-15 14:47:04,276][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 14:47:04,277][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 14:47:04,277][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 14:47:04,277][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 14:47:04,277][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2016-07-15 14:47:04,277][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 14:47:04,277][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f03c1969290>
[2016-07-15 14:47:04,277][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 14:47:04,277][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f03c194a6e0>
[2016-07-15 14:47:04,277][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 14:47:04,277][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 14:47:04,277][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2016-07-15 14:47:04,279][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts ceph21
[2016-07-15 14:47:04,279][ceph_deploy.mon][DEBUG ] detecting platform for host ceph21 ...
[2016-07-15 14:47:04,956][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:47:04,957][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:47:04,973][ceph21][DEBUG ] detect machine type
[2016-07-15 14:47:04,977][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:47:04,979][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:47:04,990][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:47:04,991][ceph_deploy.mon][INFO  ] distro info: Ubuntu 14.04 trusty
[2016-07-15 14:47:04,991][ceph21][DEBUG ] determining if provided host has same hostname in remote
[2016-07-15 14:47:04,991][ceph21][DEBUG ] get remote short hostname
[2016-07-15 14:47:04,992][ceph21][DEBUG ] deploying mon to ceph21
[2016-07-15 14:47:04,992][ceph21][DEBUG ] get remote short hostname
[2016-07-15 14:47:04,993][ceph21][DEBUG ] remote hostname: ceph21
[2016-07-15 14:47:04,996][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 14:47:04,998][ceph21][DEBUG ] create the mon path if it does not exist
[2016-07-15 14:47:04,998][ceph21][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-15 14:47:04,999][ceph21][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-15 14:47:05,000][ceph21][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 14:47:05,000][ceph21][DEBUG ] create the monitor keyring file
[2016-07-15 14:47:05,002][ceph21][INFO  ] Running command: ceph-mon --cluster ceph --mkfs -i ceph21 --keyring /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 14:47:05,037][ceph21][DEBUG ] ceph-mon: mon.noname-a 10.1.0.44:6789/0 is local, renaming to mon.ceph21
[2016-07-15 14:47:05,037][ceph21][DEBUG ] ceph-mon: set fsid to 88150661-5905-4732-bf0d-c59f3bc778e6
[2016-07-15 14:47:05,038][ceph21][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-ceph21 for mon.ceph21
[2016-07-15 14:47:05,038][ceph21][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 14:47:05,039][ceph21][DEBUG ] create a done file to avoid re-doing the mon deployment
[2016-07-15 14:47:05,040][ceph21][DEBUG ] create the init path if it does not exist
[2016-07-15 14:47:05,042][ceph21][INFO  ] Running command: initctl emit ceph-mon cluster=ceph id=ceph21
[2016-07-15 14:47:07,065][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 14:47:07,130][ceph21][DEBUG ] ********************************************************************************
[2016-07-15 14:47:07,130][ceph21][DEBUG ] status for monitor: mon.ceph21
[2016-07-15 14:47:07,131][ceph21][DEBUG ] {
[2016-07-15 14:47:07,131][ceph21][DEBUG ]   "election_epoch": 2, 
[2016-07-15 14:47:07,131][ceph21][DEBUG ]   "extra_probe_peers": [], 
[2016-07-15 14:47:07,131][ceph21][DEBUG ]   "monmap": {
[2016-07-15 14:47:07,131][ceph21][DEBUG ]     "created": "0.000000", 
[2016-07-15 14:47:07,131][ceph21][DEBUG ]     "epoch": 1, 
[2016-07-15 14:47:07,131][ceph21][DEBUG ]     "fsid": "88150661-5905-4732-bf0d-c59f3bc778e6", 
[2016-07-15 14:47:07,131][ceph21][DEBUG ]     "modified": "0.000000", 
[2016-07-15 14:47:07,131][ceph21][DEBUG ]     "mons": [
[2016-07-15 14:47:07,131][ceph21][DEBUG ]       {
[2016-07-15 14:47:07,131][ceph21][DEBUG ]         "addr": "10.1.0.44:6789/0", 
[2016-07-15 14:47:07,131][ceph21][DEBUG ]         "name": "ceph21", 
[2016-07-15 14:47:07,132][ceph21][DEBUG ]         "rank": 0
[2016-07-15 14:47:07,132][ceph21][DEBUG ]       }
[2016-07-15 14:47:07,132][ceph21][DEBUG ]     ]
[2016-07-15 14:47:07,132][ceph21][DEBUG ]   }, 
[2016-07-15 14:47:07,132][ceph21][DEBUG ]   "name": "ceph21", 
[2016-07-15 14:47:07,132][ceph21][DEBUG ]   "outside_quorum": [], 
[2016-07-15 14:47:07,132][ceph21][DEBUG ]   "quorum": [
[2016-07-15 14:47:07,132][ceph21][DEBUG ]     0
[2016-07-15 14:47:07,132][ceph21][DEBUG ]   ], 
[2016-07-15 14:47:07,132][ceph21][DEBUG ]   "rank": 0, 
[2016-07-15 14:47:07,132][ceph21][DEBUG ]   "state": "leader", 
[2016-07-15 14:47:07,132][ceph21][DEBUG ]   "sync_provider": []
[2016-07-15 14:47:07,132][ceph21][DEBUG ] }
[2016-07-15 14:47:07,133][ceph21][DEBUG ] ********************************************************************************
[2016-07-15 14:47:07,133][ceph21][INFO  ] monitor: mon.ceph21 is running
[2016-07-15 14:47:07,134][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 14:47:07,200][ceph_deploy.mon][INFO  ] processing monitor mon.ceph21
[2016-07-15 14:47:07,922][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:47:07,923][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:47:07,939][ceph21][DEBUG ] detect machine type
[2016-07-15 14:47:07,943][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:47:07,945][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:47:07,954][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:47:07,956][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 14:47:08,021][ceph_deploy.mon][INFO  ] mon.ceph21 monitor has reached quorum!
[2016-07-15 14:47:08,022][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2016-07-15 14:47:08,022][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2016-07-15 14:47:08,022][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /etc/ceph/ceph.client.admin.keyring
[2016-07-15 14:47:08,735][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:47:08,735][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:47:08,751][ceph21][DEBUG ] detect machine type
[2016-07-15 14:47:08,755][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:47:08,757][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:47:08,766][ceph21][DEBUG ] fetch remote file
[2016-07-15 14:47:08,767][ceph_deploy.gatherkeys][DEBUG ] Got ceph.client.admin.keyring key from ceph21.
[2016-07-15 14:47:08,767][ceph_deploy.gatherkeys][DEBUG ] Have ceph.mon.keyring
[2016-07-15 14:47:08,767][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-osd/ceph.keyring
[2016-07-15 14:47:09,500][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:47:09,501][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:47:09,517][ceph21][DEBUG ] detect machine type
[2016-07-15 14:47:09,521][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:47:09,524][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:47:09,533][ceph21][DEBUG ] fetch remote file
[2016-07-15 14:47:09,534][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-osd.keyring key from ceph21.
[2016-07-15 14:47:09,535][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-mds/ceph.keyring
[2016-07-15 14:47:10,226][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:47:10,227][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:47:10,245][ceph21][DEBUG ] detect machine type
[2016-07-15 14:47:10,249][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:47:10,252][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:47:10,269][ceph21][DEBUG ] fetch remote file
[2016-07-15 14:47:10,270][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-mds.keyring key from ceph21.
[2016-07-15 14:47:10,270][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-rgw/ceph.keyring
[2016-07-15 14:47:10,976][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:47:10,977][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:47:10,993][ceph21][DEBUG ] detect machine type
[2016-07-15 14:47:10,997][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:47:11,000][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:47:11,009][ceph21][DEBUG ] fetch remote file
[2016-07-15 14:47:11,010][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-rgw.keyring key from ceph21.
[2016-07-15 14:47:30,089][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 14:47:30,089][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf osd create --zap-disk ceph22:/dev/vdb ceph22:/dev/vdc ceph23:/dev/vdb ceph23:/dev/vdc
[2016-07-15 14:47:30,089][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 14:47:30,089][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 14:47:30,089][ceph_deploy.cli][INFO  ]  disk                          : [('ceph22', '/dev/vdb', None), ('ceph22', '/dev/vdc', None), ('ceph23', '/dev/vdb', None), ('ceph23', '/dev/vdc', None)]
[2016-07-15 14:47:30,089][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2016-07-15 14:47:30,090][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 14:47:30,090][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2016-07-15 14:47:30,090][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-15 14:47:30,090][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-15 14:47:30,090][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2016-07-15 14:47:30,090][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 14:47:30,090][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f384100e1b8>
[2016-07-15 14:47:30,090][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 14:47:30,090][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2016-07-15 14:47:30,090][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f3840fdf578>
[2016-07-15 14:47:30,090][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 14:47:30,090][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 14:47:30,090][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2016-07-15 14:47:30,091][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks ceph22:/dev/vdb: ceph22:/dev/vdc: ceph23:/dev/vdb: ceph23:/dev/vdc:
[2016-07-15 14:47:30,780][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 14:47:30,781][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 14:47:30,799][ceph22][DEBUG ] detect machine type
[2016-07-15 14:47:30,802][ceph22][DEBUG ] find the location of an executable
[2016-07-15 14:47:30,805][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:47:30,824][ceph22][DEBUG ] find the location of an executable
[2016-07-15 14:47:30,825][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 14:47:30,826][ceph_deploy.osd][DEBUG ] Deploying osd to ceph22
[2016-07-15 14:47:30,826][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 14:47:30,828][ceph22][WARNING] osd keyring does not exist yet, creating one
[2016-07-15 14:47:30,828][ceph22][DEBUG ] create a keyring file
[2016-07-15 14:47:30,830][ceph_deploy.osd][DEBUG ] Preparing host ceph22 disk /dev/vdb journal None activate True
[2016-07-15 14:47:30,830][ceph22][DEBUG ] find the location of an executable
[2016-07-15 14:47:30,832][ceph22][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-15 14:47:30,949][ceph22][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-15 14:47:30,949][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-15 14:47:30,949][ceph22][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 14:47:30,949][ceph22][WARNING] backup header from main header.
[2016-07-15 14:47:30,949][ceph22][WARNING] 
[2016-07-15 14:47:30,949][ceph22][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 14:47:30,949][ceph22][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 14:47:30,949][ceph22][WARNING] 
[2016-07-15 14:47:30,950][ceph22][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 14:47:30,950][ceph22][WARNING] 
[2016-07-15 14:47:31,966][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 14:47:31,966][ceph22][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 14:47:31,966][ceph22][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 14:47:31,966][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 14:47:31,966][ceph22][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 14:47:31,966][ceph22][DEBUG ] other utilities.
[2016-07-15 14:47:31,966][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-15 14:47:32,982][ceph22][DEBUG ] Creating new GPT entries.
[2016-07-15 14:47:32,983][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 14:47:32,983][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-15 14:47:32,983][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 14:47:32,983][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 14:47:32,983][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 14:47:32,984][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 14:47:33,000][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 14:47:33,015][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 14:47:33,031][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 14:47:33,039][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 14:47:33,054][ceph22][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-15 14:47:33,054][ceph22][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-15 14:47:33,054][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:71a8483e-e243-4cfe-83f9-35e7abd8cc82 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-15 14:47:34,070][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 14:47:34,071][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 14:47:34,071][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 14:47:34,235][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 14:47:34,299][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/71a8483e-e243-4cfe-83f9-35e7abd8cc82
[2016-07-15 14:47:34,299][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/71a8483e-e243-4cfe-83f9-35e7abd8cc82
[2016-07-15 14:47:34,299][ceph22][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-15 14:47:34,299][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:996f7f62-69fd-48ef-9549-95f9f185acb5 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-15 14:47:35,315][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 14:47:35,316][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-15 14:47:35,316][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 14:47:35,580][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 14:47:35,612][ceph22][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-15 14:47:35,613][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-15 14:47:35,777][ceph22][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=1638335 blks
[2016-07-15 14:47:35,777][ceph22][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 14:47:35,777][ceph22][DEBUG ] data     =                       bsize=4096   blocks=6553339, imaxpct=25
[2016-07-15 14:47:35,777][ceph22][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 14:47:35,778][ceph22][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 14:47:35,778][ceph22][DEBUG ] log      =internal log           bsize=4096   blocks=3199, version=2
[2016-07-15 14:47:35,778][ceph22][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 14:47:35,778][ceph22][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.gFCyWR with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 14:47:35,778][ceph22][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 14:47:35,778][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.gFCyWR
[2016-07-15 14:47:35,778][ceph22][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.gFCyWR
[2016-07-15 14:47:35,778][ceph22][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.gFCyWR/journal -> /dev/disk/by-partuuid/71a8483e-e243-4cfe-83f9-35e7abd8cc82
[2016-07-15 14:47:35,810][ceph22][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.gFCyWR
[2016-07-15 14:47:35,810][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.gFCyWR
[2016-07-15 14:47:35,842][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-15 14:47:36,858][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 14:47:36,859][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 14:47:36,859][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 14:47:42,930][ceph22][INFO  ] checking OSD status...
[2016-07-15 14:47:42,931][ceph22][DEBUG ] find the location of an executable
[2016-07-15 14:47:42,934][ceph22][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 14:47:43,149][ceph_deploy.osd][DEBUG ] Host ceph22 is now ready for osd use.
[2016-07-15 14:47:43,830][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 14:47:43,831][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 14:47:43,847][ceph22][DEBUG ] detect machine type
[2016-07-15 14:47:43,851][ceph22][DEBUG ] find the location of an executable
[2016-07-15 14:47:43,854][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:47:43,863][ceph22][DEBUG ] find the location of an executable
[2016-07-15 14:47:43,864][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 14:47:43,864][ceph_deploy.osd][DEBUG ] Preparing host ceph22 disk /dev/vdc journal None activate True
[2016-07-15 14:47:43,864][ceph22][DEBUG ] find the location of an executable
[2016-07-15 14:47:43,867][ceph22][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-15 14:47:43,934][ceph22][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-15 14:47:43,934][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-15 14:47:43,934][ceph22][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 14:47:43,934][ceph22][WARNING] backup header from main header.
[2016-07-15 14:47:43,935][ceph22][WARNING] 
[2016-07-15 14:47:43,935][ceph22][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 14:47:43,935][ceph22][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 14:47:43,935][ceph22][WARNING] 
[2016-07-15 14:47:43,935][ceph22][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 14:47:43,935][ceph22][WARNING] 
[2016-07-15 14:47:44,951][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 14:47:44,952][ceph22][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 14:47:44,952][ceph22][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 14:47:44,952][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 14:47:44,953][ceph22][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 14:47:44,953][ceph22][DEBUG ] other utilities.
[2016-07-15 14:47:44,953][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-15 14:47:45,969][ceph22][DEBUG ] Creating new GPT entries.
[2016-07-15 14:47:45,970][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 14:47:45,970][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-15 14:47:45,970][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 14:47:45,986][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 14:47:46,001][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 14:47:46,017][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 14:47:46,033][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 14:47:46,040][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 14:47:46,056][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 14:47:46,071][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 14:47:46,079][ceph22][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-15 14:47:46,079][ceph22][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-15 14:47:46,079][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:55559938-09b9-40c0-bb9f-642fecb4146b --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-15 14:47:47,095][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 14:47:47,097][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 14:47:47,097][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 14:47:47,311][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 14:47:47,315][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/55559938-09b9-40c0-bb9f-642fecb4146b
[2016-07-15 14:47:47,315][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/55559938-09b9-40c0-bb9f-642fecb4146b
[2016-07-15 14:47:47,315][ceph22][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-15 14:47:47,316][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:086e8119-3afc-476a-9023-6f3d95db5352 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-15 14:47:48,382][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 14:47:48,382][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-15 14:47:48,382][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 14:47:48,647][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 14:47:48,654][ceph22][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-15 14:47:48,655][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-15 14:47:48,819][ceph22][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=1638335 blks
[2016-07-15 14:47:48,819][ceph22][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 14:47:48,819][ceph22][DEBUG ] data     =                       bsize=4096   blocks=6553339, imaxpct=25
[2016-07-15 14:47:48,820][ceph22][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 14:47:48,820][ceph22][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 14:47:48,820][ceph22][DEBUG ] log      =internal log           bsize=4096   blocks=3199, version=2
[2016-07-15 14:47:48,820][ceph22][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 14:47:48,820][ceph22][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 14:47:48,820][ceph22][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt.L6Ig1I with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 14:47:48,820][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt.L6Ig1I
[2016-07-15 14:47:48,821][ceph22][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.L6Ig1I
[2016-07-15 14:47:48,821][ceph22][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.L6Ig1I/journal -> /dev/disk/by-partuuid/55559938-09b9-40c0-bb9f-642fecb4146b
[2016-07-15 14:47:48,852][ceph22][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.L6Ig1I
[2016-07-15 14:47:48,853][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.L6Ig1I
[2016-07-15 14:47:48,884][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-15 14:47:49,901][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 14:47:49,901][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 14:47:49,901][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 14:47:56,621][ceph22][INFO  ] checking OSD status...
[2016-07-15 14:47:56,621][ceph22][DEBUG ] find the location of an executable
[2016-07-15 14:47:56,625][ceph22][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 14:47:56,841][ceph_deploy.osd][DEBUG ] Host ceph22 is now ready for osd use.
[2016-07-15 14:47:57,535][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 14:47:57,536][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 14:47:57,553][ceph23][DEBUG ] detect machine type
[2016-07-15 14:47:57,557][ceph23][DEBUG ] find the location of an executable
[2016-07-15 14:47:57,559][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:47:57,568][ceph23][DEBUG ] find the location of an executable
[2016-07-15 14:47:57,569][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 14:47:57,569][ceph_deploy.osd][DEBUG ] Deploying osd to ceph23
[2016-07-15 14:47:57,569][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 14:47:57,571][ceph23][WARNING] osd keyring does not exist yet, creating one
[2016-07-15 14:47:57,571][ceph23][DEBUG ] create a keyring file
[2016-07-15 14:47:57,572][ceph_deploy.osd][DEBUG ] Preparing host ceph23 disk /dev/vdb journal None activate True
[2016-07-15 14:47:57,573][ceph23][DEBUG ] find the location of an executable
[2016-07-15 14:47:57,574][ceph23][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-15 14:47:57,641][ceph23][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-15 14:47:57,642][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-15 14:47:57,642][ceph23][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 14:47:57,642][ceph23][WARNING] backup header from main header.
[2016-07-15 14:47:57,642][ceph23][WARNING] 
[2016-07-15 14:47:57,643][ceph23][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 14:47:57,643][ceph23][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 14:47:57,643][ceph23][WARNING] 
[2016-07-15 14:47:57,643][ceph23][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 14:47:57,643][ceph23][WARNING] 
[2016-07-15 14:47:58,710][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 14:47:58,710][ceph23][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 14:47:58,710][ceph23][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 14:47:58,710][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 14:47:58,710][ceph23][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 14:47:58,711][ceph23][DEBUG ] other utilities.
[2016-07-15 14:47:58,711][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-15 14:47:59,727][ceph23][DEBUG ] Creating new GPT entries.
[2016-07-15 14:47:59,727][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 14:47:59,727][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-15 14:47:59,727][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 14:47:59,728][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 14:47:59,729][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 14:47:59,745][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 14:47:59,752][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 14:47:59,768][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 14:47:59,784][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 14:47:59,787][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 14:47:59,803][ceph23][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-15 14:47:59,803][ceph23][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-15 14:47:59,804][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:4a8d1ea6-dc25-4961-bfa1-589b1c831f14 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-15 14:48:00,870][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 14:48:00,870][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 14:48:00,871][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 14:48:00,984][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 14:48:01,048][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/4a8d1ea6-dc25-4961-bfa1-589b1c831f14
[2016-07-15 14:48:01,049][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/4a8d1ea6-dc25-4961-bfa1-589b1c831f14
[2016-07-15 14:48:01,049][ceph23][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-15 14:48:01,049][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:166f0438-0347-4455-a107-e11531e4f243 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-15 14:48:02,066][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 14:48:02,066][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-15 14:48:02,066][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 14:48:02,331][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 14:48:02,363][ceph23][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-15 14:48:02,363][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-15 14:48:02,527][ceph23][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=1638335 blks
[2016-07-15 14:48:02,528][ceph23][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 14:48:02,528][ceph23][DEBUG ] data     =                       bsize=4096   blocks=6553339, imaxpct=25
[2016-07-15 14:48:02,528][ceph23][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 14:48:02,528][ceph23][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 14:48:02,528][ceph23][DEBUG ] log      =internal log           bsize=4096   blocks=3199, version=2
[2016-07-15 14:48:02,529][ceph23][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 14:48:02,529][ceph23][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 14:48:02,530][ceph23][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.y302pO with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 14:48:02,530][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.y302pO
[2016-07-15 14:48:02,538][ceph23][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.y302pO
[2016-07-15 14:48:02,538][ceph23][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.y302pO/journal -> /dev/disk/by-partuuid/4a8d1ea6-dc25-4961-bfa1-589b1c831f14
[2016-07-15 14:48:02,570][ceph23][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.y302pO
[2016-07-15 14:48:02,570][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.y302pO
[2016-07-15 14:48:02,602][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-15 14:48:03,669][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 14:48:03,669][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 14:48:03,669][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 14:48:10,441][ceph23][INFO  ] checking OSD status...
[2016-07-15 14:48:10,442][ceph23][DEBUG ] find the location of an executable
[2016-07-15 14:48:10,445][ceph23][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 14:48:10,610][ceph_deploy.osd][DEBUG ] Host ceph23 is now ready for osd use.
[2016-07-15 14:48:11,304][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 14:48:11,305][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 14:48:11,320][ceph23][DEBUG ] detect machine type
[2016-07-15 14:48:11,324][ceph23][DEBUG ] find the location of an executable
[2016-07-15 14:48:11,326][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:48:11,335][ceph23][DEBUG ] find the location of an executable
[2016-07-15 14:48:11,336][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 14:48:11,336][ceph_deploy.osd][DEBUG ] Preparing host ceph23 disk /dev/vdc journal None activate True
[2016-07-15 14:48:11,336][ceph23][DEBUG ] find the location of an executable
[2016-07-15 14:48:11,338][ceph23][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-15 14:48:11,405][ceph23][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-15 14:48:11,405][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-15 14:48:11,405][ceph23][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 14:48:11,405][ceph23][WARNING] backup header from main header.
[2016-07-15 14:48:11,405][ceph23][WARNING] 
[2016-07-15 14:48:11,405][ceph23][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 14:48:11,405][ceph23][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 14:48:11,406][ceph23][WARNING] 
[2016-07-15 14:48:11,406][ceph23][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 14:48:11,406][ceph23][WARNING] 
[2016-07-15 14:48:12,522][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 14:48:12,522][ceph23][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 14:48:12,522][ceph23][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 14:48:12,522][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 14:48:12,522][ceph23][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 14:48:12,522][ceph23][DEBUG ] other utilities.
[2016-07-15 14:48:12,523][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-15 14:48:13,538][ceph23][DEBUG ] Creating new GPT entries.
[2016-07-15 14:48:13,539][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 14:48:13,539][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-15 14:48:13,539][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 14:48:13,539][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 14:48:13,555][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 14:48:13,562][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 14:48:13,578][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 14:48:13,594][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 14:48:13,609][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 14:48:13,617][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 14:48:13,633][ceph23][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-15 14:48:13,633][ceph23][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-15 14:48:13,633][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:5a1441d1-76d7-4b55-a3da-a01c1d107bd4 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-15 14:48:14,649][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 14:48:14,649][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 14:48:14,649][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 14:48:14,864][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 14:48:14,864][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/5a1441d1-76d7-4b55-a3da-a01c1d107bd4
[2016-07-15 14:48:14,864][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/5a1441d1-76d7-4b55-a3da-a01c1d107bd4
[2016-07-15 14:48:14,865][ceph23][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-15 14:48:14,865][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:f67661c3-8193-4715-9669-cd0b20985359 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-15 14:48:15,881][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 14:48:15,883][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-15 14:48:15,883][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 14:48:16,148][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 14:48:16,180][ceph23][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-15 14:48:16,180][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-15 14:48:16,344][ceph23][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=1638335 blks
[2016-07-15 14:48:16,345][ceph23][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 14:48:16,346][ceph23][DEBUG ] data     =                       bsize=4096   blocks=6553339, imaxpct=25
[2016-07-15 14:48:16,347][ceph23][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 14:48:16,347][ceph23][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 14:48:16,348][ceph23][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt.FUkc7D with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 14:48:16,348][ceph23][DEBUG ] log      =internal log           bsize=4096   blocks=3199, version=2
[2016-07-15 14:48:16,348][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt.FUkc7D
[2016-07-15 14:48:16,348][ceph23][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 14:48:16,348][ceph23][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 14:48:16,356][ceph23][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.FUkc7D
[2016-07-15 14:48:16,356][ceph23][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.FUkc7D/journal -> /dev/disk/by-partuuid/5a1441d1-76d7-4b55-a3da-a01c1d107bd4
[2016-07-15 14:48:16,388][ceph23][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.FUkc7D
[2016-07-15 14:48:16,388][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.FUkc7D
[2016-07-15 14:48:16,420][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-15 14:48:17,436][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 14:48:17,437][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 14:48:17,437][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 14:48:24,210][ceph23][INFO  ] checking OSD status...
[2016-07-15 14:48:24,210][ceph23][DEBUG ] find the location of an executable
[2016-07-15 14:48:24,213][ceph23][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 14:48:24,429][ceph_deploy.osd][DEBUG ] Host ceph23 is now ready for osd use.
[2016-07-15 14:49:39,872][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 14:49:39,873][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf admin ceph21 ceph22 ceph23
[2016-07-15 14:49:39,873][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 14:49:39,873][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 14:49:39,873][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 14:49:39,873][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-15 14:49:39,873][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 14:49:39,873][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9cd66575a8>
[2016-07-15 14:49:39,873][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 14:49:39,873][ceph_deploy.cli][INFO  ]  client                        : ['ceph21', 'ceph22', 'ceph23']
[2016-07-15 14:49:39,874][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f9cd6f7a7d0>
[2016-07-15 14:49:39,874][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 14:49:39,874][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 14:49:39,875][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph21
[2016-07-15 14:49:40,584][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:49:40,585][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:49:40,604][ceph21][DEBUG ] detect machine type
[2016-07-15 14:49:40,608][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:49:40,611][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:49:40,623][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 14:49:40,626][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph22
[2016-07-15 14:49:41,317][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 14:49:41,319][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 14:49:41,338][ceph22][DEBUG ] detect machine type
[2016-07-15 14:49:41,342][ceph22][DEBUG ] find the location of an executable
[2016-07-15 14:49:41,345][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:49:41,354][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 14:49:41,357][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph23
[2016-07-15 14:49:42,053][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 14:49:42,054][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 14:49:42,071][ceph23][DEBUG ] detect machine type
[2016-07-15 14:49:42,074][ceph23][DEBUG ] find the location of an executable
[2016-07-15 14:49:42,077][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:49:42,095][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 14:55:59,941][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 14:55:59,941][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy rgw create ceph21
[2016-07-15 14:55:59,941][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 14:55:59,941][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 14:55:59,941][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 14:55:59,941][ceph_deploy.cli][INFO  ]  rgw                           : [('ceph21', 'rgw.ceph21')]
[2016-07-15 14:55:59,942][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 14:55:59,942][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-15 14:55:59,942][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 14:55:59,942][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f160cc2f680>
[2016-07-15 14:55:59,942][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 14:55:59,942][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f160d4f66e0>
[2016-07-15 14:55:59,942][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 14:55:59,942][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 14:55:59,943][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts ceph21:rgw.ceph21
[2016-07-15 14:56:00,722][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 14:56:00,723][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 14:56:00,741][ceph21][DEBUG ] detect machine type
[2016-07-15 14:56:00,745][ceph21][DEBUG ] find the location of an executable
[2016-07-15 14:56:00,748][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 14:56:00,768][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 14:56:00,769][ceph_deploy.rgw][DEBUG ] remote host will use upstart
[2016-07-15 14:56:00,769][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to ceph21
[2016-07-15 14:56:00,769][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 14:56:00,772][ceph21][DEBUG ] create path recursively if it doesn't exist
[2016-07-15 14:56:00,775][ceph21][INFO  ] Running command: ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.ceph21 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.ceph21/keyring
[2016-07-15 14:56:00,994][ceph21][INFO  ] Running command: initctl emit radosgw cluster=ceph id=rgw.ceph21
[2016-07-15 14:56:01,013][ceph_deploy.rgw][INFO  ] The Ceph Object Gateway (RGW) is now running on host ceph21 and default port 7480
[2016-07-15 15:42:35,850][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 15:42:35,851][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph21
[2016-07-15 15:42:35,851][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 15:42:35,851][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 15:42:35,852][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 15:42:35,852][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 15:42:35,852][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 15:42:35,852][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb0edae2b00>
[2016-07-15 15:42:35,852][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 15:42:35,852][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-15 15:42:35,852][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fb0ee3f91b8>
[2016-07-15 15:42:35,852][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 15:42:35,853][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 15:42:35,853][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 15:42:35,853][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 15:42:35,853][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph21
[2016-07-15 15:42:35,853][ceph_deploy.install][DEBUG ] Detecting platform for host ceph21 ...
[2016-07-15 15:42:36,563][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 15:42:36,564][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 15:42:36,580][ceph21][DEBUG ] detect machine type
[2016-07-15 15:42:36,584][ceph21][DEBUG ] find the location of an executable
[2016-07-15 15:42:36,587][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:42:36,598][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 15:42:36,599][ceph21][INFO  ] Purging Ceph on ceph21
[2016-07-15 15:42:36,600][ceph21][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 15:42:37,018][ceph21][DEBUG ] Reading package lists...
[2016-07-15 15:42:37,333][ceph21][DEBUG ] Building dependency tree...
[2016-07-15 15:42:37,333][ceph21][DEBUG ] Reading state information...
[2016-07-15 15:42:37,598][ceph21][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 15:42:37,598][ceph21][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 15:42:37,598][ceph21][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 15:42:37,598][ceph21][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 15:42:37,599][ceph21][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 15:42:37,599][ceph21][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-15 15:42:37,599][ceph21][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libnspr4
[2016-07-15 15:42:37,599][ceph21][DEBUG ]   libnss3 libnss3-nssdb libxslt1.1 xmlstarlet
[2016-07-15 15:42:37,599][ceph21][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-15 15:42:37,607][ceph21][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 216 not upgraded.
[2016-07-15 15:42:37,705][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 15:42:37,706][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph21
[2016-07-15 15:42:37,706][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 15:42:37,706][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 15:42:37,706][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 15:42:37,706][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 15:42:37,706][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 15:42:37,706][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5f42e341b8>
[2016-07-15 15:42:37,706][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 15:42:37,706][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-15 15:42:37,706][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f5f43743230>
[2016-07-15 15:42:37,707][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 15:42:37,707][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 15:42:37,707][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph21
[2016-07-15 15:42:38,425][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 15:42:38,427][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 15:42:38,442][ceph21][DEBUG ] detect machine type
[2016-07-15 15:42:38,446][ceph21][DEBUG ] find the location of an executable
[2016-07-15 15:42:38,449][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:42:38,459][ceph21][DEBUG ] find the location of an executable
[2016-07-15 15:42:39,164][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 15:42:39,166][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 15:42:39,186][ceph21][DEBUG ] detect machine type
[2016-07-15 15:42:39,190][ceph21][DEBUG ] find the location of an executable
[2016-07-15 15:42:39,193][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:42:39,210][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 15:42:39,210][ceph21][INFO  ] purging data on ceph21
[2016-07-15 15:42:39,212][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 15:42:39,223][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 15:42:49,217][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 15:42:49,217][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph22
[2016-07-15 15:42:49,217][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 15:42:49,218][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 15:42:49,218][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 15:42:49,218][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 15:42:49,218][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 15:42:49,218][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f293c474b00>
[2016-07-15 15:42:49,218][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 15:42:49,218][ceph_deploy.cli][INFO  ]  host                          : ['ceph22']
[2016-07-15 15:42:49,219][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f293cd8b1b8>
[2016-07-15 15:42:49,219][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 15:42:49,219][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 15:42:49,219][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 15:42:49,219][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 15:42:49,219][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph22
[2016-07-15 15:42:49,219][ceph_deploy.install][DEBUG ] Detecting platform for host ceph22 ...
[2016-07-15 15:42:49,898][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 15:42:49,899][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 15:42:49,916][ceph22][DEBUG ] detect machine type
[2016-07-15 15:42:49,920][ceph22][DEBUG ] find the location of an executable
[2016-07-15 15:42:49,922][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:42:49,941][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 15:42:49,942][ceph22][INFO  ] Purging Ceph on ceph22
[2016-07-15 15:42:49,943][ceph22][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 15:42:50,211][ceph22][DEBUG ] Reading package lists...
[2016-07-15 15:42:50,525][ceph22][DEBUG ] Building dependency tree...
[2016-07-15 15:42:50,526][ceph22][DEBUG ] Reading state information...
[2016-07-15 15:42:50,740][ceph22][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 15:42:50,740][ceph22][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 15:42:50,740][ceph22][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 15:42:50,740][ceph22][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 15:42:50,741][ceph22][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 15:42:50,741][ceph22][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 218 not upgraded.
[2016-07-15 15:42:50,838][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 15:42:50,839][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph22
[2016-07-15 15:42:50,839][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 15:42:50,839][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 15:42:50,839][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 15:42:50,839][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 15:42:50,840][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 15:42:50,840][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f21daafa1b8>
[2016-07-15 15:42:50,840][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 15:42:50,840][ceph_deploy.cli][INFO  ]  host                          : ['ceph22']
[2016-07-15 15:42:50,840][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f21db409230>
[2016-07-15 15:42:50,840][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 15:42:50,840][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 15:42:50,840][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph22
[2016-07-15 15:42:51,543][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 15:42:51,544][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 15:42:51,561][ceph22][DEBUG ] detect machine type
[2016-07-15 15:42:51,565][ceph22][DEBUG ] find the location of an executable
[2016-07-15 15:42:51,567][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:42:51,578][ceph22][DEBUG ] find the location of an executable
[2016-07-15 15:42:52,269][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 15:42:52,270][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 15:42:52,286][ceph22][DEBUG ] detect machine type
[2016-07-15 15:42:52,291][ceph22][DEBUG ] find the location of an executable
[2016-07-15 15:42:52,294][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:42:52,311][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 15:42:52,311][ceph22][INFO  ] purging data on ceph22
[2016-07-15 15:42:52,313][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 15:42:52,323][ceph22][WARNING] OSDs may still be mounted, trying to unmount them
[2016-07-15 15:42:52,325][ceph22][INFO  ] Running command: find /var/lib/ceph -mindepth 1 -maxdepth 2 -type d -exec umount {} ;
[2016-07-15 15:42:52,335][ceph22][WARNING] umount: /var/lib/ceph/osd: not mounted
[2016-07-15 15:42:52,402][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 15:42:52,414][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 15:43:03,251][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 15:43:03,251][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph23
[2016-07-15 15:43:03,251][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 15:43:03,251][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 15:43:03,252][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 15:43:03,252][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 15:43:03,252][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 15:43:03,252][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fea78095b00>
[2016-07-15 15:43:03,252][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 15:43:03,252][ceph_deploy.cli][INFO  ]  host                          : ['ceph23']
[2016-07-15 15:43:03,252][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fea789ac1b8>
[2016-07-15 15:43:03,252][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 15:43:03,253][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 15:43:03,253][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 15:43:03,253][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 15:43:03,253][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph23
[2016-07-15 15:43:03,253][ceph_deploy.install][DEBUG ] Detecting platform for host ceph23 ...
[2016-07-15 15:43:03,983][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 15:43:03,984][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 15:43:04,010][ceph23][DEBUG ] detect machine type
[2016-07-15 15:43:04,015][ceph23][DEBUG ] find the location of an executable
[2016-07-15 15:43:04,018][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:43:04,036][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 15:43:04,036][ceph23][INFO  ] Purging Ceph on ceph23
[2016-07-15 15:43:04,038][ceph23][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 15:43:04,505][ceph23][DEBUG ] Reading package lists...
[2016-07-15 15:43:04,770][ceph23][DEBUG ] Building dependency tree...
[2016-07-15 15:43:04,771][ceph23][DEBUG ] Reading state information...
[2016-07-15 15:43:04,985][ceph23][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 15:43:04,985][ceph23][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 15:43:04,985][ceph23][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 15:43:04,985][ceph23][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 15:43:04,985][ceph23][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 15:43:04,986][ceph23][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-15 15:43:04,986][ceph23][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libxslt1.1
[2016-07-15 15:43:04,986][ceph23][DEBUG ]   xmlstarlet
[2016-07-15 15:43:04,986][ceph23][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-15 15:43:05,050][ceph23][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 218 not upgraded.
[2016-07-15 15:43:05,145][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 15:43:05,146][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph23
[2016-07-15 15:43:05,146][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 15:43:05,146][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 15:43:05,146][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 15:43:05,146][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 15:43:05,146][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 15:43:05,147][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f19f60201b8>
[2016-07-15 15:43:05,147][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 15:43:05,147][ceph_deploy.cli][INFO  ]  host                          : ['ceph23']
[2016-07-15 15:43:05,147][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f19f692f230>
[2016-07-15 15:43:05,147][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 15:43:05,147][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 15:43:05,147][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph23
[2016-07-15 15:43:05,889][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 15:43:05,890][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 15:43:05,906][ceph23][DEBUG ] detect machine type
[2016-07-15 15:43:05,910][ceph23][DEBUG ] find the location of an executable
[2016-07-15 15:43:05,913][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:43:05,924][ceph23][DEBUG ] find the location of an executable
[2016-07-15 15:43:06,613][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 15:43:06,614][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 15:43:06,632][ceph23][DEBUG ] detect machine type
[2016-07-15 15:43:06,637][ceph23][DEBUG ] find the location of an executable
[2016-07-15 15:43:06,639][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:43:06,656][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 15:43:06,657][ceph23][INFO  ] purging data on ceph23
[2016-07-15 15:43:06,658][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 15:43:06,668][ceph23][WARNING] OSDs may still be mounted, trying to unmount them
[2016-07-15 15:43:06,669][ceph23][INFO  ] Running command: find /var/lib/ceph -mindepth 1 -maxdepth 2 -type d -exec umount {} ;
[2016-07-15 15:43:06,680][ceph23][WARNING] umount: /var/lib/ceph/osd: not mounted
[2016-07-15 15:43:06,746][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 15:43:06,758][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 15:50:47,870][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 15:50:47,871][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy new ceph21
[2016-07-15 15:50:47,871][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 15:50:47,871][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 15:50:47,871][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f7d9c16e410>
[2016-07-15 15:50:47,871][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 15:50:47,872][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 15:50:47,872][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 15:50:47,872][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7d9b8d0ef0>
[2016-07-15 15:50:47,872][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 15:50:47,872][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2016-07-15 15:50:47,872][ceph_deploy.cli][INFO  ]  mon                           : ['ceph21']
[2016-07-15 15:50:47,872][ceph_deploy.cli][INFO  ]  public_network                : None
[2016-07-15 15:50:47,872][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 15:50:47,873][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2016-07-15 15:50:47,873][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 15:50:47,873][ceph_deploy.cli][INFO  ]  fsid                          : None
[2016-07-15 15:50:47,873][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2016-07-15 15:50:47,873][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2016-07-15 15:50:47,902][ceph21][DEBUG ] connected to host: cephAdmin 
[2016-07-15 15:50:47,908][ceph21][INFO  ] Running command: ssh -CT -o BatchMode=yes ceph21
[2016-07-15 15:50:49,018][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 15:50:49,019][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 15:50:49,046][ceph21][DEBUG ] detect machine type
[2016-07-15 15:50:49,050][ceph21][DEBUG ] find the location of an executable
[2016-07-15 15:50:49,052][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:50:49,061][ceph21][DEBUG ] find the location of an executable
[2016-07-15 15:50:49,064][ceph21][INFO  ] Running command: /bin/ip link show
[2016-07-15 15:50:49,074][ceph21][INFO  ] Running command: /bin/ip addr show
[2016-07-15 15:50:49,083][ceph21][DEBUG ] IP addresses found: ['10.1.0.44']
[2016-07-15 15:50:49,083][ceph_deploy.new][DEBUG ] Resolving host ceph21
[2016-07-15 15:50:49,084][ceph_deploy.new][DEBUG ] Monitor ceph21 at 10.1.0.44
[2016-07-15 15:50:49,084][ceph_deploy.new][DEBUG ] Monitor initial members are ['ceph21']
[2016-07-15 15:50:49,084][ceph_deploy.new][DEBUG ] Monitor addrs are ['10.1.0.44']
[2016-07-15 15:50:49,085][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2016-07-15 15:50:49,085][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2016-07-15 15:50:49,085][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2016-07-15 15:50:49,195][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 15:50:49,196][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy mon create-initial
[2016-07-15 15:50:49,197][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 15:50:49,197][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 15:50:49,197][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 15:50:49,197][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 15:50:49,197][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2016-07-15 15:50:49,198][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 15:50:49,198][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f39fc279290>
[2016-07-15 15:50:49,198][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 15:50:49,198][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f39fc25a6e0>
[2016-07-15 15:50:49,198][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 15:50:49,198][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 15:50:49,198][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2016-07-15 15:50:49,200][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts ceph21
[2016-07-15 15:50:49,200][ceph_deploy.mon][DEBUG ] detecting platform for host ceph21 ...
[2016-07-15 15:50:49,909][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 15:50:49,910][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 15:50:49,926][ceph21][DEBUG ] detect machine type
[2016-07-15 15:50:49,930][ceph21][DEBUG ] find the location of an executable
[2016-07-15 15:50:49,933][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:50:49,944][ceph21][DEBUG ] find the location of an executable
[2016-07-15 15:50:49,945][ceph_deploy.mon][INFO  ] distro info: Ubuntu 14.04 trusty
[2016-07-15 15:50:49,945][ceph21][DEBUG ] determining if provided host has same hostname in remote
[2016-07-15 15:50:49,946][ceph21][DEBUG ] get remote short hostname
[2016-07-15 15:50:49,946][ceph21][DEBUG ] deploying mon to ceph21
[2016-07-15 15:50:49,946][ceph21][DEBUG ] get remote short hostname
[2016-07-15 15:50:49,947][ceph21][DEBUG ] remote hostname: ceph21
[2016-07-15 15:50:49,950][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 15:50:49,952][ceph21][DEBUG ] create the mon path if it does not exist
[2016-07-15 15:50:49,952][ceph21][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-15 15:50:49,953][ceph21][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-15 15:50:49,954][ceph21][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 15:50:49,954][ceph21][DEBUG ] create the monitor keyring file
[2016-07-15 15:50:49,956][ceph21][INFO  ] Running command: ceph-mon --cluster ceph --mkfs -i ceph21 --keyring /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 15:50:49,991][ceph21][DEBUG ] ceph-mon: mon.noname-a 10.1.0.44:6789/0 is local, renaming to mon.ceph21
[2016-07-15 15:50:49,991][ceph21][DEBUG ] ceph-mon: set fsid to 0f1337e0-57d4-41eb-95de-76bf9276f6e5
[2016-07-15 15:50:49,991][ceph21][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-ceph21 for mon.ceph21
[2016-07-15 15:50:49,992][ceph21][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 15:50:49,993][ceph21][DEBUG ] create a done file to avoid re-doing the mon deployment
[2016-07-15 15:50:49,994][ceph21][DEBUG ] create the init path if it does not exist
[2016-07-15 15:50:49,996][ceph21][INFO  ] Running command: initctl emit ceph-mon cluster=ceph id=ceph21
[2016-07-15 15:50:52,021][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 15:50:52,086][ceph21][DEBUG ] ********************************************************************************
[2016-07-15 15:50:52,087][ceph21][DEBUG ] status for monitor: mon.ceph21
[2016-07-15 15:50:52,087][ceph21][DEBUG ] {
[2016-07-15 15:50:52,087][ceph21][DEBUG ]   "election_epoch": 2, 
[2016-07-15 15:50:52,087][ceph21][DEBUG ]   "extra_probe_peers": [], 
[2016-07-15 15:50:52,087][ceph21][DEBUG ]   "monmap": {
[2016-07-15 15:50:52,088][ceph21][DEBUG ]     "created": "0.000000", 
[2016-07-15 15:50:52,088][ceph21][DEBUG ]     "epoch": 1, 
[2016-07-15 15:50:52,088][ceph21][DEBUG ]     "fsid": "0f1337e0-57d4-41eb-95de-76bf9276f6e5", 
[2016-07-15 15:50:52,088][ceph21][DEBUG ]     "modified": "0.000000", 
[2016-07-15 15:50:52,088][ceph21][DEBUG ]     "mons": [
[2016-07-15 15:50:52,088][ceph21][DEBUG ]       {
[2016-07-15 15:50:52,089][ceph21][DEBUG ]         "addr": "10.1.0.44:6789/0", 
[2016-07-15 15:50:52,089][ceph21][DEBUG ]         "name": "ceph21", 
[2016-07-15 15:50:52,089][ceph21][DEBUG ]         "rank": 0
[2016-07-15 15:50:52,089][ceph21][DEBUG ]       }
[2016-07-15 15:50:52,089][ceph21][DEBUG ]     ]
[2016-07-15 15:50:52,089][ceph21][DEBUG ]   }, 
[2016-07-15 15:50:52,090][ceph21][DEBUG ]   "name": "ceph21", 
[2016-07-15 15:50:52,090][ceph21][DEBUG ]   "outside_quorum": [], 
[2016-07-15 15:50:52,090][ceph21][DEBUG ]   "quorum": [
[2016-07-15 15:50:52,090][ceph21][DEBUG ]     0
[2016-07-15 15:50:52,090][ceph21][DEBUG ]   ], 
[2016-07-15 15:50:52,091][ceph21][DEBUG ]   "rank": 0, 
[2016-07-15 15:50:52,091][ceph21][DEBUG ]   "state": "leader", 
[2016-07-15 15:50:52,091][ceph21][DEBUG ]   "sync_provider": []
[2016-07-15 15:50:52,091][ceph21][DEBUG ] }
[2016-07-15 15:50:52,091][ceph21][DEBUG ] ********************************************************************************
[2016-07-15 15:50:52,092][ceph21][INFO  ] monitor: mon.ceph21 is running
[2016-07-15 15:50:52,094][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 15:50:52,160][ceph_deploy.mon][INFO  ] processing monitor mon.ceph21
[2016-07-15 15:50:52,853][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 15:50:52,854][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 15:50:52,871][ceph21][DEBUG ] detect machine type
[2016-07-15 15:50:52,875][ceph21][DEBUG ] find the location of an executable
[2016-07-15 15:50:52,877][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:50:52,886][ceph21][DEBUG ] find the location of an executable
[2016-07-15 15:50:52,889][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 15:50:52,954][ceph_deploy.mon][INFO  ] mon.ceph21 monitor has reached quorum!
[2016-07-15 15:50:52,954][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2016-07-15 15:50:52,954][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2016-07-15 15:50:52,955][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /etc/ceph/ceph.client.admin.keyring
[2016-07-15 15:50:53,655][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 15:50:53,656][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 15:50:53,672][ceph21][DEBUG ] detect machine type
[2016-07-15 15:50:53,677][ceph21][DEBUG ] find the location of an executable
[2016-07-15 15:50:53,679][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:50:53,688][ceph21][DEBUG ] fetch remote file
[2016-07-15 15:50:53,689][ceph_deploy.gatherkeys][DEBUG ] Got ceph.client.admin.keyring key from ceph21.
[2016-07-15 15:50:53,690][ceph_deploy.gatherkeys][DEBUG ] Have ceph.mon.keyring
[2016-07-15 15:50:53,690][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-osd/ceph.keyring
[2016-07-15 15:50:54,378][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 15:50:54,380][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 15:50:54,396][ceph21][DEBUG ] detect machine type
[2016-07-15 15:50:54,400][ceph21][DEBUG ] find the location of an executable
[2016-07-15 15:50:54,402][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:50:54,411][ceph21][DEBUG ] fetch remote file
[2016-07-15 15:50:54,412][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-osd.keyring key from ceph21.
[2016-07-15 15:50:54,417][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-mds/ceph.keyring
[2016-07-15 15:50:55,082][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 15:50:55,083][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 15:50:55,100][ceph21][DEBUG ] detect machine type
[2016-07-15 15:50:55,104][ceph21][DEBUG ] find the location of an executable
[2016-07-15 15:50:55,106][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:50:55,115][ceph21][DEBUG ] fetch remote file
[2016-07-15 15:50:55,117][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-mds.keyring key from ceph21.
[2016-07-15 15:50:55,117][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-rgw/ceph.keyring
[2016-07-15 15:50:55,799][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 15:50:55,800][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 15:50:55,816][ceph21][DEBUG ] detect machine type
[2016-07-15 15:50:55,825][ceph21][DEBUG ] find the location of an executable
[2016-07-15 15:50:55,827][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:50:55,836][ceph21][DEBUG ] fetch remote file
[2016-07-15 15:50:55,837][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-rgw.keyring key from ceph21.
[2016-07-15 15:50:55,966][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 15:50:55,967][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf osd create --zap-disk ceph22:/dev/vdb ceph22:/dev/vdc ceph23:/dev/vdb ceph23:/dev/vdc
[2016-07-15 15:50:55,967][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 15:50:55,967][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 15:50:55,967][ceph_deploy.cli][INFO  ]  disk                          : [('ceph22', '/dev/vdb', None), ('ceph22', '/dev/vdc', None), ('ceph23', '/dev/vdb', None), ('ceph23', '/dev/vdc', None)]
[2016-07-15 15:50:55,967][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2016-07-15 15:50:55,968][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 15:50:55,968][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2016-07-15 15:50:55,968][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-15 15:50:55,968][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-15 15:50:55,968][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2016-07-15 15:50:55,968][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 15:50:55,968][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ffe8da211b8>
[2016-07-15 15:50:55,968][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 15:50:55,968][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2016-07-15 15:50:55,969][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7ffe8d9f2578>
[2016-07-15 15:50:55,969][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 15:50:55,969][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 15:50:55,969][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2016-07-15 15:50:55,970][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks ceph22:/dev/vdb: ceph22:/dev/vdc: ceph23:/dev/vdb: ceph23:/dev/vdc:
[2016-07-15 15:50:56,676][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 15:50:56,677][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 15:50:56,694][ceph22][DEBUG ] detect machine type
[2016-07-15 15:50:56,698][ceph22][DEBUG ] find the location of an executable
[2016-07-15 15:50:56,701][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:50:56,720][ceph22][DEBUG ] find the location of an executable
[2016-07-15 15:50:56,721][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 15:50:56,722][ceph_deploy.osd][DEBUG ] Deploying osd to ceph22
[2016-07-15 15:50:56,722][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 15:50:56,724][ceph22][WARNING] osd keyring does not exist yet, creating one
[2016-07-15 15:50:56,725][ceph22][DEBUG ] create a keyring file
[2016-07-15 15:50:56,726][ceph_deploy.osd][DEBUG ] Preparing host ceph22 disk /dev/vdb journal None activate True
[2016-07-15 15:50:56,726][ceph22][DEBUG ] find the location of an executable
[2016-07-15 15:50:56,729][ceph22][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-15 15:50:56,796][ceph22][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-15 15:50:56,796][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-15 15:50:56,797][ceph22][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 15:50:56,799][ceph22][WARNING] backup header from main header.
[2016-07-15 15:50:56,799][ceph22][WARNING] 
[2016-07-15 15:50:56,799][ceph22][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 15:50:56,799][ceph22][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 15:50:56,799][ceph22][WARNING] 
[2016-07-15 15:50:56,799][ceph22][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 15:50:56,799][ceph22][WARNING] 
[2016-07-15 15:50:57,865][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 15:50:57,866][ceph22][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 15:50:57,866][ceph22][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 15:50:57,866][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 15:50:57,866][ceph22][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 15:50:57,867][ceph22][DEBUG ] other utilities.
[2016-07-15 15:50:57,867][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-15 15:50:58,883][ceph22][DEBUG ] Creating new GPT entries.
[2016-07-15 15:50:58,883][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 15:50:58,883][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-15 15:50:58,884][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 15:50:58,884][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 15:50:58,884][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 15:50:58,884][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 15:50:58,892][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 15:50:58,908][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 15:50:58,924][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 15:50:58,931][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 15:50:58,947][ceph22][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-15 15:50:58,947][ceph22][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-15 15:50:58,948][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:050a0343-978d-4bf2-aaf5-968abc59cadf --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-15 15:50:59,963][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 15:50:59,964][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 15:50:59,964][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 15:51:00,128][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 15:51:00,193][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/050a0343-978d-4bf2-aaf5-968abc59cadf
[2016-07-15 15:51:00,193][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/050a0343-978d-4bf2-aaf5-968abc59cadf
[2016-07-15 15:51:00,193][ceph22][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-15 15:51:00,193][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:c1f6e8bd-79f0-45c1-9e30-d8ec6187cafa --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-15 15:51:01,209][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 15:51:01,209][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-15 15:51:01,210][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 15:51:01,474][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 15:51:01,506][ceph22][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-15 15:51:01,506][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-15 15:51:01,671][ceph22][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=1638335 blks
[2016-07-15 15:51:01,671][ceph22][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 15:51:01,671][ceph22][DEBUG ] data     =                       bsize=4096   blocks=6553339, imaxpct=25
[2016-07-15 15:51:01,671][ceph22][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 15:51:01,671][ceph22][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 15:51:01,672][ceph22][DEBUG ] log      =internal log           bsize=4096   blocks=3199, version=2
[2016-07-15 15:51:01,672][ceph22][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 15:51:01,672][ceph22][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.ZYD8P3 with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 15:51:01,672][ceph22][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 15:51:01,672][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.ZYD8P3
[2016-07-15 15:51:01,672][ceph22][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.ZYD8P3
[2016-07-15 15:51:01,672][ceph22][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.ZYD8P3/journal -> /dev/disk/by-partuuid/050a0343-978d-4bf2-aaf5-968abc59cadf
[2016-07-15 15:51:01,704][ceph22][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.ZYD8P3
[2016-07-15 15:51:01,705][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.ZYD8P3
[2016-07-15 15:51:01,737][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-15 15:51:02,753][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 15:51:02,753][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 15:51:02,754][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 15:51:08,924][ceph22][INFO  ] checking OSD status...
[2016-07-15 15:51:08,924][ceph22][DEBUG ] find the location of an executable
[2016-07-15 15:51:08,927][ceph22][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 15:51:09,092][ceph_deploy.osd][DEBUG ] Host ceph22 is now ready for osd use.
[2016-07-15 15:51:09,771][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 15:51:09,772][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 15:51:09,789][ceph22][DEBUG ] detect machine type
[2016-07-15 15:51:09,793][ceph22][DEBUG ] find the location of an executable
[2016-07-15 15:51:09,795][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:51:09,812][ceph22][DEBUG ] find the location of an executable
[2016-07-15 15:51:09,814][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 15:51:09,814][ceph_deploy.osd][DEBUG ] Preparing host ceph22 disk /dev/vdc journal None activate True
[2016-07-15 15:51:09,814][ceph22][DEBUG ] find the location of an executable
[2016-07-15 15:51:09,816][ceph22][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-15 15:51:09,886][ceph22][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-15 15:51:09,886][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-15 15:51:09,886][ceph22][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 15:51:09,886][ceph22][WARNING] backup header from main header.
[2016-07-15 15:51:09,886][ceph22][WARNING] 
[2016-07-15 15:51:09,886][ceph22][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 15:51:09,887][ceph22][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 15:51:09,887][ceph22][WARNING] 
[2016-07-15 15:51:09,887][ceph22][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 15:51:09,887][ceph22][WARNING] 
[2016-07-15 15:51:10,904][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 15:51:10,904][ceph22][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 15:51:10,904][ceph22][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 15:51:10,905][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 15:51:10,905][ceph22][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 15:51:10,905][ceph22][DEBUG ] other utilities.
[2016-07-15 15:51:10,905][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-15 15:51:11,971][ceph22][DEBUG ] Creating new GPT entries.
[2016-07-15 15:51:11,972][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 15:51:11,972][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-15 15:51:11,972][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 15:51:11,972][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 15:51:11,972][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 15:51:11,973][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 15:51:11,988][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 15:51:12,004][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 15:51:12,012][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 15:51:12,027][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 15:51:12,035][ceph22][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-15 15:51:12,035][ceph22][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-15 15:51:12,035][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:9220d1cb-cdaa-404f-b75c-6e491871aa32 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-15 15:51:13,102][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 15:51:13,102][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 15:51:13,102][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 15:51:13,266][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 15:51:13,267][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/9220d1cb-cdaa-404f-b75c-6e491871aa32
[2016-07-15 15:51:13,267][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/9220d1cb-cdaa-404f-b75c-6e491871aa32
[2016-07-15 15:51:13,267][ceph22][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-15 15:51:13,267][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:6c899fff-a28c-4805-b9ce-f357699b9a38 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-15 15:51:14,283][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 15:51:14,283][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-15 15:51:14,284][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 15:51:14,598][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 15:51:14,598][ceph22][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-15 15:51:14,598][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-15 15:51:14,762][ceph22][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=1638335 blks
[2016-07-15 15:51:14,763][ceph22][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 15:51:14,763][ceph22][DEBUG ] data     =                       bsize=4096   blocks=6553339, imaxpct=25
[2016-07-15 15:51:14,763][ceph22][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 15:51:14,763][ceph22][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 15:51:14,763][ceph22][DEBUG ] log      =internal log           bsize=4096   blocks=3199, version=2
[2016-07-15 15:51:14,763][ceph22][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 15:51:14,763][ceph22][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 15:51:14,764][ceph22][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt.ed8VtA with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 15:51:14,764][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt.ed8VtA
[2016-07-15 15:51:14,764][ceph22][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.ed8VtA
[2016-07-15 15:51:14,764][ceph22][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.ed8VtA/journal -> /dev/disk/by-partuuid/9220d1cb-cdaa-404f-b75c-6e491871aa32
[2016-07-15 15:51:14,796][ceph22][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.ed8VtA
[2016-07-15 15:51:14,796][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.ed8VtA
[2016-07-15 15:51:14,812][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-15 15:51:15,878][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 15:51:15,878][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 15:51:15,879][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 15:51:22,551][ceph22][INFO  ] checking OSD status...
[2016-07-15 15:51:22,551][ceph22][DEBUG ] find the location of an executable
[2016-07-15 15:51:22,555][ceph22][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 15:51:22,770][ceph_deploy.osd][DEBUG ] Host ceph22 is now ready for osd use.
[2016-07-15 15:51:23,481][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 15:51:23,483][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 15:51:23,499][ceph23][DEBUG ] detect machine type
[2016-07-15 15:51:23,503][ceph23][DEBUG ] find the location of an executable
[2016-07-15 15:51:23,505][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:51:23,514][ceph23][DEBUG ] find the location of an executable
[2016-07-15 15:51:23,515][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 15:51:23,516][ceph_deploy.osd][DEBUG ] Deploying osd to ceph23
[2016-07-15 15:51:23,516][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 15:51:23,518][ceph23][WARNING] osd keyring does not exist yet, creating one
[2016-07-15 15:51:23,518][ceph23][DEBUG ] create a keyring file
[2016-07-15 15:51:23,520][ceph_deploy.osd][DEBUG ] Preparing host ceph23 disk /dev/vdb journal None activate True
[2016-07-15 15:51:23,520][ceph23][DEBUG ] find the location of an executable
[2016-07-15 15:51:23,521][ceph23][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-15 15:51:23,639][ceph23][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-15 15:51:23,639][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-15 15:51:23,639][ceph23][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 15:51:23,639][ceph23][WARNING] backup header from main header.
[2016-07-15 15:51:23,639][ceph23][WARNING] 
[2016-07-15 15:51:23,640][ceph23][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 15:51:23,640][ceph23][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 15:51:23,640][ceph23][WARNING] 
[2016-07-15 15:51:23,640][ceph23][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 15:51:23,640][ceph23][WARNING] 
[2016-07-15 15:51:24,656][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 15:51:24,657][ceph23][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 15:51:24,657][ceph23][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 15:51:24,657][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 15:51:24,657][ceph23][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 15:51:24,657][ceph23][DEBUG ] other utilities.
[2016-07-15 15:51:24,657][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-15 15:51:25,673][ceph23][DEBUG ] Creating new GPT entries.
[2016-07-15 15:51:25,674][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 15:51:25,674][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-15 15:51:25,674][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 15:51:25,675][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 15:51:25,675][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 15:51:25,678][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 15:51:25,694][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 15:51:25,710][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 15:51:25,725][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 15:51:25,729][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 15:51:25,745][ceph23][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-15 15:51:25,745][ceph23][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-15 15:51:25,745][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:ae01e5a9-2d19-48fd-8924-9d944814b2a3 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-15 15:51:26,761][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 15:51:26,764][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 15:51:26,765][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 15:51:26,929][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 15:51:26,993][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/ae01e5a9-2d19-48fd-8924-9d944814b2a3
[2016-07-15 15:51:26,993][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/ae01e5a9-2d19-48fd-8924-9d944814b2a3
[2016-07-15 15:51:26,993][ceph23][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-15 15:51:26,993][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:42314eff-7422-4926-a1d0-f95b888e563c --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-15 15:51:28,009][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 15:51:28,010][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-15 15:51:28,010][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 15:51:28,274][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 15:51:28,306][ceph23][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-15 15:51:28,307][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-15 15:51:28,471][ceph23][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=1638335 blks
[2016-07-15 15:51:28,471][ceph23][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 15:51:28,471][ceph23][DEBUG ] data     =                       bsize=4096   blocks=6553339, imaxpct=25
[2016-07-15 15:51:28,471][ceph23][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 15:51:28,471][ceph23][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 15:51:28,471][ceph23][DEBUG ] log      =internal log           bsize=4096   blocks=3199, version=2
[2016-07-15 15:51:28,472][ceph23][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 15:51:28,472][ceph23][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 15:51:28,472][ceph23][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.D_aEgJ with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 15:51:28,472][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.D_aEgJ
[2016-07-15 15:51:28,472][ceph23][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.D_aEgJ
[2016-07-15 15:51:28,472][ceph23][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.D_aEgJ/journal -> /dev/disk/by-partuuid/ae01e5a9-2d19-48fd-8924-9d944814b2a3
[2016-07-15 15:51:28,504][ceph23][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.D_aEgJ
[2016-07-15 15:51:28,504][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.D_aEgJ
[2016-07-15 15:51:28,520][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-15 15:51:29,586][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 15:51:29,587][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 15:51:29,587][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 15:51:36,360][ceph23][INFO  ] checking OSD status...
[2016-07-15 15:51:36,360][ceph23][DEBUG ] find the location of an executable
[2016-07-15 15:51:36,363][ceph23][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 15:51:36,578][ceph_deploy.osd][DEBUG ] Host ceph23 is now ready for osd use.
[2016-07-15 15:51:37,288][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 15:51:37,289][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 15:51:37,305][ceph23][DEBUG ] detect machine type
[2016-07-15 15:51:37,309][ceph23][DEBUG ] find the location of an executable
[2016-07-15 15:51:37,311][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:51:37,328][ceph23][DEBUG ] find the location of an executable
[2016-07-15 15:51:37,330][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 15:51:37,330][ceph_deploy.osd][DEBUG ] Preparing host ceph23 disk /dev/vdc journal None activate True
[2016-07-15 15:51:37,330][ceph23][DEBUG ] find the location of an executable
[2016-07-15 15:51:37,332][ceph23][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-15 15:51:37,399][ceph23][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-15 15:51:37,400][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-15 15:51:37,400][ceph23][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 15:51:37,400][ceph23][WARNING] backup header from main header.
[2016-07-15 15:51:37,400][ceph23][WARNING] 
[2016-07-15 15:51:37,401][ceph23][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 15:51:37,401][ceph23][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 15:51:37,401][ceph23][WARNING] 
[2016-07-15 15:51:37,401][ceph23][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 15:51:37,401][ceph23][WARNING] 
[2016-07-15 15:51:38,417][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 15:51:38,417][ceph23][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 15:51:38,417][ceph23][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 15:51:38,418][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 15:51:38,418][ceph23][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 15:51:38,418][ceph23][DEBUG ] other utilities.
[2016-07-15 15:51:38,418][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-15 15:51:39,434][ceph23][DEBUG ] Creating new GPT entries.
[2016-07-15 15:51:39,434][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 15:51:39,435][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-15 15:51:39,435][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 15:51:39,450][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 15:51:39,466][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 15:51:39,482][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 15:51:39,489][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 15:51:39,505][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 15:51:39,521][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 15:51:39,537][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 15:51:39,544][ceph23][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-15 15:51:39,545][ceph23][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-15 15:51:39,545][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:22367a2e-6176-4cdb-8f92-969717731cdf --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-15 15:51:40,561][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 15:51:40,561][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 15:51:40,562][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 15:51:40,726][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 15:51:40,790][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/22367a2e-6176-4cdb-8f92-969717731cdf
[2016-07-15 15:51:40,790][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/22367a2e-6176-4cdb-8f92-969717731cdf
[2016-07-15 15:51:40,791][ceph23][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-15 15:51:40,791][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:7103550a-f624-4375-a0d6-ddfc985c6bc9 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-15 15:51:41,807][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 15:51:41,808][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-15 15:51:41,808][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 15:51:42,073][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 15:51:42,105][ceph23][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-15 15:51:42,105][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-15 15:51:42,269][ceph23][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=1638335 blks
[2016-07-15 15:51:42,269][ceph23][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 15:51:42,269][ceph23][DEBUG ] data     =                       bsize=4096   blocks=6553339, imaxpct=25
[2016-07-15 15:51:42,270][ceph23][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 15:51:42,270][ceph23][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 15:51:42,270][ceph23][DEBUG ] log      =internal log           bsize=4096   blocks=3199, version=2
[2016-07-15 15:51:42,270][ceph23][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 15:51:42,270][ceph23][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 15:51:42,270][ceph23][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt.mngnRl with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 15:51:42,270][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt.mngnRl
[2016-07-15 15:51:42,286][ceph23][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.mngnRl
[2016-07-15 15:51:42,286][ceph23][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.mngnRl/journal -> /dev/disk/by-partuuid/22367a2e-6176-4cdb-8f92-969717731cdf
[2016-07-15 15:51:42,318][ceph23][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.mngnRl
[2016-07-15 15:51:42,319][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.mngnRl
[2016-07-15 15:51:42,350][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-15 15:51:43,417][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 15:51:43,417][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 15:51:43,417][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 15:51:49,990][ceph23][INFO  ] checking OSD status...
[2016-07-15 15:51:49,990][ceph23][DEBUG ] find the location of an executable
[2016-07-15 15:51:49,993][ceph23][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 15:51:50,160][ceph_deploy.osd][DEBUG ] Host ceph23 is now ready for osd use.
[2016-07-15 15:51:50,260][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 15:51:50,261][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf admin ceph21 ceph22 ceph23
[2016-07-15 15:51:50,261][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 15:51:50,261][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 15:51:50,261][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 15:51:50,261][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-15 15:51:50,261][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 15:51:50,261][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f01402445a8>
[2016-07-15 15:51:50,262][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 15:51:50,262][ceph_deploy.cli][INFO  ]  client                        : ['ceph21', 'ceph22', 'ceph23']
[2016-07-15 15:51:50,262][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f0140b667d0>
[2016-07-15 15:51:50,262][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 15:51:50,262][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 15:51:50,263][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph21
[2016-07-15 15:51:50,946][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 15:51:50,948][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 15:51:50,965][ceph21][DEBUG ] detect machine type
[2016-07-15 15:51:50,969][ceph21][DEBUG ] find the location of an executable
[2016-07-15 15:51:50,972][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:51:50,991][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 15:51:50,994][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph22
[2016-07-15 15:51:51,677][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 15:51:51,678][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 15:51:51,696][ceph22][DEBUG ] detect machine type
[2016-07-15 15:51:51,700][ceph22][DEBUG ] find the location of an executable
[2016-07-15 15:51:51,702][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:51:51,711][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 15:51:51,713][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph23
[2016-07-15 15:51:52,444][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 15:51:52,445][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 15:51:52,462][ceph23][DEBUG ] detect machine type
[2016-07-15 15:51:52,466][ceph23][DEBUG ] find the location of an executable
[2016-07-15 15:51:52,468][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:51:52,485][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 15:59:35,137][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 15:59:35,138][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph21
[2016-07-15 15:59:35,138][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 15:59:35,138][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 15:59:35,138][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 15:59:35,138][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 15:59:35,139][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 15:59:35,139][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fac3de04b00>
[2016-07-15 15:59:35,139][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 15:59:35,139][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-15 15:59:35,139][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fac3e71b1b8>
[2016-07-15 15:59:35,139][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 15:59:35,139][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 15:59:35,139][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 15:59:35,140][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 15:59:35,140][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph21
[2016-07-15 15:59:35,140][ceph_deploy.install][DEBUG ] Detecting platform for host ceph21 ...
[2016-07-15 15:59:35,814][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 15:59:35,815][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 15:59:35,831][ceph21][DEBUG ] detect machine type
[2016-07-15 15:59:35,835][ceph21][DEBUG ] find the location of an executable
[2016-07-15 15:59:35,837][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:59:35,849][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 15:59:35,849][ceph21][INFO  ] Purging Ceph on ceph21
[2016-07-15 15:59:35,850][ceph21][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 15:59:36,218][ceph21][DEBUG ] Reading package lists...
[2016-07-15 15:59:36,533][ceph21][DEBUG ] Building dependency tree...
[2016-07-15 15:59:36,533][ceph21][DEBUG ] Reading state information...
[2016-07-15 15:59:36,747][ceph21][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 15:59:36,748][ceph21][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 15:59:36,748][ceph21][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 15:59:36,748][ceph21][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 15:59:36,748][ceph21][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 15:59:36,748][ceph21][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-15 15:59:36,748][ceph21][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libnspr4
[2016-07-15 15:59:36,749][ceph21][DEBUG ]   libnss3 libnss3-nssdb libxslt1.1 xmlstarlet
[2016-07-15 15:59:36,749][ceph21][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-15 15:59:36,752][ceph21][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 216 not upgraded.
[2016-07-15 15:59:36,855][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 15:59:36,855][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph21
[2016-07-15 15:59:36,856][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 15:59:36,856][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 15:59:36,856][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 15:59:36,856][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 15:59:36,856][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 15:59:36,856][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fcd3293a1b8>
[2016-07-15 15:59:36,856][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 15:59:36,856][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-15 15:59:36,856][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7fcd33249230>
[2016-07-15 15:59:36,856][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 15:59:36,856][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 15:59:36,856][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph21
[2016-07-15 15:59:37,561][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 15:59:37,562][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 15:59:37,578][ceph21][DEBUG ] detect machine type
[2016-07-15 15:59:37,582][ceph21][DEBUG ] find the location of an executable
[2016-07-15 15:59:37,585][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:59:37,604][ceph21][DEBUG ] find the location of an executable
[2016-07-15 15:59:38,301][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 15:59:38,302][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 15:59:38,319][ceph21][DEBUG ] detect machine type
[2016-07-15 15:59:38,323][ceph21][DEBUG ] find the location of an executable
[2016-07-15 15:59:38,326][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:59:38,335][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 15:59:38,335][ceph21][INFO  ] purging data on ceph21
[2016-07-15 15:59:38,337][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 15:59:38,349][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 15:59:48,101][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 15:59:48,101][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph22
[2016-07-15 15:59:48,101][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 15:59:48,102][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 15:59:48,102][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 15:59:48,102][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 15:59:48,102][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 15:59:48,102][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f58bb15fb00>
[2016-07-15 15:59:48,102][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 15:59:48,102][ceph_deploy.cli][INFO  ]  host                          : ['ceph22']
[2016-07-15 15:59:48,102][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f58bba761b8>
[2016-07-15 15:59:48,103][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 15:59:48,103][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 15:59:48,103][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 15:59:48,103][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 15:59:48,103][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph22
[2016-07-15 15:59:48,103][ceph_deploy.install][DEBUG ] Detecting platform for host ceph22 ...
[2016-07-15 15:59:48,800][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 15:59:48,801][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 15:59:48,818][ceph22][DEBUG ] detect machine type
[2016-07-15 15:59:48,822][ceph22][DEBUG ] find the location of an executable
[2016-07-15 15:59:48,824][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:59:48,836][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 15:59:48,836][ceph22][INFO  ] Purging Ceph on ceph22
[2016-07-15 15:59:48,837][ceph22][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 15:59:49,355][ceph22][DEBUG ] Reading package lists...
[2016-07-15 15:59:49,670][ceph22][DEBUG ] Building dependency tree...
[2016-07-15 15:59:49,671][ceph22][DEBUG ] Reading state information...
[2016-07-15 15:59:49,985][ceph22][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 15:59:49,985][ceph22][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 15:59:49,985][ceph22][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 15:59:49,986][ceph22][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 15:59:49,986][ceph22][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 15:59:49,986][ceph22][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 218 not upgraded.
[2016-07-15 15:59:50,081][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 15:59:50,081][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph22
[2016-07-15 15:59:50,082][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 15:59:50,082][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 15:59:50,082][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 15:59:50,082][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 15:59:50,082][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 15:59:50,082][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f46516801b8>
[2016-07-15 15:59:50,082][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 15:59:50,083][ceph_deploy.cli][INFO  ]  host                          : ['ceph22']
[2016-07-15 15:59:50,083][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f4651f8f230>
[2016-07-15 15:59:50,083][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 15:59:50,083][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 15:59:50,083][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph22
[2016-07-15 15:59:50,798][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 15:59:50,798][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 15:59:50,815][ceph22][DEBUG ] detect machine type
[2016-07-15 15:59:50,819][ceph22][DEBUG ] find the location of an executable
[2016-07-15 15:59:50,822][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:59:50,841][ceph22][DEBUG ] find the location of an executable
[2016-07-15 15:59:51,513][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 15:59:51,514][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 15:59:51,530][ceph22][DEBUG ] detect machine type
[2016-07-15 15:59:51,534][ceph22][DEBUG ] find the location of an executable
[2016-07-15 15:59:51,537][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 15:59:51,545][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 15:59:51,546][ceph22][INFO  ] purging data on ceph22
[2016-07-15 15:59:51,547][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 15:59:51,558][ceph22][WARNING] OSDs may still be mounted, trying to unmount them
[2016-07-15 15:59:51,559][ceph22][INFO  ] Running command: find /var/lib/ceph -mindepth 1 -maxdepth 2 -type d -exec umount {} ;
[2016-07-15 15:59:51,572][ceph22][WARNING] umount: /var/lib/ceph/osd: not mounted
[2016-07-15 15:59:51,637][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 15:59:51,650][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 16:00:02,116][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 16:00:02,117][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph23
[2016-07-15 16:00:02,117][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 16:00:02,117][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 16:00:02,117][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 16:00:02,117][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 16:00:02,117][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 16:00:02,118][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fd68a230b00>
[2016-07-15 16:00:02,118][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 16:00:02,118][ceph_deploy.cli][INFO  ]  host                          : ['ceph23']
[2016-07-15 16:00:02,118][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fd68ab471b8>
[2016-07-15 16:00:02,118][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 16:00:02,118][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 16:00:02,118][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 16:00:02,118][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 16:00:02,119][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph23
[2016-07-15 16:00:02,119][ceph_deploy.install][DEBUG ] Detecting platform for host ceph23 ...
[2016-07-15 16:00:02,808][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 16:00:02,808][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 16:00:02,825][ceph23][DEBUG ] detect machine type
[2016-07-15 16:00:02,831][ceph23][DEBUG ] find the location of an executable
[2016-07-15 16:00:02,833][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:00:02,845][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 16:00:02,846][ceph23][INFO  ] Purging Ceph on ceph23
[2016-07-15 16:00:02,847][ceph23][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 16:00:03,215][ceph23][DEBUG ] Reading package lists...
[2016-07-15 16:00:03,529][ceph23][DEBUG ] Building dependency tree...
[2016-07-15 16:00:03,529][ceph23][DEBUG ] Reading state information...
[2016-07-15 16:00:03,743][ceph23][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 16:00:03,744][ceph23][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 16:00:03,744][ceph23][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 16:00:03,744][ceph23][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 16:00:03,744][ceph23][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 16:00:03,744][ceph23][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-15 16:00:03,744][ceph23][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libxslt1.1
[2016-07-15 16:00:03,744][ceph23][DEBUG ]   xmlstarlet
[2016-07-15 16:00:03,744][ceph23][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-15 16:00:03,776][ceph23][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 218 not upgraded.
[2016-07-15 16:00:03,875][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 16:00:03,876][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph23
[2016-07-15 16:00:03,876][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 16:00:03,876][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 16:00:03,876][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 16:00:03,877][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 16:00:03,877][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 16:00:03,877][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f1faf5481b8>
[2016-07-15 16:00:03,877][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 16:00:03,877][ceph_deploy.cli][INFO  ]  host                          : ['ceph23']
[2016-07-15 16:00:03,877][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f1fafe57230>
[2016-07-15 16:00:03,877][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 16:00:03,878][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 16:00:03,878][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph23
[2016-07-15 16:00:04,604][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 16:00:04,604][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 16:00:04,621][ceph23][DEBUG ] detect machine type
[2016-07-15 16:00:04,624][ceph23][DEBUG ] find the location of an executable
[2016-07-15 16:00:04,627][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:00:04,646][ceph23][DEBUG ] find the location of an executable
[2016-07-15 16:00:05,375][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 16:00:05,377][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 16:00:05,395][ceph23][DEBUG ] detect machine type
[2016-07-15 16:00:05,399][ceph23][DEBUG ] find the location of an executable
[2016-07-15 16:00:05,401][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:00:05,419][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 16:00:05,419][ceph23][INFO  ] purging data on ceph23
[2016-07-15 16:00:05,421][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 16:00:05,432][ceph23][WARNING] OSDs may still be mounted, trying to unmount them
[2016-07-15 16:00:05,434][ceph23][INFO  ] Running command: find /var/lib/ceph -mindepth 1 -maxdepth 2 -type d -exec umount {} ;
[2016-07-15 16:00:05,455][ceph23][WARNING] umount: /var/lib/ceph/osd: not mounted
[2016-07-15 16:00:05,521][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 16:00:05,533][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 16:01:03,425][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 16:01:03,425][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy new ceph21
[2016-07-15 16:01:03,425][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 16:01:03,425][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 16:01:03,425][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f0700514410>
[2016-07-15 16:01:03,425][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 16:01:03,425][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 16:01:03,425][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 16:01:03,426][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f06ffc76ef0>
[2016-07-15 16:01:03,426][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 16:01:03,426][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2016-07-15 16:01:03,426][ceph_deploy.cli][INFO  ]  mon                           : ['ceph21']
[2016-07-15 16:01:03,426][ceph_deploy.cli][INFO  ]  public_network                : None
[2016-07-15 16:01:03,426][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 16:01:03,426][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2016-07-15 16:01:03,426][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 16:01:03,426][ceph_deploy.cli][INFO  ]  fsid                          : None
[2016-07-15 16:01:03,426][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2016-07-15 16:01:03,426][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2016-07-15 16:01:03,454][ceph21][DEBUG ] connected to host: cephAdmin 
[2016-07-15 16:01:03,458][ceph21][INFO  ] Running command: ssh -CT -o BatchMode=yes ceph21
[2016-07-15 16:01:04,549][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 16:01:04,551][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 16:01:04,567][ceph21][DEBUG ] detect machine type
[2016-07-15 16:01:04,571][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:01:04,573][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:01:04,582][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:01:04,585][ceph21][INFO  ] Running command: /bin/ip link show
[2016-07-15 16:01:04,595][ceph21][INFO  ] Running command: /bin/ip addr show
[2016-07-15 16:01:04,604][ceph21][DEBUG ] IP addresses found: ['10.1.0.44']
[2016-07-15 16:01:04,605][ceph_deploy.new][DEBUG ] Resolving host ceph21
[2016-07-15 16:01:04,605][ceph_deploy.new][DEBUG ] Monitor ceph21 at 10.1.0.44
[2016-07-15 16:01:04,605][ceph_deploy.new][DEBUG ] Monitor initial members are ['ceph21']
[2016-07-15 16:01:04,605][ceph_deploy.new][DEBUG ] Monitor addrs are ['10.1.0.44']
[2016-07-15 16:01:04,605][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2016-07-15 16:01:04,605][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2016-07-15 16:01:04,606][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2016-07-15 16:01:24,672][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 16:01:24,673][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy mon create-initial
[2016-07-15 16:01:24,673][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 16:01:24,673][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 16:01:24,673][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 16:01:24,673][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 16:01:24,673][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2016-07-15 16:01:24,673][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 16:01:24,673][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f52ce3c0290>
[2016-07-15 16:01:24,673][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 16:01:24,674][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f52ce3a16e0>
[2016-07-15 16:01:24,674][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 16:01:24,674][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 16:01:24,674][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2016-07-15 16:01:24,676][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts ceph21
[2016-07-15 16:01:24,676][ceph_deploy.mon][DEBUG ] detecting platform for host ceph21 ...
[2016-07-15 16:01:25,388][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 16:01:25,390][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 16:01:25,405][ceph21][DEBUG ] detect machine type
[2016-07-15 16:01:25,409][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:01:25,411][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:01:25,422][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:01:25,423][ceph_deploy.mon][INFO  ] distro info: Ubuntu 14.04 trusty
[2016-07-15 16:01:25,423][ceph21][DEBUG ] determining if provided host has same hostname in remote
[2016-07-15 16:01:25,423][ceph21][DEBUG ] get remote short hostname
[2016-07-15 16:01:25,424][ceph21][DEBUG ] deploying mon to ceph21
[2016-07-15 16:01:25,424][ceph21][DEBUG ] get remote short hostname
[2016-07-15 16:01:25,425][ceph21][DEBUG ] remote hostname: ceph21
[2016-07-15 16:01:25,427][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 16:01:25,429][ceph21][DEBUG ] create the mon path if it does not exist
[2016-07-15 16:01:25,430][ceph21][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-15 16:01:25,431][ceph21][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-15 16:01:25,431][ceph21][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 16:01:25,432][ceph21][DEBUG ] create the monitor keyring file
[2016-07-15 16:01:25,434][ceph21][INFO  ] Running command: ceph-mon --cluster ceph --mkfs -i ceph21 --keyring /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 16:01:25,468][ceph21][DEBUG ] ceph-mon: mon.noname-a 10.1.0.44:6789/0 is local, renaming to mon.ceph21
[2016-07-15 16:01:25,469][ceph21][DEBUG ] ceph-mon: set fsid to e2d8a956-c848-4819-a7fe-f75b8f3e350b
[2016-07-15 16:01:25,469][ceph21][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-ceph21 for mon.ceph21
[2016-07-15 16:01:25,469][ceph21][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 16:01:25,470][ceph21][DEBUG ] create a done file to avoid re-doing the mon deployment
[2016-07-15 16:01:25,471][ceph21][DEBUG ] create the init path if it does not exist
[2016-07-15 16:01:25,473][ceph21][INFO  ] Running command: initctl emit ceph-mon cluster=ceph id=ceph21
[2016-07-15 16:01:27,496][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 16:01:27,561][ceph21][DEBUG ] ********************************************************************************
[2016-07-15 16:01:27,561][ceph21][DEBUG ] status for monitor: mon.ceph21
[2016-07-15 16:01:27,562][ceph21][DEBUG ] {
[2016-07-15 16:01:27,562][ceph21][DEBUG ]   "election_epoch": 2, 
[2016-07-15 16:01:27,562][ceph21][DEBUG ]   "extra_probe_peers": [], 
[2016-07-15 16:01:27,562][ceph21][DEBUG ]   "monmap": {
[2016-07-15 16:01:27,562][ceph21][DEBUG ]     "created": "0.000000", 
[2016-07-15 16:01:27,562][ceph21][DEBUG ]     "epoch": 1, 
[2016-07-15 16:01:27,563][ceph21][DEBUG ]     "fsid": "e2d8a956-c848-4819-a7fe-f75b8f3e350b", 
[2016-07-15 16:01:27,563][ceph21][DEBUG ]     "modified": "0.000000", 
[2016-07-15 16:01:27,563][ceph21][DEBUG ]     "mons": [
[2016-07-15 16:01:27,563][ceph21][DEBUG ]       {
[2016-07-15 16:01:27,563][ceph21][DEBUG ]         "addr": "10.1.0.44:6789/0", 
[2016-07-15 16:01:27,563][ceph21][DEBUG ]         "name": "ceph21", 
[2016-07-15 16:01:27,563][ceph21][DEBUG ]         "rank": 0
[2016-07-15 16:01:27,563][ceph21][DEBUG ]       }
[2016-07-15 16:01:27,564][ceph21][DEBUG ]     ]
[2016-07-15 16:01:27,564][ceph21][DEBUG ]   }, 
[2016-07-15 16:01:27,564][ceph21][DEBUG ]   "name": "ceph21", 
[2016-07-15 16:01:27,564][ceph21][DEBUG ]   "outside_quorum": [], 
[2016-07-15 16:01:27,564][ceph21][DEBUG ]   "quorum": [
[2016-07-15 16:01:27,564][ceph21][DEBUG ]     0
[2016-07-15 16:01:27,564][ceph21][DEBUG ]   ], 
[2016-07-15 16:01:27,564][ceph21][DEBUG ]   "rank": 0, 
[2016-07-15 16:01:27,565][ceph21][DEBUG ]   "state": "leader", 
[2016-07-15 16:01:27,565][ceph21][DEBUG ]   "sync_provider": []
[2016-07-15 16:01:27,565][ceph21][DEBUG ] }
[2016-07-15 16:01:27,565][ceph21][DEBUG ] ********************************************************************************
[2016-07-15 16:01:27,565][ceph21][INFO  ] monitor: mon.ceph21 is running
[2016-07-15 16:01:27,567][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 16:01:27,632][ceph_deploy.mon][INFO  ] processing monitor mon.ceph21
[2016-07-15 16:01:28,336][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 16:01:28,337][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 16:01:28,355][ceph21][DEBUG ] detect machine type
[2016-07-15 16:01:28,359][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:01:28,362][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:01:28,383][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:01:28,386][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 16:01:28,451][ceph_deploy.mon][INFO  ] mon.ceph21 monitor has reached quorum!
[2016-07-15 16:01:28,452][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2016-07-15 16:01:28,453][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2016-07-15 16:01:28,453][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /etc/ceph/ceph.client.admin.keyring
[2016-07-15 16:01:29,146][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 16:01:29,147][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 16:01:29,164][ceph21][DEBUG ] detect machine type
[2016-07-15 16:01:29,168][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:01:29,170][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:01:29,180][ceph21][DEBUG ] fetch remote file
[2016-07-15 16:01:29,181][ceph_deploy.gatherkeys][DEBUG ] Got ceph.client.admin.keyring key from ceph21.
[2016-07-15 16:01:29,181][ceph_deploy.gatherkeys][DEBUG ] Have ceph.mon.keyring
[2016-07-15 16:01:29,181][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-osd/ceph.keyring
[2016-07-15 16:01:29,842][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 16:01:29,843][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 16:01:29,859][ceph21][DEBUG ] detect machine type
[2016-07-15 16:01:29,863][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:01:29,865][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:01:29,874][ceph21][DEBUG ] fetch remote file
[2016-07-15 16:01:29,875][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-osd.keyring key from ceph21.
[2016-07-15 16:01:29,875][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-mds/ceph.keyring
[2016-07-15 16:01:30,556][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 16:01:30,557][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 16:01:30,572][ceph21][DEBUG ] detect machine type
[2016-07-15 16:01:30,576][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:01:30,579][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:01:30,588][ceph21][DEBUG ] fetch remote file
[2016-07-15 16:01:30,589][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-mds.keyring key from ceph21.
[2016-07-15 16:01:30,589][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-rgw/ceph.keyring
[2016-07-15 16:01:31,295][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 16:01:31,297][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 16:01:31,318][ceph21][DEBUG ] detect machine type
[2016-07-15 16:01:31,322][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:01:31,325][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:01:31,334][ceph21][DEBUG ] fetch remote file
[2016-07-15 16:01:31,335][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-rgw.keyring key from ceph21.
[2016-07-15 16:01:52,065][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 16:01:52,065][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf osd create --zap-disk ceph22:/dev/vdb ceph22:/dev/vdc ceph23:/dev/vdb ceph23:/dev/vdc
[2016-07-15 16:01:52,066][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 16:01:52,066][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 16:01:52,066][ceph_deploy.cli][INFO  ]  disk                          : [('ceph22', '/dev/vdb', None), ('ceph22', '/dev/vdc', None), ('ceph23', '/dev/vdb', None), ('ceph23', '/dev/vdc', None)]
[2016-07-15 16:01:52,066][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2016-07-15 16:01:52,066][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 16:01:52,066][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2016-07-15 16:01:52,066][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-15 16:01:52,066][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-15 16:01:52,066][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2016-07-15 16:01:52,067][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 16:01:52,067][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb1d55ae1b8>
[2016-07-15 16:01:52,067][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 16:01:52,067][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2016-07-15 16:01:52,067][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fb1d557f578>
[2016-07-15 16:01:52,067][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 16:01:52,067][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 16:01:52,067][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2016-07-15 16:01:52,068][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks ceph22:/dev/vdb: ceph22:/dev/vdc: ceph23:/dev/vdb: ceph23:/dev/vdc:
[2016-07-15 16:01:52,760][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 16:01:52,760][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 16:01:52,777][ceph22][DEBUG ] detect machine type
[2016-07-15 16:01:52,781][ceph22][DEBUG ] find the location of an executable
[2016-07-15 16:01:52,784][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:01:52,803][ceph22][DEBUG ] find the location of an executable
[2016-07-15 16:01:52,804][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 16:01:52,805][ceph_deploy.osd][DEBUG ] Deploying osd to ceph22
[2016-07-15 16:01:52,805][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 16:01:52,808][ceph22][WARNING] osd keyring does not exist yet, creating one
[2016-07-15 16:01:52,808][ceph22][DEBUG ] create a keyring file
[2016-07-15 16:01:52,809][ceph_deploy.osd][DEBUG ] Preparing host ceph22 disk /dev/vdb journal None activate True
[2016-07-15 16:01:52,809][ceph22][DEBUG ] find the location of an executable
[2016-07-15 16:01:52,813][ceph22][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-15 16:01:52,879][ceph22][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-15 16:01:52,880][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-15 16:01:52,887][ceph22][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 16:01:52,888][ceph22][WARNING] backup header from main header.
[2016-07-15 16:01:52,888][ceph22][WARNING] 
[2016-07-15 16:01:52,888][ceph22][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 16:01:52,889][ceph22][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 16:01:52,889][ceph22][WARNING] 
[2016-07-15 16:01:52,889][ceph22][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 16:01:52,890][ceph22][WARNING] 
[2016-07-15 16:01:53,959][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 16:01:53,959][ceph22][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 16:01:53,959][ceph22][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 16:01:53,959][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 16:01:53,960][ceph22][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 16:01:53,960][ceph22][DEBUG ] other utilities.
[2016-07-15 16:01:53,960][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-15 16:01:54,926][ceph22][DEBUG ] Creating new GPT entries.
[2016-07-15 16:01:54,926][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 16:01:54,927][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-15 16:01:54,927][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 16:01:54,942][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 16:01:54,974][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 16:01:54,974][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 16:01:54,990][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 16:01:55,006][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 16:01:55,021][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 16:01:55,029][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 16:01:55,045][ceph22][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-15 16:01:55,045][ceph22][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-15 16:01:55,045][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:515f5f23-49ea-4e09-9c3a-322748659325 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-15 16:01:56,061][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 16:01:56,061][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 16:01:56,061][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 16:01:56,225][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 16:01:56,289][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/515f5f23-49ea-4e09-9c3a-322748659325
[2016-07-15 16:01:56,289][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/515f5f23-49ea-4e09-9c3a-322748659325
[2016-07-15 16:01:56,290][ceph22][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-15 16:01:56,290][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:103e69f9-7193-4e41-8e28-b2b62bedb48d --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-15 16:01:57,305][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 16:01:57,306][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-15 16:01:57,306][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 16:01:57,570][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 16:01:57,602][ceph22][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-15 16:01:57,602][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-15 16:01:57,766][ceph22][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=1638335 blks
[2016-07-15 16:01:57,766][ceph22][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 16:01:57,767][ceph22][DEBUG ] data     =                       bsize=4096   blocks=6553339, imaxpct=25
[2016-07-15 16:01:57,767][ceph22][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 16:01:57,767][ceph22][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 16:01:57,767][ceph22][DEBUG ] log      =internal log           bsize=4096   blocks=3199, version=2
[2016-07-15 16:01:57,767][ceph22][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 16:01:57,767][ceph22][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.ejlqaf with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 16:01:57,767][ceph22][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 16:01:57,768][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.ejlqaf
[2016-07-15 16:01:57,768][ceph22][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.ejlqaf
[2016-07-15 16:01:57,768][ceph22][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.ejlqaf/journal -> /dev/disk/by-partuuid/515f5f23-49ea-4e09-9c3a-322748659325
[2016-07-15 16:01:57,800][ceph22][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.ejlqaf
[2016-07-15 16:01:57,800][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.ejlqaf
[2016-07-15 16:01:57,864][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-15 16:01:58,880][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 16:01:58,880][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 16:01:58,880][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 16:02:04,900][ceph22][INFO  ] checking OSD status...
[2016-07-15 16:02:04,901][ceph22][DEBUG ] find the location of an executable
[2016-07-15 16:02:04,904][ceph22][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 16:02:05,119][ceph_deploy.osd][DEBUG ] Host ceph22 is now ready for osd use.
[2016-07-15 16:02:05,792][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 16:02:05,793][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 16:02:05,810][ceph22][DEBUG ] detect machine type
[2016-07-15 16:02:05,814][ceph22][DEBUG ] find the location of an executable
[2016-07-15 16:02:05,816][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:02:05,825][ceph22][DEBUG ] find the location of an executable
[2016-07-15 16:02:05,827][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 16:02:05,827][ceph_deploy.osd][DEBUG ] Preparing host ceph22 disk /dev/vdc journal None activate True
[2016-07-15 16:02:05,827][ceph22][DEBUG ] find the location of an executable
[2016-07-15 16:02:05,829][ceph22][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-15 16:02:05,896][ceph22][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-15 16:02:05,896][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-15 16:02:05,896][ceph22][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 16:02:05,896][ceph22][WARNING] backup header from main header.
[2016-07-15 16:02:05,896][ceph22][WARNING] 
[2016-07-15 16:02:05,897][ceph22][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 16:02:05,897][ceph22][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 16:02:05,897][ceph22][WARNING] 
[2016-07-15 16:02:05,897][ceph22][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 16:02:05,897][ceph22][WARNING] 
[2016-07-15 16:02:06,963][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 16:02:06,963][ceph22][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 16:02:06,964][ceph22][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 16:02:06,964][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 16:02:06,964][ceph22][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 16:02:06,964][ceph22][DEBUG ] other utilities.
[2016-07-15 16:02:06,964][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-15 16:02:07,980][ceph22][DEBUG ] Creating new GPT entries.
[2016-07-15 16:02:07,981][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 16:02:07,981][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-15 16:02:07,981][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 16:02:07,981][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 16:02:07,981][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 16:02:07,989][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 16:02:08,004][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 16:02:08,020][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 16:02:08,036][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 16:02:08,052][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 16:02:08,055][ceph22][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-15 16:02:08,056][ceph22][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-15 16:02:08,056][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:6f404c06-05ef-4032-aaa3-e0ef58d909c1 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-15 16:02:09,072][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 16:02:09,073][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 16:02:09,073][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 16:02:09,237][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 16:02:09,302][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/6f404c06-05ef-4032-aaa3-e0ef58d909c1
[2016-07-15 16:02:09,302][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/6f404c06-05ef-4032-aaa3-e0ef58d909c1
[2016-07-15 16:02:09,302][ceph22][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-15 16:02:09,302][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:6c808808-0596-40ab-9624-04e861e6c9de --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-15 16:02:10,319][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 16:02:10,319][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-15 16:02:10,319][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 16:02:10,583][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 16:02:10,615][ceph22][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-15 16:02:10,616][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-15 16:02:10,780][ceph22][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=1638335 blks
[2016-07-15 16:02:10,780][ceph22][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 16:02:10,780][ceph22][DEBUG ] data     =                       bsize=4096   blocks=6553339, imaxpct=25
[2016-07-15 16:02:10,780][ceph22][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 16:02:10,781][ceph22][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 16:02:10,781][ceph22][DEBUG ] log      =internal log           bsize=4096   blocks=3199, version=2
[2016-07-15 16:02:10,781][ceph22][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 16:02:10,781][ceph22][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 16:02:10,781][ceph22][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt.g4Xffs with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 16:02:10,781][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt.g4Xffs
[2016-07-15 16:02:10,781][ceph22][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.g4Xffs
[2016-07-15 16:02:10,782][ceph22][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.g4Xffs/journal -> /dev/disk/by-partuuid/6f404c06-05ef-4032-aaa3-e0ef58d909c1
[2016-07-15 16:02:10,813][ceph22][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.g4Xffs
[2016-07-15 16:02:10,814][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.g4Xffs
[2016-07-15 16:02:10,829][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-15 16:02:11,846][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 16:02:11,846][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 16:02:11,846][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 16:02:18,619][ceph22][INFO  ] checking OSD status...
[2016-07-15 16:02:18,619][ceph22][DEBUG ] find the location of an executable
[2016-07-15 16:02:18,623][ceph22][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 16:02:18,838][ceph_deploy.osd][DEBUG ] Host ceph22 is now ready for osd use.
[2016-07-15 16:02:19,553][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 16:02:19,555][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 16:02:19,572][ceph23][DEBUG ] detect machine type
[2016-07-15 16:02:19,575][ceph23][DEBUG ] find the location of an executable
[2016-07-15 16:02:19,578][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:02:19,587][ceph23][DEBUG ] find the location of an executable
[2016-07-15 16:02:19,588][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 16:02:19,588][ceph_deploy.osd][DEBUG ] Deploying osd to ceph23
[2016-07-15 16:02:19,589][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 16:02:19,591][ceph23][WARNING] osd keyring does not exist yet, creating one
[2016-07-15 16:02:19,591][ceph23][DEBUG ] create a keyring file
[2016-07-15 16:02:19,593][ceph_deploy.osd][DEBUG ] Preparing host ceph23 disk /dev/vdb journal None activate True
[2016-07-15 16:02:19,593][ceph23][DEBUG ] find the location of an executable
[2016-07-15 16:02:19,595][ceph23][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-15 16:02:19,664][ceph23][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-15 16:02:19,664][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-15 16:02:19,664][ceph23][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 16:02:19,664][ceph23][WARNING] backup header from main header.
[2016-07-15 16:02:19,664][ceph23][WARNING] 
[2016-07-15 16:02:19,664][ceph23][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 16:02:19,665][ceph23][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 16:02:19,665][ceph23][WARNING] 
[2016-07-15 16:02:19,665][ceph23][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 16:02:19,665][ceph23][WARNING] 
[2016-07-15 16:02:20,681][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 16:02:20,681][ceph23][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 16:02:20,681][ceph23][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 16:02:20,681][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 16:02:20,682][ceph23][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 16:02:20,682][ceph23][DEBUG ] other utilities.
[2016-07-15 16:02:20,682][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-15 16:02:21,748][ceph23][DEBUG ] Creating new GPT entries.
[2016-07-15 16:02:21,748][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 16:02:21,748][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-15 16:02:21,749][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 16:02:21,749][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 16:02:21,749][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 16:02:21,749][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 16:02:21,757][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 16:02:21,772][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 16:02:21,788][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 16:02:21,804][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 16:02:21,811][ceph23][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-15 16:02:21,812][ceph23][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-15 16:02:21,812][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:5575fc6d-aa66-44e8-837f-fa017e6e78ce --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-15 16:02:22,828][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 16:02:22,828][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 16:02:22,829][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 16:02:23,043][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 16:02:23,043][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/5575fc6d-aa66-44e8-837f-fa017e6e78ce
[2016-07-15 16:02:23,044][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/5575fc6d-aa66-44e8-837f-fa017e6e78ce
[2016-07-15 16:02:23,044][ceph23][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-15 16:02:23,044][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:36ab3796-b399-4666-8878-031f900c76f9 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-15 16:02:24,060][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 16:02:24,061][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-15 16:02:24,061][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 16:02:24,325][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 16:02:24,389][ceph23][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-15 16:02:24,389][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-15 16:02:24,553][ceph23][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=1638335 blks
[2016-07-15 16:02:24,554][ceph23][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 16:02:24,554][ceph23][DEBUG ] data     =                       bsize=4096   blocks=6553339, imaxpct=25
[2016-07-15 16:02:24,554][ceph23][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 16:02:24,554][ceph23][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 16:02:24,554][ceph23][DEBUG ] log      =internal log           bsize=4096   blocks=3199, version=2
[2016-07-15 16:02:24,555][ceph23][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 16:02:24,555][ceph23][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 16:02:24,555][ceph23][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.50zl5L with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 16:02:24,555][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.50zl5L
[2016-07-15 16:02:24,555][ceph23][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.50zl5L
[2016-07-15 16:02:24,555][ceph23][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.50zl5L/journal -> /dev/disk/by-partuuid/5575fc6d-aa66-44e8-837f-fa017e6e78ce
[2016-07-15 16:02:24,571][ceph23][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.50zl5L
[2016-07-15 16:02:24,571][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.50zl5L
[2016-07-15 16:02:24,603][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-15 16:02:25,620][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 16:02:25,621][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 16:02:25,621][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 16:02:32,294][ceph23][INFO  ] checking OSD status...
[2016-07-15 16:02:32,294][ceph23][DEBUG ] find the location of an executable
[2016-07-15 16:02:32,297][ceph23][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 16:02:32,462][ceph_deploy.osd][DEBUG ] Host ceph23 is now ready for osd use.
[2016-07-15 16:02:33,146][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 16:02:33,146][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 16:02:33,168][ceph23][DEBUG ] detect machine type
[2016-07-15 16:02:33,172][ceph23][DEBUG ] find the location of an executable
[2016-07-15 16:02:33,174][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:02:33,183][ceph23][DEBUG ] find the location of an executable
[2016-07-15 16:02:33,184][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 16:02:33,184][ceph_deploy.osd][DEBUG ] Preparing host ceph23 disk /dev/vdc journal None activate True
[2016-07-15 16:02:33,184][ceph23][DEBUG ] find the location of an executable
[2016-07-15 16:02:33,187][ceph23][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-15 16:02:33,304][ceph23][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-15 16:02:33,304][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-15 16:02:33,304][ceph23][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 16:02:33,304][ceph23][WARNING] backup header from main header.
[2016-07-15 16:02:33,304][ceph23][WARNING] 
[2016-07-15 16:02:33,305][ceph23][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 16:02:33,305][ceph23][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 16:02:33,305][ceph23][WARNING] 
[2016-07-15 16:02:33,305][ceph23][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 16:02:33,305][ceph23][WARNING] 
[2016-07-15 16:02:34,321][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 16:02:34,322][ceph23][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 16:02:34,322][ceph23][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 16:02:34,322][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 16:02:34,322][ceph23][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 16:02:34,322][ceph23][DEBUG ] other utilities.
[2016-07-15 16:02:34,323][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-15 16:02:35,339][ceph23][DEBUG ] Creating new GPT entries.
[2016-07-15 16:02:35,340][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 16:02:35,340][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-15 16:02:35,340][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 16:02:35,340][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 16:02:35,356][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 16:02:35,364][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 16:02:35,379][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 16:02:35,395][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 16:02:35,402][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 16:02:35,418][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 16:02:35,426][ceph23][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-15 16:02:35,426][ceph23][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-15 16:02:35,426][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:2f2be230-57fb-4d78-8d40-8ea40217f8cf --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-15 16:02:36,442][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 16:02:36,443][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 16:02:36,443][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 16:02:36,607][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 16:02:36,671][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/2f2be230-57fb-4d78-8d40-8ea40217f8cf
[2016-07-15 16:02:36,671][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/2f2be230-57fb-4d78-8d40-8ea40217f8cf
[2016-07-15 16:02:36,671][ceph23][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-15 16:02:36,672][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:548bb361-d62e-4dd6-982c-279fbe223d86 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-15 16:02:37,688][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 16:02:37,689][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-15 16:02:37,689][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 16:02:37,954][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 16:02:37,986][ceph23][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-15 16:02:37,987][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-15 16:02:38,151][ceph23][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=1638335 blks
[2016-07-15 16:02:38,151][ceph23][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 16:02:38,152][ceph23][DEBUG ] data     =                       bsize=4096   blocks=6553339, imaxpct=25
[2016-07-15 16:02:38,152][ceph23][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 16:02:38,152][ceph23][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 16:02:38,152][ceph23][DEBUG ] log      =internal log           bsize=4096   blocks=3199, version=2
[2016-07-15 16:02:38,153][ceph23][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 16:02:38,153][ceph23][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 16:02:38,153][ceph23][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt._EP7Ug with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 16:02:38,153][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt._EP7Ug
[2016-07-15 16:02:38,153][ceph23][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt._EP7Ug
[2016-07-15 16:02:38,154][ceph23][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt._EP7Ug/journal -> /dev/disk/by-partuuid/2f2be230-57fb-4d78-8d40-8ea40217f8cf
[2016-07-15 16:02:38,185][ceph23][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt._EP7Ug
[2016-07-15 16:02:38,186][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt._EP7Ug
[2016-07-15 16:02:38,217][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-15 16:02:39,234][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 16:02:39,234][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 16:02:39,234][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 16:02:46,007][ceph23][INFO  ] checking OSD status...
[2016-07-15 16:02:46,008][ceph23][DEBUG ] find the location of an executable
[2016-07-15 16:02:46,011][ceph23][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 16:02:46,226][ceph_deploy.osd][DEBUG ] Host ceph23 is now ready for osd use.
[2016-07-15 16:40:30,417][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 16:40:30,417][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph21
[2016-07-15 16:40:30,418][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 16:40:30,418][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 16:40:30,418][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 16:40:30,418][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 16:40:30,418][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 16:40:30,418][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f49b21f7b00>
[2016-07-15 16:40:30,418][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 16:40:30,419][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-15 16:40:30,419][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f49b2b0e1b8>
[2016-07-15 16:40:30,419][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 16:40:30,419][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 16:40:30,419][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 16:40:30,419][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 16:40:30,419][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph21
[2016-07-15 16:40:30,419][ceph_deploy.install][DEBUG ] Detecting platform for host ceph21 ...
[2016-07-15 16:40:31,205][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 16:40:31,206][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 16:40:31,223][ceph21][DEBUG ] detect machine type
[2016-07-15 16:40:31,227][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:40:31,229][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:40:31,248][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 16:40:31,249][ceph21][INFO  ] Purging Ceph on ceph21
[2016-07-15 16:40:31,250][ceph21][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 16:40:31,618][ceph21][DEBUG ] Reading package lists...
[2016-07-15 16:40:31,982][ceph21][DEBUG ] Building dependency tree...
[2016-07-15 16:40:31,983][ceph21][DEBUG ] Reading state information...
[2016-07-15 16:40:32,197][ceph21][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 16:40:32,197][ceph21][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 16:40:32,197][ceph21][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 16:40:32,197][ceph21][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 16:40:32,197][ceph21][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 16:40:32,198][ceph21][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-15 16:40:32,198][ceph21][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libnspr4
[2016-07-15 16:40:32,198][ceph21][DEBUG ]   libnss3 libnss3-nssdb libxslt1.1 xmlstarlet
[2016-07-15 16:40:32,198][ceph21][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-15 16:40:32,198][ceph21][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 216 not upgraded.
[2016-07-15 16:40:32,295][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 16:40:32,296][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph21
[2016-07-15 16:40:32,296][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 16:40:32,296][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 16:40:32,296][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 16:40:32,296][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 16:40:32,296][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 16:40:32,297][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fd43564e1b8>
[2016-07-15 16:40:32,297][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 16:40:32,297][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-15 16:40:32,297][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7fd435f5d230>
[2016-07-15 16:40:32,297][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 16:40:32,297][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 16:40:32,297][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph21
[2016-07-15 16:40:32,990][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 16:40:32,991][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 16:40:33,012][ceph21][DEBUG ] detect machine type
[2016-07-15 16:40:33,016][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:40:33,019][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:40:33,030][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:40:33,715][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 16:40:33,716][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 16:40:33,734][ceph21][DEBUG ] detect machine type
[2016-07-15 16:40:33,738][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:40:33,740][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:40:33,749][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 16:40:33,749][ceph21][INFO  ] purging data on ceph21
[2016-07-15 16:40:33,751][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 16:40:33,762][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 16:40:43,632][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 16:40:43,633][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph22
[2016-07-15 16:40:43,633][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 16:40:43,633][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 16:40:43,633][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 16:40:43,633][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 16:40:43,633][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 16:40:43,634][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ffa2c292b00>
[2016-07-15 16:40:43,634][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 16:40:43,634][ceph_deploy.cli][INFO  ]  host                          : ['ceph22']
[2016-07-15 16:40:43,634][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7ffa2cba91b8>
[2016-07-15 16:40:43,634][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 16:40:43,634][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 16:40:43,634][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 16:40:43,634][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 16:40:43,634][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph22
[2016-07-15 16:40:43,635][ceph_deploy.install][DEBUG ] Detecting platform for host ceph22 ...
[2016-07-15 16:40:44,336][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 16:40:44,337][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 16:40:44,355][ceph22][DEBUG ] detect machine type
[2016-07-15 16:40:44,359][ceph22][DEBUG ] find the location of an executable
[2016-07-15 16:40:44,362][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:40:44,375][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 16:40:44,375][ceph22][INFO  ] Purging Ceph on ceph22
[2016-07-15 16:40:44,376][ceph22][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 16:40:44,845][ceph22][DEBUG ] Reading package lists...
[2016-07-15 16:40:45,109][ceph22][DEBUG ] Building dependency tree...
[2016-07-15 16:40:45,109][ceph22][DEBUG ] Reading state information...
[2016-07-15 16:40:45,374][ceph22][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 16:40:45,374][ceph22][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 16:40:45,374][ceph22][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 16:40:45,375][ceph22][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 16:40:45,375][ceph22][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 16:40:45,375][ceph22][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 218 not upgraded.
[2016-07-15 16:40:45,468][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 16:40:45,469][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph22
[2016-07-15 16:40:45,469][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 16:40:45,469][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 16:40:45,469][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 16:40:45,469][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 16:40:45,469][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 16:40:45,469][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb116afc1b8>
[2016-07-15 16:40:45,469][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 16:40:45,470][ceph_deploy.cli][INFO  ]  host                          : ['ceph22']
[2016-07-15 16:40:45,470][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7fb11740b230>
[2016-07-15 16:40:45,470][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 16:40:45,470][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 16:40:45,470][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph22
[2016-07-15 16:40:46,167][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 16:40:46,169][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 16:40:46,184][ceph22][DEBUG ] detect machine type
[2016-07-15 16:40:46,188][ceph22][DEBUG ] find the location of an executable
[2016-07-15 16:40:46,190][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:40:46,201][ceph22][DEBUG ] find the location of an executable
[2016-07-15 16:40:46,882][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 16:40:46,884][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 16:40:46,901][ceph22][DEBUG ] detect machine type
[2016-07-15 16:40:46,905][ceph22][DEBUG ] find the location of an executable
[2016-07-15 16:40:46,907][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:40:46,917][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 16:40:46,917][ceph22][INFO  ] purging data on ceph22
[2016-07-15 16:40:46,919][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 16:40:46,928][ceph22][WARNING] OSDs may still be mounted, trying to unmount them
[2016-07-15 16:40:46,930][ceph22][INFO  ] Running command: find /var/lib/ceph -mindepth 1 -maxdepth 2 -type d -exec umount {} ;
[2016-07-15 16:40:46,940][ceph22][WARNING] umount: /var/lib/ceph/osd: not mounted
[2016-07-15 16:40:47,006][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 16:40:47,018][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 16:40:57,994][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 16:40:57,995][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph23
[2016-07-15 16:40:57,995][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 16:40:57,995][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 16:40:57,995][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 16:40:57,996][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 16:40:57,996][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 16:40:57,996][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7d2eabab00>
[2016-07-15 16:40:57,996][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 16:40:57,996][ceph_deploy.cli][INFO  ]  host                          : ['ceph23']
[2016-07-15 16:40:57,996][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f7d2f3d11b8>
[2016-07-15 16:40:57,996][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 16:40:57,997][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 16:40:57,997][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 16:40:57,997][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 16:40:57,997][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph23
[2016-07-15 16:40:57,997][ceph_deploy.install][DEBUG ] Detecting platform for host ceph23 ...
[2016-07-15 16:40:58,706][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 16:40:58,707][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 16:40:58,724][ceph23][DEBUG ] detect machine type
[2016-07-15 16:40:58,727][ceph23][DEBUG ] find the location of an executable
[2016-07-15 16:40:58,730][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:40:58,741][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 16:40:58,741][ceph23][INFO  ] Purging Ceph on ceph23
[2016-07-15 16:40:58,743][ceph23][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 16:40:59,561][ceph23][DEBUG ] Reading package lists...
[2016-07-15 16:40:59,876][ceph23][DEBUG ] Building dependency tree...
[2016-07-15 16:40:59,876][ceph23][DEBUG ] Reading state information...
[2016-07-15 16:41:00,141][ceph23][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 16:41:00,141][ceph23][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 16:41:00,141][ceph23][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 16:41:00,142][ceph23][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 16:41:00,142][ceph23][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 16:41:00,142][ceph23][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-15 16:41:00,142][ceph23][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libxslt1.1
[2016-07-15 16:41:00,142][ceph23][DEBUG ]   xmlstarlet
[2016-07-15 16:41:00,142][ceph23][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-15 16:41:00,143][ceph23][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 218 not upgraded.
[2016-07-15 16:41:00,249][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 16:41:00,250][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph23
[2016-07-15 16:41:00,250][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 16:41:00,250][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 16:41:00,250][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 16:41:00,250][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 16:41:00,250][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 16:41:00,250][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9e087351b8>
[2016-07-15 16:41:00,250][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 16:41:00,250][ceph_deploy.cli][INFO  ]  host                          : ['ceph23']
[2016-07-15 16:41:00,250][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f9e09044230>
[2016-07-15 16:41:00,250][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 16:41:00,250][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 16:41:00,250][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph23
[2016-07-15 16:41:00,981][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 16:41:00,982][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 16:41:00,998][ceph23][DEBUG ] detect machine type
[2016-07-15 16:41:01,005][ceph23][DEBUG ] find the location of an executable
[2016-07-15 16:41:01,008][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:41:01,027][ceph23][DEBUG ] find the location of an executable
[2016-07-15 16:41:01,736][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 16:41:01,738][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 16:41:01,754][ceph23][DEBUG ] detect machine type
[2016-07-15 16:41:01,758][ceph23][DEBUG ] find the location of an executable
[2016-07-15 16:41:01,761][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:41:01,770][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 16:41:01,770][ceph23][INFO  ] purging data on ceph23
[2016-07-15 16:41:01,771][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 16:41:01,781][ceph23][WARNING] OSDs may still be mounted, trying to unmount them
[2016-07-15 16:41:01,782][ceph23][INFO  ] Running command: find /var/lib/ceph -mindepth 1 -maxdepth 2 -type d -exec umount {} ;
[2016-07-15 16:41:01,793][ceph23][WARNING] umount: /var/lib/ceph/osd: not mounted
[2016-07-15 16:41:01,859][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 16:41:01,872][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 16:43:17,131][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 16:43:17,131][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy new ceph21
[2016-07-15 16:43:17,131][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 16:43:17,132][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 16:43:17,132][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f38579e2410>
[2016-07-15 16:43:17,132][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 16:43:17,132][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 16:43:17,132][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 16:43:17,132][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3857144ef0>
[2016-07-15 16:43:17,132][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 16:43:17,132][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2016-07-15 16:43:17,132][ceph_deploy.cli][INFO  ]  mon                           : ['ceph21']
[2016-07-15 16:43:17,133][ceph_deploy.cli][INFO  ]  public_network                : None
[2016-07-15 16:43:17,133][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 16:43:17,133][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2016-07-15 16:43:17,133][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 16:43:17,133][ceph_deploy.cli][INFO  ]  fsid                          : None
[2016-07-15 16:43:17,133][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2016-07-15 16:43:17,133][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2016-07-15 16:43:17,162][ceph21][DEBUG ] connected to host: cephAdmin 
[2016-07-15 16:43:17,166][ceph21][INFO  ] Running command: ssh -CT -o BatchMode=yes ceph21
[2016-07-15 16:43:18,224][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 16:43:18,225][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 16:43:18,241][ceph21][DEBUG ] detect machine type
[2016-07-15 16:43:18,245][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:43:18,247][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:43:18,256][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:43:18,258][ceph21][INFO  ] Running command: /bin/ip link show
[2016-07-15 16:43:18,268][ceph21][INFO  ] Running command: /bin/ip addr show
[2016-07-15 16:43:18,277][ceph21][DEBUG ] IP addresses found: ['10.1.0.44']
[2016-07-15 16:43:18,278][ceph_deploy.new][DEBUG ] Resolving host ceph21
[2016-07-15 16:43:18,278][ceph_deploy.new][DEBUG ] Monitor ceph21 at 10.1.0.44
[2016-07-15 16:43:18,278][ceph_deploy.new][DEBUG ] Monitor initial members are ['ceph21']
[2016-07-15 16:43:18,278][ceph_deploy.new][DEBUG ] Monitor addrs are ['10.1.0.44']
[2016-07-15 16:43:18,278][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2016-07-15 16:43:18,279][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2016-07-15 16:43:18,279][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2016-07-15 16:43:42,534][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 16:43:42,535][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy mon create-initial
[2016-07-15 16:43:42,535][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 16:43:42,535][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 16:43:42,535][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 16:43:42,535][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 16:43:42,535][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2016-07-15 16:43:42,535][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 16:43:42,535][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f17e9554290>
[2016-07-15 16:43:42,535][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 16:43:42,536][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f17e95356e0>
[2016-07-15 16:43:42,536][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 16:43:42,536][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 16:43:42,536][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2016-07-15 16:43:42,538][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts ceph21
[2016-07-15 16:43:42,538][ceph_deploy.mon][DEBUG ] detecting platform for host ceph21 ...
[2016-07-15 16:43:43,249][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 16:43:43,251][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 16:43:43,268][ceph21][DEBUG ] detect machine type
[2016-07-15 16:43:43,271][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:43:43,274][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:43:43,285][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:43:43,286][ceph_deploy.mon][INFO  ] distro info: Ubuntu 14.04 trusty
[2016-07-15 16:43:43,286][ceph21][DEBUG ] determining if provided host has same hostname in remote
[2016-07-15 16:43:43,286][ceph21][DEBUG ] get remote short hostname
[2016-07-15 16:43:43,287][ceph21][DEBUG ] deploying mon to ceph21
[2016-07-15 16:43:43,287][ceph21][DEBUG ] get remote short hostname
[2016-07-15 16:43:43,288][ceph21][DEBUG ] remote hostname: ceph21
[2016-07-15 16:43:43,290][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 16:43:43,292][ceph21][DEBUG ] create the mon path if it does not exist
[2016-07-15 16:43:43,293][ceph21][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-15 16:43:43,294][ceph21][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-15 16:43:43,295][ceph21][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 16:43:43,295][ceph21][DEBUG ] create the monitor keyring file
[2016-07-15 16:43:43,297][ceph21][INFO  ] Running command: ceph-mon --cluster ceph --mkfs -i ceph21 --keyring /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 16:43:43,332][ceph21][DEBUG ] ceph-mon: mon.noname-a 10.1.0.44:6789/0 is local, renaming to mon.ceph21
[2016-07-15 16:43:43,333][ceph21][DEBUG ] ceph-mon: set fsid to 409aad2e-d318-4e79-ba53-6e6661ac032f
[2016-07-15 16:43:43,333][ceph21][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-ceph21 for mon.ceph21
[2016-07-15 16:43:43,333][ceph21][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 16:43:43,334][ceph21][DEBUG ] create a done file to avoid re-doing the mon deployment
[2016-07-15 16:43:43,335][ceph21][DEBUG ] create the init path if it does not exist
[2016-07-15 16:43:43,338][ceph21][INFO  ] Running command: initctl emit ceph-mon cluster=ceph id=ceph21
[2016-07-15 16:43:45,377][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 16:43:45,442][ceph21][DEBUG ] ********************************************************************************
[2016-07-15 16:43:45,443][ceph21][DEBUG ] status for monitor: mon.ceph21
[2016-07-15 16:43:45,443][ceph21][DEBUG ] {
[2016-07-15 16:43:45,443][ceph21][DEBUG ]   "election_epoch": 2, 
[2016-07-15 16:43:45,443][ceph21][DEBUG ]   "extra_probe_peers": [], 
[2016-07-15 16:43:45,443][ceph21][DEBUG ]   "monmap": {
[2016-07-15 16:43:45,443][ceph21][DEBUG ]     "created": "0.000000", 
[2016-07-15 16:43:45,443][ceph21][DEBUG ]     "epoch": 1, 
[2016-07-15 16:43:45,443][ceph21][DEBUG ]     "fsid": "409aad2e-d318-4e79-ba53-6e6661ac032f", 
[2016-07-15 16:43:45,444][ceph21][DEBUG ]     "modified": "0.000000", 
[2016-07-15 16:43:45,444][ceph21][DEBUG ]     "mons": [
[2016-07-15 16:43:45,444][ceph21][DEBUG ]       {
[2016-07-15 16:43:45,444][ceph21][DEBUG ]         "addr": "10.1.0.44:6789/0", 
[2016-07-15 16:43:45,444][ceph21][DEBUG ]         "name": "ceph21", 
[2016-07-15 16:43:45,444][ceph21][DEBUG ]         "rank": 0
[2016-07-15 16:43:45,444][ceph21][DEBUG ]       }
[2016-07-15 16:43:45,444][ceph21][DEBUG ]     ]
[2016-07-15 16:43:45,444][ceph21][DEBUG ]   }, 
[2016-07-15 16:43:45,444][ceph21][DEBUG ]   "name": "ceph21", 
[2016-07-15 16:43:45,444][ceph21][DEBUG ]   "outside_quorum": [], 
[2016-07-15 16:43:45,444][ceph21][DEBUG ]   "quorum": [
[2016-07-15 16:43:45,444][ceph21][DEBUG ]     0
[2016-07-15 16:43:45,444][ceph21][DEBUG ]   ], 
[2016-07-15 16:43:45,445][ceph21][DEBUG ]   "rank": 0, 
[2016-07-15 16:43:45,445][ceph21][DEBUG ]   "state": "leader", 
[2016-07-15 16:43:45,445][ceph21][DEBUG ]   "sync_provider": []
[2016-07-15 16:43:45,445][ceph21][DEBUG ] }
[2016-07-15 16:43:45,445][ceph21][DEBUG ] ********************************************************************************
[2016-07-15 16:43:45,445][ceph21][INFO  ] monitor: mon.ceph21 is running
[2016-07-15 16:43:45,447][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 16:43:45,512][ceph_deploy.mon][INFO  ] processing monitor mon.ceph21
[2016-07-15 16:43:46,182][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 16:43:46,183][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 16:43:46,200][ceph21][DEBUG ] detect machine type
[2016-07-15 16:43:46,204][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:43:46,206][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:43:46,216][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:43:46,218][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 16:43:46,283][ceph_deploy.mon][INFO  ] mon.ceph21 monitor has reached quorum!
[2016-07-15 16:43:46,284][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2016-07-15 16:43:46,284][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2016-07-15 16:43:46,284][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /etc/ceph/ceph.client.admin.keyring
[2016-07-15 16:43:46,983][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 16:43:46,984][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 16:43:47,000][ceph21][DEBUG ] detect machine type
[2016-07-15 16:43:47,004][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:43:47,007][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:43:47,016][ceph21][DEBUG ] fetch remote file
[2016-07-15 16:43:47,017][ceph_deploy.gatherkeys][DEBUG ] Got ceph.client.admin.keyring key from ceph21.
[2016-07-15 16:43:47,017][ceph_deploy.gatherkeys][DEBUG ] Have ceph.mon.keyring
[2016-07-15 16:43:47,018][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-osd/ceph.keyring
[2016-07-15 16:43:47,711][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 16:43:47,712][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 16:43:47,733][ceph21][DEBUG ] detect machine type
[2016-07-15 16:43:47,737][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:43:47,739][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:43:47,748][ceph21][DEBUG ] fetch remote file
[2016-07-15 16:43:47,749][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-osd.keyring key from ceph21.
[2016-07-15 16:43:47,750][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-mds/ceph.keyring
[2016-07-15 16:43:48,433][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 16:43:48,434][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 16:43:48,451][ceph21][DEBUG ] detect machine type
[2016-07-15 16:43:48,455][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:43:48,457][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:43:48,466][ceph21][DEBUG ] fetch remote file
[2016-07-15 16:43:48,467][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-mds.keyring key from ceph21.
[2016-07-15 16:43:48,468][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-rgw/ceph.keyring
[2016-07-15 16:43:49,167][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 16:43:49,168][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 16:43:49,185][ceph21][DEBUG ] detect machine type
[2016-07-15 16:43:49,189][ceph21][DEBUG ] find the location of an executable
[2016-07-15 16:43:49,193][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:43:49,217][ceph21][DEBUG ] fetch remote file
[2016-07-15 16:43:49,219][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-rgw.keyring key from ceph21.
[2016-07-15 16:44:18,294][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 16:44:18,295][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf osd create --zap-disk ceph22:/dev/vdb
[2016-07-15 16:44:18,295][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 16:44:18,295][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 16:44:18,295][ceph_deploy.cli][INFO  ]  disk                          : [('ceph22', '/dev/vdb', None)]
[2016-07-15 16:44:18,295][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2016-07-15 16:44:18,295][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 16:44:18,295][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2016-07-15 16:44:18,295][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-15 16:44:18,295][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-15 16:44:18,295][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2016-07-15 16:44:18,295][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 16:44:18,295][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f896627b1b8>
[2016-07-15 16:44:18,296][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 16:44:18,296][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2016-07-15 16:44:18,296][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f896624c578>
[2016-07-15 16:44:18,296][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 16:44:18,296][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 16:44:18,296][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2016-07-15 16:44:18,297][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks ceph22:/dev/vdb:
[2016-07-15 16:44:19,023][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 16:44:19,024][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 16:44:19,040][ceph22][DEBUG ] detect machine type
[2016-07-15 16:44:19,050][ceph22][DEBUG ] find the location of an executable
[2016-07-15 16:44:19,053][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 16:44:19,065][ceph22][DEBUG ] find the location of an executable
[2016-07-15 16:44:19,066][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 16:44:19,066][ceph_deploy.osd][DEBUG ] Deploying osd to ceph22
[2016-07-15 16:44:19,066][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 16:44:19,069][ceph22][WARNING] osd keyring does not exist yet, creating one
[2016-07-15 16:44:19,069][ceph22][DEBUG ] create a keyring file
[2016-07-15 16:44:19,070][ceph_deploy.osd][DEBUG ] Preparing host ceph22 disk /dev/vdb journal None activate True
[2016-07-15 16:44:19,070][ceph22][DEBUG ] find the location of an executable
[2016-07-15 16:44:19,072][ceph22][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-15 16:44:19,139][ceph22][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-15 16:44:19,140][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-15 16:44:19,140][ceph22][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 16:44:19,141][ceph22][WARNING] backup header from main header.
[2016-07-15 16:44:19,141][ceph22][WARNING] 
[2016-07-15 16:44:19,141][ceph22][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 16:44:19,141][ceph22][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 16:44:19,142][ceph22][WARNING] 
[2016-07-15 16:44:19,142][ceph22][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 16:44:19,142][ceph22][WARNING] 
[2016-07-15 16:44:20,158][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 16:44:20,158][ceph22][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 16:44:20,159][ceph22][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 16:44:20,159][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 16:44:20,159][ceph22][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 16:44:20,159][ceph22][DEBUG ] other utilities.
[2016-07-15 16:44:20,160][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-15 16:44:21,226][ceph22][DEBUG ] Creating new GPT entries.
[2016-07-15 16:44:21,226][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 16:44:21,226][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-15 16:44:21,227][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 16:44:21,227][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 16:44:21,227][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 16:44:21,227][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 16:44:21,230][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 16:44:21,246][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 16:44:21,262][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 16:44:21,269][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 16:44:21,285][ceph22][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-15 16:44:21,285][ceph22][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-15 16:44:21,285][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:c89c068c-5841-40d4-9c56-122b27d7f100 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-15 16:44:22,302][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 16:44:22,302][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 16:44:22,302][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 16:44:22,466][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 16:44:22,530][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/c89c068c-5841-40d4-9c56-122b27d7f100
[2016-07-15 16:44:22,531][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/c89c068c-5841-40d4-9c56-122b27d7f100
[2016-07-15 16:44:22,531][ceph22][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-15 16:44:22,531][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:0e650d14-8d4f-4bbc-b3ff-2d4c9d8d15e7 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-15 16:44:23,547][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 16:44:23,548][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-15 16:44:23,548][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 16:44:23,812][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 16:44:23,844][ceph22][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-15 16:44:23,845][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-15 16:44:24,009][ceph22][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=1638335 blks
[2016-07-15 16:44:24,009][ceph22][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 16:44:24,011][ceph22][DEBUG ] data     =                       bsize=4096   blocks=6553339, imaxpct=25
[2016-07-15 16:44:24,011][ceph22][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 16:44:24,011][ceph22][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.VhW6X8 with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 16:44:24,012][ceph22][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 16:44:24,012][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.VhW6X8
[2016-07-15 16:44:24,012][ceph22][DEBUG ] log      =internal log           bsize=4096   blocks=3199, version=2
[2016-07-15 16:44:24,013][ceph22][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 16:44:24,014][ceph22][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 16:44:24,029][ceph22][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.VhW6X8
[2016-07-15 16:44:24,030][ceph22][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.VhW6X8/journal -> /dev/disk/by-partuuid/c89c068c-5841-40d4-9c56-122b27d7f100
[2016-07-15 16:44:24,061][ceph22][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.VhW6X8
[2016-07-15 16:44:24,062][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.VhW6X8
[2016-07-15 16:44:24,077][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-15 16:44:25,143][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 16:44:25,144][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 16:44:25,145][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 16:44:31,266][ceph22][INFO  ] checking OSD status...
[2016-07-15 16:44:31,266][ceph22][DEBUG ] find the location of an executable
[2016-07-15 16:44:31,270][ceph22][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 16:44:31,485][ceph_deploy.osd][DEBUG ] Host ceph22 is now ready for osd use.
[2016-07-15 17:51:17,434][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 17:51:17,434][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf osd create --zap-disk ceph22:/dev/vdc
[2016-07-15 17:51:17,435][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 17:51:17,435][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 17:51:17,435][ceph_deploy.cli][INFO  ]  disk                          : [('ceph22', '/dev/vdc', None)]
[2016-07-15 17:51:17,435][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2016-07-15 17:51:17,435][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 17:51:17,435][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2016-07-15 17:51:17,436][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-15 17:51:17,436][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-15 17:51:17,436][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2016-07-15 17:51:17,436][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 17:51:17,436][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f4c05a131b8>
[2016-07-15 17:51:17,436][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 17:51:17,436][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2016-07-15 17:51:17,437][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f4c059e4578>
[2016-07-15 17:51:17,437][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 17:51:17,437][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 17:51:17,437][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2016-07-15 17:51:17,439][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks ceph22:/dev/vdc:
[2016-07-15 17:51:18,155][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 17:51:18,156][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 17:51:18,175][ceph22][DEBUG ] detect machine type
[2016-07-15 17:51:18,180][ceph22][DEBUG ] find the location of an executable
[2016-07-15 17:51:18,183][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 17:51:18,195][ceph22][DEBUG ] find the location of an executable
[2016-07-15 17:51:18,196][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 17:51:18,196][ceph_deploy.osd][DEBUG ] Deploying osd to ceph22
[2016-07-15 17:51:18,197][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 17:51:18,200][ceph_deploy.osd][DEBUG ] Preparing host ceph22 disk /dev/vdc journal None activate True
[2016-07-15 17:51:18,200][ceph22][DEBUG ] find the location of an executable
[2016-07-15 17:51:18,202][ceph22][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-15 17:51:18,269][ceph22][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-15 17:51:18,269][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-15 17:51:18,270][ceph22][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 17:51:18,270][ceph22][WARNING] backup header from main header.
[2016-07-15 17:51:18,270][ceph22][WARNING] 
[2016-07-15 17:51:19,286][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 17:51:19,286][ceph22][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 17:51:19,286][ceph22][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 17:51:19,286][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 17:51:19,287][ceph22][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 17:51:19,287][ceph22][DEBUG ] other utilities.
[2016-07-15 17:51:19,287][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-15 17:51:20,303][ceph22][DEBUG ] Creating new GPT entries.
[2016-07-15 17:51:20,304][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 17:51:20,304][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-15 17:51:20,304][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 17:51:20,320][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 17:51:20,336][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 17:51:20,344][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 17:51:20,359][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 17:51:20,375][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 17:51:20,391][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 17:51:20,398][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 17:51:20,414][ceph22][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-15 17:51:20,414][ceph22][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-15 17:51:20,414][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:8e7fbbdf-1061-40c9-be6e-0d930baa9a2b --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-15 17:51:21,430][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 17:51:21,431][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 17:51:21,431][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 17:51:21,595][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 17:51:21,595][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/8e7fbbdf-1061-40c9-be6e-0d930baa9a2b
[2016-07-15 17:51:21,595][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/8e7fbbdf-1061-40c9-be6e-0d930baa9a2b
[2016-07-15 17:51:21,595][ceph22][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-15 17:51:21,596][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:c1f3dabc-295e-4677-9d21-6754b88f5aaf --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-15 17:51:22,612][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 17:51:22,612][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-15 17:51:22,612][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 17:51:22,877][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 17:51:22,877][ceph22][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-15 17:51:22,877][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-15 17:51:23,041][ceph22][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=1638335 blks
[2016-07-15 17:51:23,042][ceph22][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 17:51:23,042][ceph22][DEBUG ] data     =                       bsize=4096   blocks=6553339, imaxpct=25
[2016-07-15 17:51:23,042][ceph22][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 17:51:23,042][ceph22][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 17:51:23,042][ceph22][DEBUG ] log      =internal log           bsize=4096   blocks=3199, version=2
[2016-07-15 17:51:23,042][ceph22][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 17:51:23,043][ceph22][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 17:51:23,043][ceph22][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt.c2RALM with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 17:51:23,043][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt.c2RALM
[2016-07-15 17:51:23,044][ceph22][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.c2RALM
[2016-07-15 17:51:23,044][ceph22][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.c2RALM/journal -> /dev/disk/by-partuuid/8e7fbbdf-1061-40c9-be6e-0d930baa9a2b
[2016-07-15 17:51:23,076][ceph22][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.c2RALM
[2016-07-15 17:51:23,076][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.c2RALM
[2016-07-15 17:51:23,108][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-15 17:51:24,124][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 17:51:24,124][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 17:51:24,125][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 17:51:30,245][ceph22][INFO  ] checking OSD status...
[2016-07-15 17:51:30,245][ceph22][DEBUG ] find the location of an executable
[2016-07-15 17:51:30,248][ceph22][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 17:51:30,464][ceph_deploy.osd][DEBUG ] Host ceph22 is now ready for osd use.
[2016-07-15 17:58:39,025][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 17:58:39,025][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf osd create --zap-disk ceph23:/dev/vdb
[2016-07-15 17:58:39,026][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 17:58:39,026][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 17:58:39,026][ceph_deploy.cli][INFO  ]  disk                          : [('ceph23', '/dev/vdb', None)]
[2016-07-15 17:58:39,026][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2016-07-15 17:58:39,026][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 17:58:39,026][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2016-07-15 17:58:39,026][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-15 17:58:39,026][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-15 17:58:39,027][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2016-07-15 17:58:39,027][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 17:58:39,027][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ffa97f131b8>
[2016-07-15 17:58:39,027][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 17:58:39,027][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2016-07-15 17:58:39,027][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7ffa97ee4578>
[2016-07-15 17:58:39,027][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 17:58:39,027][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 17:58:39,027][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2016-07-15 17:58:39,028][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks ceph23:/dev/vdb:
[2016-07-15 17:58:39,722][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 17:58:39,723][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 17:58:39,740][ceph23][DEBUG ] detect machine type
[2016-07-15 17:58:39,744][ceph23][DEBUG ] find the location of an executable
[2016-07-15 17:58:39,747][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 17:58:39,766][ceph23][DEBUG ] find the location of an executable
[2016-07-15 17:58:39,766][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 17:58:39,767][ceph_deploy.osd][DEBUG ] Deploying osd to ceph23
[2016-07-15 17:58:39,767][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 17:58:39,769][ceph23][WARNING] osd keyring does not exist yet, creating one
[2016-07-15 17:58:39,769][ceph23][DEBUG ] create a keyring file
[2016-07-15 17:58:39,770][ceph_deploy.osd][DEBUG ] Preparing host ceph23 disk /dev/vdb journal None activate True
[2016-07-15 17:58:39,770][ceph23][DEBUG ] find the location of an executable
[2016-07-15 17:58:39,772][ceph23][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-15 17:58:39,839][ceph23][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-15 17:58:39,840][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-15 17:58:39,840][ceph23][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 17:58:39,840][ceph23][WARNING] backup header from main header.
[2016-07-15 17:58:39,840][ceph23][WARNING] 
[2016-07-15 17:58:39,840][ceph23][WARNING] Invalid partition data!
[2016-07-15 17:58:40,856][ceph23][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 17:58:40,857][ceph23][DEBUG ] other utilities.
[2016-07-15 17:58:40,857][ceph23][WARNING] ceph-disk: Error: Command '['/sbin/sgdisk', '--zap-all', '--', '/dev/vdb']' returned non-zero exit status 2
[2016-07-15 17:58:40,864][ceph23][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2016-07-15 17:58:40,865][ceph_deploy.osd][ERROR ] Failed to execute command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-15 17:58:40,865][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2016-07-15 17:59:04,239][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 17:59:04,239][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf osd create --zap-disk ceph23:/dev/vdc
[2016-07-15 17:59:04,239][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 17:59:04,239][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 17:59:04,239][ceph_deploy.cli][INFO  ]  disk                          : [('ceph23', '/dev/vdc', None)]
[2016-07-15 17:59:04,239][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2016-07-15 17:59:04,239][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 17:59:04,240][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2016-07-15 17:59:04,240][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-15 17:59:04,240][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-15 17:59:04,240][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2016-07-15 17:59:04,240][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 17:59:04,240][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f43b55ad1b8>
[2016-07-15 17:59:04,240][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 17:59:04,240][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2016-07-15 17:59:04,240][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f43b557e578>
[2016-07-15 17:59:04,240][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 17:59:04,240][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 17:59:04,240][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2016-07-15 17:59:04,241][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks ceph23:/dev/vdc:
[2016-07-15 17:59:04,926][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 17:59:04,926][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 17:59:04,942][ceph23][DEBUG ] detect machine type
[2016-07-15 17:59:04,946][ceph23][DEBUG ] find the location of an executable
[2016-07-15 17:59:04,948][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 17:59:04,959][ceph23][DEBUG ] find the location of an executable
[2016-07-15 17:59:04,960][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 17:59:04,960][ceph_deploy.osd][DEBUG ] Deploying osd to ceph23
[2016-07-15 17:59:04,960][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 17:59:04,962][ceph_deploy.osd][DEBUG ] Preparing host ceph23 disk /dev/vdc journal None activate True
[2016-07-15 17:59:04,962][ceph23][DEBUG ] find the location of an executable
[2016-07-15 17:59:04,964][ceph23][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-15 17:59:05,030][ceph23][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-15 17:59:05,030][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-15 17:59:05,031][ceph23][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 17:59:05,031][ceph23][WARNING] backup header from main header.
[2016-07-15 17:59:05,031][ceph23][WARNING] 
[2016-07-15 17:59:05,031][ceph23][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 17:59:05,031][ceph23][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 17:59:05,031][ceph23][WARNING] 
[2016-07-15 17:59:05,031][ceph23][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 17:59:05,032][ceph23][WARNING] 
[2016-07-15 17:59:06,097][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 17:59:06,098][ceph23][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 17:59:06,098][ceph23][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 17:59:06,098][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 17:59:06,098][ceph23][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 17:59:06,099][ceph23][DEBUG ] other utilities.
[2016-07-15 17:59:06,099][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-15 17:59:07,115][ceph23][DEBUG ] Creating new GPT entries.
[2016-07-15 17:59:07,115][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 17:59:07,115][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-15 17:59:07,115][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 17:59:07,116][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 17:59:07,116][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 17:59:07,119][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 17:59:07,135][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 17:59:07,150][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 17:59:07,166][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 17:59:07,174][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 17:59:07,189][ceph23][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-15 17:59:07,189][ceph23][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-15 17:59:07,190][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:1387e18f-a9d5-4b0c-b811-890472394089 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-15 17:59:08,205][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 17:59:08,206][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 17:59:08,206][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 17:59:08,420][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 17:59:08,420][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/1387e18f-a9d5-4b0c-b811-890472394089
[2016-07-15 17:59:08,420][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/1387e18f-a9d5-4b0c-b811-890472394089
[2016-07-15 17:59:08,421][ceph23][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-15 17:59:08,421][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:4ffcb42a-59b4-4ed7-9584-38b3755b8949 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-15 17:59:09,437][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 17:59:09,437][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-15 17:59:09,438][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 17:59:09,702][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 17:59:09,766][ceph23][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-15 17:59:09,766][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-15 17:59:09,930][ceph23][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=1638335 blks
[2016-07-15 17:59:09,931][ceph23][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 17:59:09,931][ceph23][DEBUG ] data     =                       bsize=4096   blocks=6553339, imaxpct=25
[2016-07-15 17:59:09,931][ceph23][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 17:59:09,932][ceph23][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 17:59:09,932][ceph23][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt.0dHDwD with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 17:59:09,932][ceph23][DEBUG ] log      =internal log           bsize=4096   blocks=3199, version=2
[2016-07-15 17:59:09,932][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt.0dHDwD
[2016-07-15 17:59:09,932][ceph23][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 17:59:09,933][ceph23][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 17:59:09,933][ceph23][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.0dHDwD
[2016-07-15 17:59:09,933][ceph23][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.0dHDwD/journal -> /dev/disk/by-partuuid/1387e18f-a9d5-4b0c-b811-890472394089
[2016-07-15 17:59:09,949][ceph23][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.0dHDwD
[2016-07-15 17:59:09,949][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.0dHDwD
[2016-07-15 17:59:09,965][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-15 17:59:11,031][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 17:59:11,031][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 17:59:11,031][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 17:59:17,102][ceph23][INFO  ] checking OSD status...
[2016-07-15 17:59:17,103][ceph23][DEBUG ] find the location of an executable
[2016-07-15 17:59:17,106][ceph23][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 17:59:17,321][ceph_deploy.osd][DEBUG ] Host ceph23 is now ready for osd use.
[2016-07-15 18:00:37,670][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:00:37,670][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf osd create --zap-disk ceph23:/dev/vdb
[2016-07-15 18:00:37,670][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:00:37,671][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:00:37,671][ceph_deploy.cli][INFO  ]  disk                          : [('ceph23', '/dev/vdb', None)]
[2016-07-15 18:00:37,671][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2016-07-15 18:00:37,671][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:00:37,671][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2016-07-15 18:00:37,671][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-15 18:00:37,671][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-15 18:00:37,671][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2016-07-15 18:00:37,672][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:00:37,672][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa322e691b8>
[2016-07-15 18:00:37,672][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:00:37,672][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2016-07-15 18:00:37,672][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fa322e3a578>
[2016-07-15 18:00:37,672][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:00:37,672][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:00:37,673][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2016-07-15 18:00:37,674][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks ceph23:/dev/vdb:
[2016-07-15 18:00:38,418][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 18:00:38,418][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 18:00:38,435][ceph23][DEBUG ] detect machine type
[2016-07-15 18:00:38,439][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:00:38,442][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:00:38,461][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:00:38,462][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:00:38,463][ceph_deploy.osd][DEBUG ] Deploying osd to ceph23
[2016-07-15 18:00:38,463][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 18:00:38,465][ceph_deploy.osd][DEBUG ] Preparing host ceph23 disk /dev/vdb journal None activate True
[2016-07-15 18:00:38,465][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:00:38,467][ceph23][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-15 18:00:38,534][ceph23][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-15 18:00:38,535][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-15 18:00:39,550][ceph23][DEBUG ] Creating new GPT entries.
[2016-07-15 18:00:39,551][ceph23][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 18:00:39,551][ceph23][DEBUG ] other utilities.
[2016-07-15 18:00:39,551][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-15 18:00:40,617][ceph23][DEBUG ] Creating new GPT entries.
[2016-07-15 18:00:40,618][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:00:40,618][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-15 18:00:40,618][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:00:40,618][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 18:00:40,618][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 18:00:40,618][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 18:00:40,626][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 18:00:40,642][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 18:00:40,650][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 18:00:40,665][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 18:00:40,673][ceph23][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-15 18:00:40,673][ceph23][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-15 18:00:40,673][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:315720f5-84c7-478e-9f85-5d9aa6cacafd --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-15 18:00:41,739][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:00:41,739][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 18:00:41,740][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:00:41,904][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 18:00:41,904][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/315720f5-84c7-478e-9f85-5d9aa6cacafd
[2016-07-15 18:00:41,904][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/315720f5-84c7-478e-9f85-5d9aa6cacafd
[2016-07-15 18:00:41,904][ceph23][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-15 18:00:41,904][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:c9437682-142d-4096-8883-b0f1a6e84322 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-15 18:00:42,920][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:00:42,922][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-15 18:00:42,922][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:00:43,186][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 18:00:43,250][ceph23][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-15 18:00:43,251][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-15 18:00:43,415][ceph23][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=1638335 blks
[2016-07-15 18:00:43,415][ceph23][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 18:00:43,415][ceph23][DEBUG ] data     =                       bsize=4096   blocks=6553339, imaxpct=25
[2016-07-15 18:00:43,416][ceph23][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 18:00:43,416][ceph23][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 18:00:43,416][ceph23][DEBUG ] log      =internal log           bsize=4096   blocks=3199, version=2
[2016-07-15 18:00:43,416][ceph23][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 18:00:43,416][ceph23][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 18:00:43,416][ceph23][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.oiGgWR with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 18:00:43,416][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.oiGgWR
[2016-07-15 18:00:43,417][ceph23][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.oiGgWR
[2016-07-15 18:00:43,417][ceph23][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.oiGgWR/journal -> /dev/disk/by-partuuid/315720f5-84c7-478e-9f85-5d9aa6cacafd
[2016-07-15 18:00:43,448][ceph23][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.oiGgWR
[2016-07-15 18:00:43,449][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.oiGgWR
[2016-07-15 18:00:43,464][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-15 18:00:44,531][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:00:44,531][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 18:00:44,531][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:00:50,603][ceph23][INFO  ] checking OSD status...
[2016-07-15 18:00:50,603][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:00:50,606][ceph23][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 18:00:50,821][ceph_deploy.osd][DEBUG ] Host ceph23 is now ready for osd use.
[2016-07-15 18:02:23,445][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:02:23,445][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph21
[2016-07-15 18:02:23,446][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:02:23,446][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:02:23,446][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:02:23,446][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 18:02:23,446][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:02:23,446][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbcc7353b00>
[2016-07-15 18:02:23,446][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:02:23,447][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-15 18:02:23,447][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fbcc7c6a1b8>
[2016-07-15 18:02:23,447][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:02:23,447][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:02:23,447][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 18:02:23,447][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 18:02:23,447][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph21
[2016-07-15 18:02:23,447][ceph_deploy.install][DEBUG ] Detecting platform for host ceph21 ...
[2016-07-15 18:02:24,142][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:02:24,143][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:02:24,159][ceph21][DEBUG ] detect machine type
[2016-07-15 18:02:24,163][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:02:24,165][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:02:24,176][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:02:24,177][ceph21][INFO  ] Purging Ceph on ceph21
[2016-07-15 18:02:24,178][ceph21][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 18:02:24,746][ceph21][DEBUG ] Reading package lists...
[2016-07-15 18:02:25,011][ceph21][DEBUG ] Building dependency tree...
[2016-07-15 18:02:25,011][ceph21][DEBUG ] Reading state information...
[2016-07-15 18:02:25,225][ceph21][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 18:02:25,225][ceph21][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 18:02:25,226][ceph21][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 18:02:25,226][ceph21][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 18:02:25,226][ceph21][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 18:02:25,226][ceph21][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-15 18:02:25,226][ceph21][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libnspr4
[2016-07-15 18:02:25,226][ceph21][DEBUG ]   libnss3 libnss3-nssdb libxslt1.1 xmlstarlet
[2016-07-15 18:02:25,227][ceph21][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-15 18:02:25,242][ceph21][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 216 not upgraded.
[2016-07-15 18:02:25,339][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:02:25,339][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph21
[2016-07-15 18:02:25,340][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:02:25,340][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:02:25,340][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:02:25,340][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 18:02:25,340][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:02:25,340][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f27cab491b8>
[2016-07-15 18:02:25,340][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:02:25,340][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-15 18:02:25,341][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f27cb458230>
[2016-07-15 18:02:25,341][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:02:25,341][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:02:25,341][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph21
[2016-07-15 18:02:26,021][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:02:26,022][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:02:26,039][ceph21][DEBUG ] detect machine type
[2016-07-15 18:02:26,044][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:02:26,046][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:02:26,057][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:02:26,777][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:02:26,779][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:02:26,796][ceph21][DEBUG ] detect machine type
[2016-07-15 18:02:26,799][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:02:26,802][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:02:26,810][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:02:26,811][ceph21][INFO  ] purging data on ceph21
[2016-07-15 18:02:26,812][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 18:02:26,823][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 18:02:36,819][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:02:36,819][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph22
[2016-07-15 18:02:36,819][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:02:36,819][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:02:36,820][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:02:36,820][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 18:02:36,820][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:02:36,820][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f13eaad8b00>
[2016-07-15 18:02:36,820][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:02:36,820][ceph_deploy.cli][INFO  ]  host                          : ['ceph22']
[2016-07-15 18:02:36,820][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f13eb3ef1b8>
[2016-07-15 18:02:36,820][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:02:36,820][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:02:36,821][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 18:02:36,821][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 18:02:36,821][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph22
[2016-07-15 18:02:36,821][ceph_deploy.install][DEBUG ] Detecting platform for host ceph22 ...
[2016-07-15 18:02:37,524][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 18:02:37,525][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 18:02:37,543][ceph22][DEBUG ] detect machine type
[2016-07-15 18:02:37,547][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:02:37,549][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:02:37,561][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:02:37,561][ceph22][INFO  ] Purging Ceph on ceph22
[2016-07-15 18:02:37,563][ceph22][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 18:02:38,031][ceph22][DEBUG ] Reading package lists...
[2016-07-15 18:02:38,346][ceph22][DEBUG ] Building dependency tree...
[2016-07-15 18:02:38,346][ceph22][DEBUG ] Reading state information...
[2016-07-15 18:02:38,560][ceph22][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 18:02:38,560][ceph22][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 18:02:38,561][ceph22][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 18:02:38,561][ceph22][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 18:02:38,561][ceph22][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 18:02:38,561][ceph22][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 218 not upgraded.
[2016-07-15 18:02:38,654][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:02:38,654][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph22
[2016-07-15 18:02:38,654][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:02:38,655][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:02:38,655][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:02:38,655][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 18:02:38,655][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:02:38,655][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0af3ab71b8>
[2016-07-15 18:02:38,655][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:02:38,655][ceph_deploy.cli][INFO  ]  host                          : ['ceph22']
[2016-07-15 18:02:38,655][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f0af43c6230>
[2016-07-15 18:02:38,655][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:02:38,656][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:02:38,656][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph22
[2016-07-15 18:02:39,358][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 18:02:39,359][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 18:02:39,375][ceph22][DEBUG ] detect machine type
[2016-07-15 18:02:39,379][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:02:39,382][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:02:39,393][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:02:40,083][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 18:02:40,084][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 18:02:40,101][ceph22][DEBUG ] detect machine type
[2016-07-15 18:02:40,105][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:02:40,108][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:02:40,116][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:02:40,116][ceph22][INFO  ] purging data on ceph22
[2016-07-15 18:02:40,118][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 18:02:40,127][ceph22][WARNING] OSDs may still be mounted, trying to unmount them
[2016-07-15 18:02:40,129][ceph22][INFO  ] Running command: find /var/lib/ceph -mindepth 1 -maxdepth 2 -type d -exec umount {} ;
[2016-07-15 18:02:40,139][ceph22][WARNING] umount: /var/lib/ceph/osd: not mounted
[2016-07-15 18:02:40,204][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 18:02:40,216][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 18:02:51,421][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:02:51,421][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph23
[2016-07-15 18:02:51,422][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:02:51,422][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:02:51,422][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:02:51,422][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 18:02:51,422][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:02:51,422][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ff7901c1b00>
[2016-07-15 18:02:51,423][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:02:51,423][ceph_deploy.cli][INFO  ]  host                          : ['ceph23']
[2016-07-15 18:02:51,423][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7ff790ad81b8>
[2016-07-15 18:02:51,423][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:02:51,423][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:02:51,423][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 18:02:51,423][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 18:02:51,423][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph23
[2016-07-15 18:02:51,423][ceph_deploy.install][DEBUG ] Detecting platform for host ceph23 ...
[2016-07-15 18:02:52,158][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 18:02:52,158][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 18:02:52,175][ceph23][DEBUG ] detect machine type
[2016-07-15 18:02:52,178][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:02:52,181][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:02:52,200][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:02:52,201][ceph23][INFO  ] Purging Ceph on ceph23
[2016-07-15 18:02:52,202][ceph23][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 18:02:52,571][ceph23][DEBUG ] Reading package lists...
[2016-07-15 18:02:52,886][ceph23][DEBUG ] Building dependency tree...
[2016-07-15 18:02:52,886][ceph23][DEBUG ] Reading state information...
[2016-07-15 18:02:53,100][ceph23][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 18:02:53,100][ceph23][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 18:02:53,101][ceph23][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 18:02:53,101][ceph23][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 18:02:53,101][ceph23][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 18:02:53,101][ceph23][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-15 18:02:53,101][ceph23][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libxslt1.1
[2016-07-15 18:02:53,101][ceph23][DEBUG ]   xmlstarlet
[2016-07-15 18:02:53,102][ceph23][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-15 18:02:53,165][ceph23][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 218 not upgraded.
[2016-07-15 18:02:53,270][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:02:53,270][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph23
[2016-07-15 18:02:53,270][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:02:53,270][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:02:53,270][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:02:53,270][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 18:02:53,270][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:02:53,270][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9bbbbf41b8>
[2016-07-15 18:02:53,271][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:02:53,271][ceph_deploy.cli][INFO  ]  host                          : ['ceph23']
[2016-07-15 18:02:53,271][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f9bbc503230>
[2016-07-15 18:02:53,271][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:02:53,271][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:02:53,271][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph23
[2016-07-15 18:02:53,973][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 18:02:53,975][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 18:02:53,991][ceph23][DEBUG ] detect machine type
[2016-07-15 18:02:53,995][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:02:53,997][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:02:54,009][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:02:54,759][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 18:02:54,760][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 18:02:54,779][ceph23][DEBUG ] detect machine type
[2016-07-15 18:02:54,782][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:02:54,784][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:02:54,802][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:02:54,802][ceph23][INFO  ] purging data on ceph23
[2016-07-15 18:02:54,807][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 18:02:54,817][ceph23][WARNING] OSDs may still be mounted, trying to unmount them
[2016-07-15 18:02:54,819][ceph23][INFO  ] Running command: find /var/lib/ceph -mindepth 1 -maxdepth 2 -type d -exec umount {} ;
[2016-07-15 18:02:54,829][ceph23][WARNING] umount: /var/lib/ceph/osd: not mounted
[2016-07-15 18:02:54,895][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 18:02:54,907][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 18:05:25,782][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:05:25,783][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy new ceph21
[2016-07-15 18:05:25,783][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:05:25,783][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:05:25,783][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f71930ad410>
[2016-07-15 18:05:25,784][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:05:25,784][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 18:05:25,784][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:05:25,784][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f719280fef0>
[2016-07-15 18:05:25,784][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:05:25,784][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2016-07-15 18:05:25,785][ceph_deploy.cli][INFO  ]  mon                           : ['ceph21']
[2016-07-15 18:05:25,785][ceph_deploy.cli][INFO  ]  public_network                : None
[2016-07-15 18:05:25,785][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:05:25,785][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2016-07-15 18:05:25,785][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:05:25,785][ceph_deploy.cli][INFO  ]  fsid                          : None
[2016-07-15 18:05:25,786][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2016-07-15 18:05:25,786][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2016-07-15 18:05:25,818][ceph21][DEBUG ] connected to host: cephAdmin 
[2016-07-15 18:05:25,825][ceph21][INFO  ] Running command: ssh -CT -o BatchMode=yes ceph21
[2016-07-15 18:05:26,848][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:05:26,849][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:05:26,865][ceph21][DEBUG ] detect machine type
[2016-07-15 18:05:26,869][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:05:26,872][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:05:26,890][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:05:26,893][ceph21][INFO  ] Running command: /bin/ip link show
[2016-07-15 18:05:26,904][ceph21][INFO  ] Running command: /bin/ip addr show
[2016-07-15 18:05:26,914][ceph21][DEBUG ] IP addresses found: ['10.1.0.44']
[2016-07-15 18:05:26,914][ceph_deploy.new][DEBUG ] Resolving host ceph21
[2016-07-15 18:05:26,915][ceph_deploy.new][DEBUG ] Monitor ceph21 at 10.1.0.44
[2016-07-15 18:05:26,915][ceph_deploy.new][DEBUG ] Monitor initial members are ['ceph21']
[2016-07-15 18:05:26,915][ceph_deploy.new][DEBUG ] Monitor addrs are ['10.1.0.44']
[2016-07-15 18:05:26,915][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2016-07-15 18:05:26,916][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2016-07-15 18:05:26,916][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2016-07-15 18:06:40,512][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:06:40,513][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy mon create-initial
[2016-07-15 18:06:40,513][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:06:40,513][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:06:40,513][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:06:40,513][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 18:06:40,513][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2016-07-15 18:06:40,513][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:06:40,514][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f18e70b6290>
[2016-07-15 18:06:40,514][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:06:40,514][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f18e70976e0>
[2016-07-15 18:06:40,514][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:06:40,514][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:06:40,514][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2016-07-15 18:06:40,516][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts ceph21
[2016-07-15 18:06:40,516][ceph_deploy.mon][DEBUG ] detecting platform for host ceph21 ...
[2016-07-15 18:06:41,177][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:06:41,179][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:06:41,194][ceph21][DEBUG ] detect machine type
[2016-07-15 18:06:41,198][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:06:41,200][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:06:41,211][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:06:41,212][ceph_deploy.mon][INFO  ] distro info: Ubuntu 14.04 trusty
[2016-07-15 18:06:41,212][ceph21][DEBUG ] determining if provided host has same hostname in remote
[2016-07-15 18:06:41,213][ceph21][DEBUG ] get remote short hostname
[2016-07-15 18:06:41,213][ceph21][DEBUG ] deploying mon to ceph21
[2016-07-15 18:06:41,214][ceph21][DEBUG ] get remote short hostname
[2016-07-15 18:06:41,214][ceph21][DEBUG ] remote hostname: ceph21
[2016-07-15 18:06:41,217][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 18:06:41,219][ceph21][DEBUG ] create the mon path if it does not exist
[2016-07-15 18:06:41,220][ceph21][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-15 18:06:41,221][ceph21][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-15 18:06:41,221][ceph21][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 18:06:41,222][ceph21][DEBUG ] create the monitor keyring file
[2016-07-15 18:06:41,224][ceph21][INFO  ] Running command: ceph-mon --cluster ceph --mkfs -i ceph21 --keyring /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 18:06:41,258][ceph21][DEBUG ] ceph-mon: mon.noname-a 10.1.0.44:6789/0 is local, renaming to mon.ceph21
[2016-07-15 18:06:41,258][ceph21][DEBUG ] ceph-mon: set fsid to 58ef75f5-1d1b-40fc-8ba9-02cd3be5a8ce
[2016-07-15 18:06:41,258][ceph21][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-ceph21 for mon.ceph21
[2016-07-15 18:06:41,259][ceph21][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 18:06:41,260][ceph21][DEBUG ] create a done file to avoid re-doing the mon deployment
[2016-07-15 18:06:41,261][ceph21][DEBUG ] create the init path if it does not exist
[2016-07-15 18:06:41,263][ceph21][INFO  ] Running command: initctl emit ceph-mon cluster=ceph id=ceph21
[2016-07-15 18:06:43,302][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 18:06:43,367][ceph21][DEBUG ] ********************************************************************************
[2016-07-15 18:06:43,368][ceph21][DEBUG ] status for monitor: mon.ceph21
[2016-07-15 18:06:43,368][ceph21][DEBUG ] {
[2016-07-15 18:06:43,368][ceph21][DEBUG ]   "election_epoch": 2, 
[2016-07-15 18:06:43,368][ceph21][DEBUG ]   "extra_probe_peers": [], 
[2016-07-15 18:06:43,368][ceph21][DEBUG ]   "monmap": {
[2016-07-15 18:06:43,369][ceph21][DEBUG ]     "created": "0.000000", 
[2016-07-15 18:06:43,369][ceph21][DEBUG ]     "epoch": 1, 
[2016-07-15 18:06:43,369][ceph21][DEBUG ]     "fsid": "58ef75f5-1d1b-40fc-8ba9-02cd3be5a8ce", 
[2016-07-15 18:06:43,369][ceph21][DEBUG ]     "modified": "0.000000", 
[2016-07-15 18:06:43,369][ceph21][DEBUG ]     "mons": [
[2016-07-15 18:06:43,369][ceph21][DEBUG ]       {
[2016-07-15 18:06:43,369][ceph21][DEBUG ]         "addr": "10.1.0.44:6789/0", 
[2016-07-15 18:06:43,369][ceph21][DEBUG ]         "name": "ceph21", 
[2016-07-15 18:06:43,370][ceph21][DEBUG ]         "rank": 0
[2016-07-15 18:06:43,370][ceph21][DEBUG ]       }
[2016-07-15 18:06:43,370][ceph21][DEBUG ]     ]
[2016-07-15 18:06:43,370][ceph21][DEBUG ]   }, 
[2016-07-15 18:06:43,370][ceph21][DEBUG ]   "name": "ceph21", 
[2016-07-15 18:06:43,370][ceph21][DEBUG ]   "outside_quorum": [], 
[2016-07-15 18:06:43,370][ceph21][DEBUG ]   "quorum": [
[2016-07-15 18:06:43,370][ceph21][DEBUG ]     0
[2016-07-15 18:06:43,371][ceph21][DEBUG ]   ], 
[2016-07-15 18:06:43,371][ceph21][DEBUG ]   "rank": 0, 
[2016-07-15 18:06:43,371][ceph21][DEBUG ]   "state": "leader", 
[2016-07-15 18:06:43,371][ceph21][DEBUG ]   "sync_provider": []
[2016-07-15 18:06:43,371][ceph21][DEBUG ] }
[2016-07-15 18:06:43,371][ceph21][DEBUG ] ********************************************************************************
[2016-07-15 18:06:43,371][ceph21][INFO  ] monitor: mon.ceph21 is running
[2016-07-15 18:06:43,373][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 18:06:43,438][ceph_deploy.mon][INFO  ] processing monitor mon.ceph21
[2016-07-15 18:06:44,088][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:06:44,090][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:06:44,105][ceph21][DEBUG ] detect machine type
[2016-07-15 18:06:44,108][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:06:44,111][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:06:44,119][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:06:44,121][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 18:06:44,187][ceph_deploy.mon][INFO  ] mon.ceph21 monitor has reached quorum!
[2016-07-15 18:06:44,187][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2016-07-15 18:06:44,187][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2016-07-15 18:06:44,187][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /etc/ceph/ceph.client.admin.keyring
[2016-07-15 18:06:44,861][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:06:44,862][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:06:44,878][ceph21][DEBUG ] detect machine type
[2016-07-15 18:06:44,882][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:06:44,885][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:06:44,893][ceph21][DEBUG ] fetch remote file
[2016-07-15 18:06:44,894][ceph_deploy.gatherkeys][DEBUG ] Got ceph.client.admin.keyring key from ceph21.
[2016-07-15 18:06:44,895][ceph_deploy.gatherkeys][DEBUG ] Have ceph.mon.keyring
[2016-07-15 18:06:44,895][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-osd/ceph.keyring
[2016-07-15 18:06:45,563][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:06:45,565][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:06:45,581][ceph21][DEBUG ] detect machine type
[2016-07-15 18:06:45,585][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:06:45,588][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:06:45,597][ceph21][DEBUG ] fetch remote file
[2016-07-15 18:06:45,598][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-osd.keyring key from ceph21.
[2016-07-15 18:06:45,599][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-mds/ceph.keyring
[2016-07-15 18:06:46,258][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:06:46,259][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:06:46,275][ceph21][DEBUG ] detect machine type
[2016-07-15 18:06:46,280][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:06:46,282][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:06:46,292][ceph21][DEBUG ] fetch remote file
[2016-07-15 18:06:46,293][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-mds.keyring key from ceph21.
[2016-07-15 18:06:46,293][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-rgw/ceph.keyring
[2016-07-15 18:06:46,944][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:06:46,945][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:06:46,962][ceph21][DEBUG ] detect machine type
[2016-07-15 18:06:46,966][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:06:46,969][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:06:46,986][ceph21][DEBUG ] fetch remote file
[2016-07-15 18:06:46,987][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-rgw.keyring key from ceph21.
[2016-07-15 18:07:27,457][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:07:27,457][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf osd create --zap-disk ceph22:/dev/vdb ceph22:/dev/vdc ceph23:/dev/vdb ceph23:/dev/vdc
[2016-07-15 18:07:27,457][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:07:27,458][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:07:27,458][ceph_deploy.cli][INFO  ]  disk                          : [('ceph22', '/dev/vdb', None), ('ceph22', '/dev/vdc', None), ('ceph23', '/dev/vdb', None), ('ceph23', '/dev/vdc', None)]
[2016-07-15 18:07:27,458][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2016-07-15 18:07:27,458][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:07:27,458][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2016-07-15 18:07:27,458][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-15 18:07:27,458][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-15 18:07:27,458][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2016-07-15 18:07:27,458][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:07:27,459][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f01fbc5e1b8>
[2016-07-15 18:07:27,459][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:07:27,459][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2016-07-15 18:07:27,459][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f01fbc2f578>
[2016-07-15 18:07:27,459][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:07:27,459][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:07:27,459][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2016-07-15 18:07:27,460][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks ceph22:/dev/vdb: ceph22:/dev/vdc: ceph23:/dev/vdb: ceph23:/dev/vdc:
[2016-07-15 18:07:28,159][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 18:07:28,160][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 18:07:28,178][ceph22][DEBUG ] detect machine type
[2016-07-15 18:07:28,183][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:07:28,186][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:07:28,205][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:07:28,206][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:07:28,206][ceph_deploy.osd][DEBUG ] Deploying osd to ceph22
[2016-07-15 18:07:28,207][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 18:07:28,209][ceph22][WARNING] osd keyring does not exist yet, creating one
[2016-07-15 18:07:28,209][ceph22][DEBUG ] create a keyring file
[2016-07-15 18:07:28,211][ceph_deploy.osd][DEBUG ] Preparing host ceph22 disk /dev/vdb journal None activate True
[2016-07-15 18:07:28,211][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:07:28,214][ceph22][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-15 18:07:28,281][ceph22][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-15 18:07:28,281][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-15 18:07:28,281][ceph22][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 18:07:28,281][ceph22][WARNING] backup header from main header.
[2016-07-15 18:07:28,281][ceph22][WARNING] 
[2016-07-15 18:07:28,282][ceph22][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 18:07:28,282][ceph22][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 18:07:28,282][ceph22][WARNING] 
[2016-07-15 18:07:28,282][ceph22][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 18:07:28,282][ceph22][WARNING] 
[2016-07-15 18:07:29,298][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 18:07:29,299][ceph22][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 18:07:29,299][ceph22][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 18:07:29,299][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 18:07:29,299][ceph22][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 18:07:29,299][ceph22][DEBUG ] other utilities.
[2016-07-15 18:07:29,300][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-15 18:07:30,366][ceph22][DEBUG ] Creating new GPT entries.
[2016-07-15 18:07:30,366][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 18:07:30,366][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-15 18:07:30,367][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:07:30,367][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 18:07:30,367][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 18:07:30,367][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 18:07:30,374][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 18:07:30,390][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 18:07:30,397][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 18:07:30,413][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 18:07:30,420][ceph22][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-15 18:07:30,421][ceph22][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-15 18:07:30,421][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:34b6be6b-1364-473d-beb7-6c4786821bb1 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-15 18:07:31,437][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 18:07:31,437][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 18:07:31,438][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:07:31,602][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 18:07:31,666][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/34b6be6b-1364-473d-beb7-6c4786821bb1
[2016-07-15 18:07:31,666][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/34b6be6b-1364-473d-beb7-6c4786821bb1
[2016-07-15 18:07:31,666][ceph22][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-15 18:07:31,666][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:4d1993c5-8c48-456c-aa74-75774d87d703 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-15 18:07:32,682][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 18:07:32,683][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-15 18:07:32,684][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:07:32,948][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 18:07:32,980][ceph22][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-15 18:07:32,980][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-15 18:07:33,746][ceph22][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-15 18:07:33,746][ceph22][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 18:07:33,746][ceph22][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-15 18:07:33,746][ceph22][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 18:07:33,747][ceph22][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 18:07:33,747][ceph22][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-15 18:07:33,747][ceph22][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 18:07:33,747][ceph22][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 18:07:33,747][ceph22][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.m8yxah with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 18:07:33,747][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.m8yxah
[2016-07-15 18:07:33,749][ceph22][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.m8yxah
[2016-07-15 18:07:33,749][ceph22][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.m8yxah/journal -> /dev/disk/by-partuuid/34b6be6b-1364-473d-beb7-6c4786821bb1
[2016-07-15 18:07:33,780][ceph22][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.m8yxah
[2016-07-15 18:07:33,781][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.m8yxah
[2016-07-15 18:07:33,812][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-15 18:07:34,829][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 18:07:34,829][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 18:07:34,829][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:07:40,901][ceph22][INFO  ] checking OSD status...
[2016-07-15 18:07:40,901][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:07:40,905][ceph22][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 18:07:41,120][ceph_deploy.osd][DEBUG ] Host ceph22 is now ready for osd use.
[2016-07-15 18:07:41,787][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 18:07:41,788][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 18:07:41,805][ceph22][DEBUG ] detect machine type
[2016-07-15 18:07:41,808][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:07:41,811][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:07:41,820][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:07:41,821][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:07:41,821][ceph_deploy.osd][DEBUG ] Preparing host ceph22 disk /dev/vdc journal None activate True
[2016-07-15 18:07:41,822][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:07:41,824][ceph22][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-15 18:07:41,890][ceph22][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-15 18:07:41,891][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-15 18:07:41,891][ceph22][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 18:07:41,891][ceph22][WARNING] backup header from main header.
[2016-07-15 18:07:41,891][ceph22][WARNING] 
[2016-07-15 18:07:41,891][ceph22][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 18:07:41,891][ceph22][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 18:07:41,892][ceph22][WARNING] 
[2016-07-15 18:07:41,892][ceph22][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 18:07:41,892][ceph22][WARNING] 
[2016-07-15 18:07:42,958][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 18:07:42,958][ceph22][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 18:07:42,959][ceph22][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 18:07:42,959][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 18:07:42,959][ceph22][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 18:07:42,959][ceph22][DEBUG ] other utilities.
[2016-07-15 18:07:42,960][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-15 18:07:43,976][ceph22][DEBUG ] Creating new GPT entries.
[2016-07-15 18:07:43,976][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 18:07:43,976][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-15 18:07:43,976][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 18:07:43,977][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 18:07:43,977][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 18:07:43,978][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 18:07:43,994][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 18:07:44,009][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 18:07:44,025][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 18:07:44,032][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 18:07:44,048][ceph22][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-15 18:07:44,048][ceph22][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-15 18:07:44,049][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:b81d0f3b-7299-455d-afb5-a07ea58fe810 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-15 18:07:45,065][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 18:07:45,065][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 18:07:45,065][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 18:07:45,229][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 18:07:45,261][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/b81d0f3b-7299-455d-afb5-a07ea58fe810
[2016-07-15 18:07:45,261][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/b81d0f3b-7299-455d-afb5-a07ea58fe810
[2016-07-15 18:07:45,262][ceph22][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-15 18:07:45,262][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:118b0ca4-fa68-4778-a400-610ef48b1bd0 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-15 18:07:46,278][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 18:07:46,278][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-15 18:07:46,279][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 18:07:46,543][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 18:07:46,607][ceph22][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-15 18:07:46,607][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-15 18:07:47,373][ceph22][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-15 18:07:47,373][ceph22][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 18:07:47,373][ceph22][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-15 18:07:47,374][ceph22][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 18:07:47,374][ceph22][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 18:07:47,374][ceph22][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-15 18:07:47,374][ceph22][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 18:07:47,374][ceph22][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 18:07:47,374][ceph22][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt.iqllz1 with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 18:07:47,375][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt.iqllz1
[2016-07-15 18:07:47,375][ceph22][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.iqllz1
[2016-07-15 18:07:47,375][ceph22][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.iqllz1/journal -> /dev/disk/by-partuuid/b81d0f3b-7299-455d-afb5-a07ea58fe810
[2016-07-15 18:07:47,407][ceph22][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.iqllz1
[2016-07-15 18:07:47,407][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.iqllz1
[2016-07-15 18:07:47,439][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-15 18:07:48,455][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 18:07:48,456][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 18:07:48,456][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 18:07:54,627][ceph22][INFO  ] checking OSD status...
[2016-07-15 18:07:54,628][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:07:54,631][ceph22][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 18:07:54,847][ceph_deploy.osd][DEBUG ] Host ceph22 is now ready for osd use.
[2016-07-15 18:07:55,580][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 18:07:55,581][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 18:07:55,599][ceph23][DEBUG ] detect machine type
[2016-07-15 18:07:55,604][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:07:55,606][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:07:55,624][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:07:55,625][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:07:55,626][ceph_deploy.osd][DEBUG ] Deploying osd to ceph23
[2016-07-15 18:07:55,626][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 18:07:55,629][ceph23][WARNING] osd keyring does not exist yet, creating one
[2016-07-15 18:07:55,629][ceph23][DEBUG ] create a keyring file
[2016-07-15 18:07:55,630][ceph_deploy.osd][DEBUG ] Preparing host ceph23 disk /dev/vdb journal None activate True
[2016-07-15 18:07:55,631][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:07:55,633][ceph23][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-15 18:07:55,701][ceph23][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-15 18:07:55,702][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-15 18:07:55,702][ceph23][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 18:07:55,703][ceph23][WARNING] backup header from main header.
[2016-07-15 18:07:55,703][ceph23][WARNING] 
[2016-07-15 18:07:55,703][ceph23][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 18:07:55,703][ceph23][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 18:07:55,703][ceph23][WARNING] 
[2016-07-15 18:07:55,703][ceph23][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 18:07:55,703][ceph23][WARNING] 
[2016-07-15 18:07:56,770][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 18:07:56,770][ceph23][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 18:07:56,770][ceph23][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 18:07:56,770][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 18:07:56,771][ceph23][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 18:07:56,771][ceph23][DEBUG ] other utilities.
[2016-07-15 18:07:56,771][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-15 18:07:57,787][ceph23][DEBUG ] Creating new GPT entries.
[2016-07-15 18:07:57,787][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:07:57,788][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-15 18:07:57,788][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:07:57,788][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 18:07:57,788][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 18:07:57,796][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 18:07:57,812][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 18:07:57,819][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 18:07:57,835][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 18:07:57,843][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 18:07:57,858][ceph23][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-15 18:07:57,859][ceph23][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-15 18:07:57,859][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:309db98e-d63a-43db-a72d-dbd7fcf5603f --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-15 18:07:58,875][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:07:58,875][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 18:07:58,875][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:07:59,039][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 18:07:59,103][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/309db98e-d63a-43db-a72d-dbd7fcf5603f
[2016-07-15 18:07:59,104][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/309db98e-d63a-43db-a72d-dbd7fcf5603f
[2016-07-15 18:07:59,104][ceph23][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-15 18:07:59,104][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:d9e32fbf-9cc0-4307-8b19-7866234f0620 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-15 18:08:00,120][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:08:00,121][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-15 18:08:00,121][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:08:00,385][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 18:08:00,417][ceph23][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-15 18:08:00,417][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-15 18:08:01,183][ceph23][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-15 18:08:01,183][ceph23][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 18:08:01,183][ceph23][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-15 18:08:01,183][ceph23][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 18:08:01,184][ceph23][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 18:08:01,184][ceph23][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-15 18:08:01,184][ceph23][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 18:08:01,184][ceph23][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 18:08:01,184][ceph23][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.feqKoM with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 18:08:01,184][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.feqKoM
[2016-07-15 18:08:01,184][ceph23][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.feqKoM
[2016-07-15 18:08:01,184][ceph23][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.feqKoM/journal -> /dev/disk/by-partuuid/309db98e-d63a-43db-a72d-dbd7fcf5603f
[2016-07-15 18:08:01,216][ceph23][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.feqKoM
[2016-07-15 18:08:01,216][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.feqKoM
[2016-07-15 18:08:01,232][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-15 18:08:02,298][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:08:02,298][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 18:08:02,299][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:08:08,370][ceph23][INFO  ] checking OSD status...
[2016-07-15 18:08:08,370][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:08:08,373][ceph23][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 18:08:08,538][ceph_deploy.osd][DEBUG ] Host ceph23 is now ready for osd use.
[2016-07-15 18:08:09,204][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 18:08:09,205][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 18:08:09,225][ceph23][DEBUG ] detect machine type
[2016-07-15 18:08:09,229][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:08:09,235][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:08:09,252][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:08:09,253][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:08:09,253][ceph_deploy.osd][DEBUG ] Preparing host ceph23 disk /dev/vdc journal None activate True
[2016-07-15 18:08:09,253][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:08:09,255][ceph23][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-15 18:08:09,323][ceph23][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-15 18:08:09,324][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-15 18:08:09,324][ceph23][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 18:08:09,324][ceph23][WARNING] backup header from main header.
[2016-07-15 18:08:09,324][ceph23][WARNING] 
[2016-07-15 18:08:09,325][ceph23][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 18:08:09,326][ceph23][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 18:08:09,326][ceph23][WARNING] 
[2016-07-15 18:08:09,326][ceph23][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 18:08:09,326][ceph23][WARNING] 
[2016-07-15 18:08:10,392][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 18:08:10,392][ceph23][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 18:08:10,393][ceph23][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 18:08:10,393][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 18:08:10,393][ceph23][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 18:08:10,393][ceph23][DEBUG ] other utilities.
[2016-07-15 18:08:10,393][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-15 18:08:11,410][ceph23][DEBUG ] Creating new GPT entries.
[2016-07-15 18:08:11,410][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:08:11,410][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-15 18:08:11,411][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 18:08:11,411][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 18:08:11,411][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 18:08:11,411][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 18:08:11,427][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 18:08:11,442][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 18:08:11,458][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 18:08:11,466][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 18:08:11,481][ceph23][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-15 18:08:11,482][ceph23][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-15 18:08:11,482][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:7f5c7dd9-4cd8-4d89-bdc4-8a10ff37be69 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-15 18:08:12,498][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:08:12,498][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 18:08:12,499][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 18:08:12,663][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 18:08:12,726][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/7f5c7dd9-4cd8-4d89-bdc4-8a10ff37be69
[2016-07-15 18:08:12,727][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/7f5c7dd9-4cd8-4d89-bdc4-8a10ff37be69
[2016-07-15 18:08:12,727][ceph23][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-15 18:08:12,727][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:0d663501-7a82-4603-8936-72f2423416ed --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-15 18:08:13,743][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:08:13,743][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-15 18:08:13,744][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 18:08:14,008][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 18:08:14,040][ceph23][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-15 18:08:14,041][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-15 18:08:14,806][ceph23][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-15 18:08:14,807][ceph23][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 18:08:14,807][ceph23][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-15 18:08:14,807][ceph23][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 18:08:14,807][ceph23][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 18:08:14,807][ceph23][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-15 18:08:14,807][ceph23][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 18:08:14,808][ceph23][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 18:08:14,808][ceph23][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt.dICYUG with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 18:08:14,808][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt.dICYUG
[2016-07-15 18:08:14,815][ceph23][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.dICYUG
[2016-07-15 18:08:14,816][ceph23][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.dICYUG/journal -> /dev/disk/by-partuuid/7f5c7dd9-4cd8-4d89-bdc4-8a10ff37be69
[2016-07-15 18:08:14,847][ceph23][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.dICYUG
[2016-07-15 18:08:14,847][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.dICYUG
[2016-07-15 18:08:14,879][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-15 18:08:15,896][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:08:15,896][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 18:08:15,897][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 18:08:22,068][ceph23][INFO  ] checking OSD status...
[2016-07-15 18:08:22,069][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:08:22,072][ceph23][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 18:08:22,287][ceph_deploy.osd][DEBUG ] Host ceph23 is now ready for osd use.
[2016-07-15 18:17:43,491][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:17:43,492][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph21
[2016-07-15 18:17:43,492][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:17:43,492][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:17:43,492][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:17:43,492][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 18:17:43,492][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:17:43,493][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ff64d56eb00>
[2016-07-15 18:17:43,493][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:17:43,493][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-15 18:17:43,493][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7ff64de851b8>
[2016-07-15 18:17:43,493][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:17:43,493][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:17:43,493][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 18:17:43,493][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 18:17:43,493][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph21
[2016-07-15 18:17:43,494][ceph_deploy.install][DEBUG ] Detecting platform for host ceph21 ...
[2016-07-15 18:17:44,186][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:17:44,188][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:17:44,203][ceph21][DEBUG ] detect machine type
[2016-07-15 18:17:44,207][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:17:44,210][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:17:44,220][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:17:44,221][ceph21][INFO  ] Purging Ceph on ceph21
[2016-07-15 18:17:44,222][ceph21][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 18:17:44,640][ceph21][DEBUG ] Reading package lists...
[2016-07-15 18:17:45,005][ceph21][DEBUG ] Building dependency tree...
[2016-07-15 18:17:45,005][ceph21][DEBUG ] Reading state information...
[2016-07-15 18:17:45,169][ceph21][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 18:17:45,169][ceph21][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 18:17:45,169][ceph21][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 18:17:45,169][ceph21][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 18:17:45,170][ceph21][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 18:17:45,170][ceph21][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-15 18:17:45,170][ceph21][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libnspr4
[2016-07-15 18:17:45,170][ceph21][DEBUG ]   libnss3 libnss3-nssdb libxslt1.1 xmlstarlet
[2016-07-15 18:17:45,170][ceph21][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-15 18:17:45,170][ceph21][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 216 not upgraded.
[2016-07-15 18:17:45,270][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:17:45,270][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph21
[2016-07-15 18:17:45,270][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:17:45,271][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:17:45,271][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:17:45,271][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 18:17:45,271][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:17:45,271][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3c452bf1b8>
[2016-07-15 18:17:45,271][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:17:45,271][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-15 18:17:45,271][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f3c45bce230>
[2016-07-15 18:17:45,271][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:17:45,271][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:17:45,271][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph21
[2016-07-15 18:17:45,966][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:17:45,967][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:17:45,984][ceph21][DEBUG ] detect machine type
[2016-07-15 18:17:45,988][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:17:45,991][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:17:46,010][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:17:46,680][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:17:46,681][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:17:46,698][ceph21][DEBUG ] detect machine type
[2016-07-15 18:17:46,702][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:17:46,704][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:17:46,713][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:17:46,713][ceph21][INFO  ] purging data on ceph21
[2016-07-15 18:17:46,714][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 18:17:46,725][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 18:17:56,672][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:17:56,672][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph22
[2016-07-15 18:17:56,672][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:17:56,673][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:17:56,673][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:17:56,673][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 18:17:56,673][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:17:56,673][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5fcbbd5b00>
[2016-07-15 18:17:56,673][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:17:56,673][ceph_deploy.cli][INFO  ]  host                          : ['ceph22']
[2016-07-15 18:17:56,674][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f5fcc4ec1b8>
[2016-07-15 18:17:56,674][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:17:56,674][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:17:56,674][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 18:17:56,674][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 18:17:56,674][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph22
[2016-07-15 18:17:56,674][ceph_deploy.install][DEBUG ] Detecting platform for host ceph22 ...
[2016-07-15 18:17:57,358][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 18:17:57,359][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 18:17:57,376][ceph22][DEBUG ] detect machine type
[2016-07-15 18:17:57,380][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:17:57,382][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:17:57,401][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:17:57,401][ceph22][INFO  ] Purging Ceph on ceph22
[2016-07-15 18:17:57,403][ceph22][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 18:17:57,670][ceph22][DEBUG ] Reading package lists...
[2016-07-15 18:17:57,985][ceph22][DEBUG ] Building dependency tree...
[2016-07-15 18:17:57,985][ceph22][DEBUG ] Reading state information...
[2016-07-15 18:17:58,199][ceph22][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 18:17:58,200][ceph22][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 18:17:58,200][ceph22][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 18:17:58,200][ceph22][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 18:17:58,200][ceph22][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 18:17:58,200][ceph22][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 218 not upgraded.
[2016-07-15 18:17:58,294][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:17:58,294][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph22
[2016-07-15 18:17:58,294][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:17:58,294][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:17:58,294][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:17:58,295][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 18:17:58,295][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:17:58,295][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ff5c797d1b8>
[2016-07-15 18:17:58,295][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:17:58,295][ceph_deploy.cli][INFO  ]  host                          : ['ceph22']
[2016-07-15 18:17:58,295][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7ff5c828c230>
[2016-07-15 18:17:58,295][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:17:58,295][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:17:58,296][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph22
[2016-07-15 18:17:58,982][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 18:17:58,982][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 18:17:58,999][ceph22][DEBUG ] detect machine type
[2016-07-15 18:17:59,003][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:17:59,005][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:17:59,016][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:17:59,706][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 18:17:59,707][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 18:17:59,724][ceph22][DEBUG ] detect machine type
[2016-07-15 18:17:59,728][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:17:59,731][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:17:59,748][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:17:59,748][ceph22][INFO  ] purging data on ceph22
[2016-07-15 18:17:59,750][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 18:17:59,759][ceph22][WARNING] OSDs may still be mounted, trying to unmount them
[2016-07-15 18:17:59,760][ceph22][INFO  ] Running command: find /var/lib/ceph -mindepth 1 -maxdepth 2 -type d -exec umount {} ;
[2016-07-15 18:17:59,771][ceph22][WARNING] umount: /var/lib/ceph/osd: not mounted
[2016-07-15 18:17:59,836][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 18:17:59,848][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 18:18:09,983][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:18:09,984][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph23
[2016-07-15 18:18:09,984][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:18:09,984][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:18:09,984][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:18:09,984][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 18:18:09,984][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:18:09,984][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f55e0aacb00>
[2016-07-15 18:18:09,985][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:18:09,985][ceph_deploy.cli][INFO  ]  host                          : ['ceph23']
[2016-07-15 18:18:09,985][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f55e13c31b8>
[2016-07-15 18:18:09,985][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:18:09,985][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:18:09,985][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 18:18:09,985][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 18:18:09,985][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph23
[2016-07-15 18:18:09,986][ceph_deploy.install][DEBUG ] Detecting platform for host ceph23 ...
[2016-07-15 18:18:10,686][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 18:18:10,687][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 18:18:10,705][ceph23][DEBUG ] detect machine type
[2016-07-15 18:18:10,709][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:18:10,711][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:18:10,722][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:18:10,722][ceph23][INFO  ] Purging Ceph on ceph23
[2016-07-15 18:18:10,724][ceph23][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 18:18:11,142][ceph23][DEBUG ] Reading package lists...
[2016-07-15 18:18:11,456][ceph23][DEBUG ] Building dependency tree...
[2016-07-15 18:18:11,456][ceph23][DEBUG ] Reading state information...
[2016-07-15 18:18:11,670][ceph23][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 18:18:11,671][ceph23][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 18:18:11,671][ceph23][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 18:18:11,671][ceph23][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 18:18:11,671][ceph23][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 18:18:11,671][ceph23][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-15 18:18:11,671][ceph23][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libxslt1.1
[2016-07-15 18:18:11,672][ceph23][DEBUG ]   xmlstarlet
[2016-07-15 18:18:11,672][ceph23][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-15 18:18:11,703][ceph23][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 218 not upgraded.
[2016-07-15 18:18:11,803][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:18:11,803][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph23
[2016-07-15 18:18:11,803][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:18:11,803][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:18:11,803][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:18:11,804][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 18:18:11,804][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:18:11,804][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f55cad561b8>
[2016-07-15 18:18:11,804][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:18:11,804][ceph_deploy.cli][INFO  ]  host                          : ['ceph23']
[2016-07-15 18:18:11,804][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f55cb665230>
[2016-07-15 18:18:11,804][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:18:11,804][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:18:11,804][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph23
[2016-07-15 18:18:12,486][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 18:18:12,487][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 18:18:12,504][ceph23][DEBUG ] detect machine type
[2016-07-15 18:18:12,507][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:18:12,510][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:18:12,520][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:18:13,196][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 18:18:13,197][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 18:18:13,212][ceph23][DEBUG ] detect machine type
[2016-07-15 18:18:13,216][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:18:13,218][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:18:13,228][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:18:13,228][ceph23][INFO  ] purging data on ceph23
[2016-07-15 18:18:13,229][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 18:18:13,240][ceph23][WARNING] OSDs may still be mounted, trying to unmount them
[2016-07-15 18:18:13,241][ceph23][INFO  ] Running command: find /var/lib/ceph -mindepth 1 -maxdepth 2 -type d -exec umount {} ;
[2016-07-15 18:18:13,251][ceph23][WARNING] umount: /var/lib/ceph/osd: not mounted
[2016-07-15 18:18:13,316][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 18:18:13,328][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 18:21:54,330][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:21:54,330][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy new ceph21
[2016-07-15 18:21:54,331][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:21:54,331][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:21:54,331][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7ff2a8f96410>
[2016-07-15 18:21:54,331][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:21:54,331][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 18:21:54,331][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:21:54,331][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ff2a86f8ef0>
[2016-07-15 18:21:54,331][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:21:54,332][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2016-07-15 18:21:54,332][ceph_deploy.cli][INFO  ]  mon                           : ['ceph21']
[2016-07-15 18:21:54,332][ceph_deploy.cli][INFO  ]  public_network                : None
[2016-07-15 18:21:54,332][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:21:54,332][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2016-07-15 18:21:54,332][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:21:54,332][ceph_deploy.cli][INFO  ]  fsid                          : None
[2016-07-15 18:21:54,332][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2016-07-15 18:21:54,333][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2016-07-15 18:21:54,361][ceph21][DEBUG ] connected to host: cephAdmin 
[2016-07-15 18:21:54,366][ceph21][INFO  ] Running command: ssh -CT -o BatchMode=yes ceph21
[2016-07-15 18:21:55,420][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:21:55,420][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:21:55,437][ceph21][DEBUG ] detect machine type
[2016-07-15 18:21:55,441][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:21:55,444][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:21:55,454][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:21:55,456][ceph21][INFO  ] Running command: /bin/ip link show
[2016-07-15 18:21:55,466][ceph21][INFO  ] Running command: /bin/ip addr show
[2016-07-15 18:21:55,476][ceph21][DEBUG ] IP addresses found: ['10.1.0.44']
[2016-07-15 18:21:55,476][ceph_deploy.new][DEBUG ] Resolving host ceph21
[2016-07-15 18:21:55,476][ceph_deploy.new][DEBUG ] Monitor ceph21 at 10.1.0.44
[2016-07-15 18:21:55,476][ceph_deploy.new][DEBUG ] Monitor initial members are ['ceph21']
[2016-07-15 18:21:55,477][ceph_deploy.new][DEBUG ] Monitor addrs are ['10.1.0.44']
[2016-07-15 18:21:55,477][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2016-07-15 18:21:55,477][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2016-07-15 18:21:55,477][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2016-07-15 18:22:18,903][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:22:18,904][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy mon create-initial
[2016-07-15 18:22:18,904][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:22:18,904][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:22:18,904][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:22:18,904][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 18:22:18,904][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2016-07-15 18:22:18,904][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:22:18,904][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f4c7dcc5290>
[2016-07-15 18:22:18,904][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:22:18,904][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f4c7dca66e0>
[2016-07-15 18:22:18,904][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:22:18,905][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:22:18,905][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2016-07-15 18:22:18,906][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts ceph21
[2016-07-15 18:22:18,907][ceph_deploy.mon][DEBUG ] detecting platform for host ceph21 ...
[2016-07-15 18:22:19,606][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:22:19,606][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:22:19,623][ceph21][DEBUG ] detect machine type
[2016-07-15 18:22:19,626][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:22:19,629][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:22:19,640][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:22:19,641][ceph_deploy.mon][INFO  ] distro info: Ubuntu 14.04 trusty
[2016-07-15 18:22:19,641][ceph21][DEBUG ] determining if provided host has same hostname in remote
[2016-07-15 18:22:19,642][ceph21][DEBUG ] get remote short hostname
[2016-07-15 18:22:19,642][ceph21][DEBUG ] deploying mon to ceph21
[2016-07-15 18:22:19,642][ceph21][DEBUG ] get remote short hostname
[2016-07-15 18:22:19,643][ceph21][DEBUG ] remote hostname: ceph21
[2016-07-15 18:22:19,646][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 18:22:19,648][ceph21][DEBUG ] create the mon path if it does not exist
[2016-07-15 18:22:19,649][ceph21][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-15 18:22:19,649][ceph21][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-15 18:22:19,650][ceph21][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 18:22:19,650][ceph21][DEBUG ] create the monitor keyring file
[2016-07-15 18:22:19,653][ceph21][INFO  ] Running command: ceph-mon --cluster ceph --mkfs -i ceph21 --keyring /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 18:22:19,689][ceph21][DEBUG ] ceph-mon: mon.noname-a 10.1.0.44:6789/0 is local, renaming to mon.ceph21
[2016-07-15 18:22:19,689][ceph21][DEBUG ] ceph-mon: set fsid to f47d6e37-d1aa-4d64-a323-c70e887eb766
[2016-07-15 18:22:19,689][ceph21][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-ceph21 for mon.ceph21
[2016-07-15 18:22:19,689][ceph21][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 18:22:19,691][ceph21][DEBUG ] create a done file to avoid re-doing the mon deployment
[2016-07-15 18:22:19,692][ceph21][DEBUG ] create the init path if it does not exist
[2016-07-15 18:22:19,694][ceph21][INFO  ] Running command: initctl emit ceph-mon cluster=ceph id=ceph21
[2016-07-15 18:22:21,734][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 18:22:21,799][ceph21][DEBUG ] ********************************************************************************
[2016-07-15 18:22:21,799][ceph21][DEBUG ] status for monitor: mon.ceph21
[2016-07-15 18:22:21,800][ceph21][DEBUG ] {
[2016-07-15 18:22:21,800][ceph21][DEBUG ]   "election_epoch": 2, 
[2016-07-15 18:22:21,800][ceph21][DEBUG ]   "extra_probe_peers": [], 
[2016-07-15 18:22:21,800][ceph21][DEBUG ]   "monmap": {
[2016-07-15 18:22:21,800][ceph21][DEBUG ]     "created": "0.000000", 
[2016-07-15 18:22:21,800][ceph21][DEBUG ]     "epoch": 1, 
[2016-07-15 18:22:21,800][ceph21][DEBUG ]     "fsid": "f47d6e37-d1aa-4d64-a323-c70e887eb766", 
[2016-07-15 18:22:21,801][ceph21][DEBUG ]     "modified": "0.000000", 
[2016-07-15 18:22:21,801][ceph21][DEBUG ]     "mons": [
[2016-07-15 18:22:21,801][ceph21][DEBUG ]       {
[2016-07-15 18:22:21,801][ceph21][DEBUG ]         "addr": "10.1.0.44:6789/0", 
[2016-07-15 18:22:21,801][ceph21][DEBUG ]         "name": "ceph21", 
[2016-07-15 18:22:21,801][ceph21][DEBUG ]         "rank": 0
[2016-07-15 18:22:21,801][ceph21][DEBUG ]       }
[2016-07-15 18:22:21,801][ceph21][DEBUG ]     ]
[2016-07-15 18:22:21,802][ceph21][DEBUG ]   }, 
[2016-07-15 18:22:21,802][ceph21][DEBUG ]   "name": "ceph21", 
[2016-07-15 18:22:21,802][ceph21][DEBUG ]   "outside_quorum": [], 
[2016-07-15 18:22:21,802][ceph21][DEBUG ]   "quorum": [
[2016-07-15 18:22:21,802][ceph21][DEBUG ]     0
[2016-07-15 18:22:21,802][ceph21][DEBUG ]   ], 
[2016-07-15 18:22:21,802][ceph21][DEBUG ]   "rank": 0, 
[2016-07-15 18:22:21,802][ceph21][DEBUG ]   "state": "leader", 
[2016-07-15 18:22:21,802][ceph21][DEBUG ]   "sync_provider": []
[2016-07-15 18:22:21,803][ceph21][DEBUG ] }
[2016-07-15 18:22:21,803][ceph21][DEBUG ] ********************************************************************************
[2016-07-15 18:22:21,803][ceph21][INFO  ] monitor: mon.ceph21 is running
[2016-07-15 18:22:21,805][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 18:22:21,870][ceph_deploy.mon][INFO  ] processing monitor mon.ceph21
[2016-07-15 18:22:22,552][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:22:22,553][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:22:22,569][ceph21][DEBUG ] detect machine type
[2016-07-15 18:22:22,573][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:22:22,575][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:22:22,584][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:22:22,587][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 18:22:22,652][ceph_deploy.mon][INFO  ] mon.ceph21 monitor has reached quorum!
[2016-07-15 18:22:22,652][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2016-07-15 18:22:22,652][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2016-07-15 18:22:22,652][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /etc/ceph/ceph.client.admin.keyring
[2016-07-15 18:22:23,382][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:22:23,383][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:22:23,410][ceph21][DEBUG ] detect machine type
[2016-07-15 18:22:23,415][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:22:23,418][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:22:23,436][ceph21][DEBUG ] fetch remote file
[2016-07-15 18:22:23,437][ceph_deploy.gatherkeys][DEBUG ] Got ceph.client.admin.keyring key from ceph21.
[2016-07-15 18:22:23,437][ceph_deploy.gatherkeys][DEBUG ] Have ceph.mon.keyring
[2016-07-15 18:22:23,438][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-osd/ceph.keyring
[2016-07-15 18:22:24,145][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:22:24,146][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:22:24,166][ceph21][DEBUG ] detect machine type
[2016-07-15 18:22:24,171][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:22:24,174][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:22:24,191][ceph21][DEBUG ] fetch remote file
[2016-07-15 18:22:24,192][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-osd.keyring key from ceph21.
[2016-07-15 18:22:24,192][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-mds/ceph.keyring
[2016-07-15 18:22:24,896][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:22:24,897][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:22:24,914][ceph21][DEBUG ] detect machine type
[2016-07-15 18:22:24,918][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:22:24,920][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:22:24,929][ceph21][DEBUG ] fetch remote file
[2016-07-15 18:22:24,930][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-mds.keyring key from ceph21.
[2016-07-15 18:22:24,931][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-rgw/ceph.keyring
[2016-07-15 18:22:25,622][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:22:25,623][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:22:25,639][ceph21][DEBUG ] detect machine type
[2016-07-15 18:22:25,643][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:22:25,646][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:22:25,655][ceph21][DEBUG ] fetch remote file
[2016-07-15 18:22:25,656][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-rgw.keyring key from ceph21.
[2016-07-15 18:22:37,230][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:22:37,231][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf osd create --zap-disk ceph22:/dev/vdb ceph22:/dev/vdc ceph23:/dev/vdb ceph23:/dev/vdc
[2016-07-15 18:22:37,231][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:22:37,231][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:22:37,231][ceph_deploy.cli][INFO  ]  disk                          : [('ceph22', '/dev/vdb', None), ('ceph22', '/dev/vdc', None), ('ceph23', '/dev/vdb', None), ('ceph23', '/dev/vdc', None)]
[2016-07-15 18:22:37,231][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2016-07-15 18:22:37,231][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:22:37,231][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2016-07-15 18:22:37,231][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-15 18:22:37,231][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-15 18:22:37,232][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2016-07-15 18:22:37,232][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:22:37,232][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7170edd1b8>
[2016-07-15 18:22:37,232][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:22:37,232][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2016-07-15 18:22:37,232][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f7170eae578>
[2016-07-15 18:22:37,232][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:22:37,232][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:22:37,232][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2016-07-15 18:22:37,233][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks ceph22:/dev/vdb: ceph22:/dev/vdc: ceph23:/dev/vdb: ceph23:/dev/vdc:
[2016-07-15 18:22:37,916][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 18:22:37,917][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 18:22:37,934][ceph22][DEBUG ] detect machine type
[2016-07-15 18:22:37,938][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:22:37,941][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:22:37,960][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:22:37,961][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:22:37,961][ceph_deploy.osd][DEBUG ] Deploying osd to ceph22
[2016-07-15 18:22:37,962][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 18:22:37,964][ceph22][WARNING] osd keyring does not exist yet, creating one
[2016-07-15 18:22:37,964][ceph22][DEBUG ] create a keyring file
[2016-07-15 18:22:37,965][ceph_deploy.osd][DEBUG ] Preparing host ceph22 disk /dev/vdb journal None activate True
[2016-07-15 18:22:37,966][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:22:37,968][ceph22][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-15 18:22:38,035][ceph22][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-15 18:22:38,035][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-15 18:22:38,038][ceph22][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 18:22:38,038][ceph22][WARNING] backup header from main header.
[2016-07-15 18:22:38,039][ceph22][WARNING] 
[2016-07-15 18:22:38,039][ceph22][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 18:22:38,039][ceph22][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 18:22:38,039][ceph22][WARNING] 
[2016-07-15 18:22:38,039][ceph22][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 18:22:38,039][ceph22][WARNING] 
[2016-07-15 18:22:39,055][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 18:22:39,055][ceph22][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 18:22:39,055][ceph22][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 18:22:39,056][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 18:22:39,056][ceph22][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 18:22:39,056][ceph22][DEBUG ] other utilities.
[2016-07-15 18:22:39,057][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-15 18:22:40,123][ceph22][DEBUG ] Creating new GPT entries.
[2016-07-15 18:22:40,124][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 18:22:40,124][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-15 18:22:40,124][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:22:40,124][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 18:22:40,125][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 18:22:40,125][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 18:22:40,140][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 18:22:40,156][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 18:22:40,164][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 18:22:40,179][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 18:22:40,183][ceph22][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-15 18:22:40,183][ceph22][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-15 18:22:40,183][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:90190285-9e24-4416-8f76-b66ee8c7dc70 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-15 18:22:41,199][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 18:22:41,201][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 18:22:41,201][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:22:41,365][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 18:22:41,429][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/90190285-9e24-4416-8f76-b66ee8c7dc70
[2016-07-15 18:22:41,429][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/90190285-9e24-4416-8f76-b66ee8c7dc70
[2016-07-15 18:22:41,430][ceph22][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-15 18:22:41,430][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:b1469059-5225-47ce-b74b-8d1263551a78 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-15 18:22:42,446][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 18:22:42,447][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-15 18:22:42,447][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:22:42,712][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 18:22:42,776][ceph22][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-15 18:22:42,776][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-15 18:22:43,542][ceph22][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-15 18:22:43,542][ceph22][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 18:22:43,542][ceph22][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-15 18:22:43,543][ceph22][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 18:22:43,543][ceph22][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 18:22:43,543][ceph22][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-15 18:22:43,543][ceph22][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 18:22:43,543][ceph22][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 18:22:43,543][ceph22][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.Jh0Ax4 with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 18:22:43,544][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.Jh0Ax4
[2016-07-15 18:22:43,544][ceph22][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.Jh0Ax4
[2016-07-15 18:22:43,544][ceph22][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.Jh0Ax4/journal -> /dev/disk/by-partuuid/90190285-9e24-4416-8f76-b66ee8c7dc70
[2016-07-15 18:22:43,544][ceph22][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.Jh0Ax4
[2016-07-15 18:22:43,544][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.Jh0Ax4
[2016-07-15 18:22:43,560][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-15 18:22:44,626][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 18:22:44,627][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 18:22:44,627][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:22:50,649][ceph22][INFO  ] checking OSD status...
[2016-07-15 18:22:50,649][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:22:50,653][ceph22][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 18:22:50,869][ceph_deploy.osd][DEBUG ] Host ceph22 is now ready for osd use.
[2016-07-15 18:22:51,534][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 18:22:51,535][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 18:22:51,551][ceph22][DEBUG ] detect machine type
[2016-07-15 18:22:51,554][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:22:51,557][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:22:51,566][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:22:51,567][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:22:51,567][ceph_deploy.osd][DEBUG ] Preparing host ceph22 disk /dev/vdc journal None activate True
[2016-07-15 18:22:51,567][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:22:51,569][ceph22][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-15 18:22:51,636][ceph22][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-15 18:22:51,636][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-15 18:22:51,637][ceph22][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 18:22:51,637][ceph22][WARNING] backup header from main header.
[2016-07-15 18:22:51,637][ceph22][WARNING] 
[2016-07-15 18:22:51,637][ceph22][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 18:22:51,637][ceph22][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 18:22:51,637][ceph22][WARNING] 
[2016-07-15 18:22:51,637][ceph22][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 18:22:51,637][ceph22][WARNING] 
[2016-07-15 18:22:52,704][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 18:22:52,704][ceph22][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 18:22:52,704][ceph22][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 18:22:52,704][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 18:22:52,704][ceph22][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 18:22:52,704][ceph22][DEBUG ] other utilities.
[2016-07-15 18:22:52,704][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-15 18:22:53,720][ceph22][DEBUG ] Creating new GPT entries.
[2016-07-15 18:22:53,720][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 18:22:53,721][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-15 18:22:53,721][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 18:22:53,721][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 18:22:53,721][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 18:22:53,721][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 18:22:53,737][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 18:22:53,752][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 18:22:53,760][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 18:22:53,775][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 18:22:53,779][ceph22][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-15 18:22:53,779][ceph22][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-15 18:22:53,779][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:3e6e2350-3733-4680-a83a-8b36214816c6 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-15 18:22:54,845][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 18:22:54,845][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 18:22:54,845][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 18:22:54,959][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 18:22:55,023][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/3e6e2350-3733-4680-a83a-8b36214816c6
[2016-07-15 18:22:55,023][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/3e6e2350-3733-4680-a83a-8b36214816c6
[2016-07-15 18:22:55,024][ceph22][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-15 18:22:55,024][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:0a123869-2b70-4f3a-aa9e-32953f543511 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-15 18:22:56,040][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 18:22:56,040][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-15 18:22:56,040][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 18:22:56,304][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 18:22:56,336][ceph22][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-15 18:22:56,336][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-15 18:22:57,102][ceph22][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-15 18:22:57,102][ceph22][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 18:22:57,103][ceph22][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-15 18:22:57,103][ceph22][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 18:22:57,103][ceph22][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 18:22:57,103][ceph22][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-15 18:22:57,103][ceph22][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 18:22:57,104][ceph22][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 18:22:57,104][ceph22][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt.z94SNB with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 18:22:57,104][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt.z94SNB
[2016-07-15 18:22:57,104][ceph22][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.z94SNB
[2016-07-15 18:22:57,105][ceph22][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.z94SNB/journal -> /dev/disk/by-partuuid/3e6e2350-3733-4680-a83a-8b36214816c6
[2016-07-15 18:22:57,120][ceph22][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.z94SNB
[2016-07-15 18:22:57,120][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.z94SNB
[2016-07-15 18:22:57,152][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-15 18:22:58,168][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 18:22:58,168][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 18:22:58,169][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 18:23:04,339][ceph22][INFO  ] checking OSD status...
[2016-07-15 18:23:04,339][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:23:04,343][ceph22][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 18:23:04,558][ceph_deploy.osd][DEBUG ] Host ceph22 is now ready for osd use.
[2016-07-15 18:23:05,215][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 18:23:05,216][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 18:23:05,234][ceph23][DEBUG ] detect machine type
[2016-07-15 18:23:05,237][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:23:05,240][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:23:05,248][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:23:05,249][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:23:05,249][ceph_deploy.osd][DEBUG ] Deploying osd to ceph23
[2016-07-15 18:23:05,250][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 18:23:05,252][ceph23][WARNING] osd keyring does not exist yet, creating one
[2016-07-15 18:23:05,252][ceph23][DEBUG ] create a keyring file
[2016-07-15 18:23:05,253][ceph_deploy.osd][DEBUG ] Preparing host ceph23 disk /dev/vdb journal None activate True
[2016-07-15 18:23:05,253][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:23:05,255][ceph23][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-15 18:23:05,321][ceph23][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-15 18:23:05,321][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-15 18:23:05,321][ceph23][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 18:23:05,322][ceph23][WARNING] backup header from main header.
[2016-07-15 18:23:05,322][ceph23][WARNING] 
[2016-07-15 18:23:05,322][ceph23][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 18:23:05,322][ceph23][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 18:23:05,322][ceph23][WARNING] 
[2016-07-15 18:23:05,322][ceph23][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 18:23:05,322][ceph23][WARNING] 
[2016-07-15 18:23:06,338][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 18:23:06,338][ceph23][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 18:23:06,338][ceph23][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 18:23:06,339][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 18:23:06,339][ceph23][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 18:23:06,339][ceph23][DEBUG ] other utilities.
[2016-07-15 18:23:06,339][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-15 18:23:07,355][ceph23][DEBUG ] Creating new GPT entries.
[2016-07-15 18:23:07,355][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:23:07,355][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-15 18:23:07,355][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:23:07,371][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 18:23:07,386][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 18:23:07,394][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 18:23:07,410][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 18:23:07,417][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 18:23:07,433][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 18:23:07,441][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 18:23:07,456][ceph23][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-15 18:23:07,457][ceph23][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-15 18:23:07,457][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:a7995a52-390e-4e36-a6b5-2fa31696ddc3 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-15 18:23:08,472][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:23:08,473][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 18:23:08,473][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:23:08,637][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 18:23:08,701][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/a7995a52-390e-4e36-a6b5-2fa31696ddc3
[2016-07-15 18:23:08,701][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/a7995a52-390e-4e36-a6b5-2fa31696ddc3
[2016-07-15 18:23:08,701][ceph23][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-15 18:23:08,702][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:b5bc1bea-06d8-4c64-b779-cc4dffb32ff6 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-15 18:23:09,718][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:23:09,718][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-15 18:23:09,719][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:23:09,983][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 18:23:10,015][ceph23][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-15 18:23:10,015][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-15 18:23:10,781][ceph23][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-15 18:23:10,781][ceph23][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 18:23:10,781][ceph23][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-15 18:23:10,781][ceph23][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 18:23:10,782][ceph23][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 18:23:10,782][ceph23][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-15 18:23:10,782][ceph23][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 18:23:10,782][ceph23][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 18:23:10,782][ceph23][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.aFugg2 with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 18:23:10,782][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.aFugg2
[2016-07-15 18:23:10,783][ceph23][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.aFugg2
[2016-07-15 18:23:10,783][ceph23][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.aFugg2/journal -> /dev/disk/by-partuuid/a7995a52-390e-4e36-a6b5-2fa31696ddc3
[2016-07-15 18:23:10,798][ceph23][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.aFugg2
[2016-07-15 18:23:10,799][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.aFugg2
[2016-07-15 18:23:10,830][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-15 18:23:11,846][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:23:11,847][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 18:23:11,847][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 18:23:18,117][ceph23][INFO  ] checking OSD status...
[2016-07-15 18:23:18,117][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:23:18,120][ceph23][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 18:23:18,336][ceph_deploy.osd][DEBUG ] Host ceph23 is now ready for osd use.
[2016-07-15 18:23:19,014][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 18:23:19,015][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 18:23:19,030][ceph23][DEBUG ] detect machine type
[2016-07-15 18:23:19,034][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:23:19,037][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:23:19,053][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:23:19,054][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 18:23:19,055][ceph_deploy.osd][DEBUG ] Preparing host ceph23 disk /dev/vdc journal None activate True
[2016-07-15 18:23:19,055][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:23:19,056][ceph23][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-15 18:23:19,123][ceph23][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-15 18:23:19,124][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-15 18:23:19,124][ceph23][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 18:23:19,124][ceph23][WARNING] backup header from main header.
[2016-07-15 18:23:19,124][ceph23][WARNING] 
[2016-07-15 18:23:19,125][ceph23][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 18:23:19,126][ceph23][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 18:23:19,127][ceph23][WARNING] 
[2016-07-15 18:23:19,127][ceph23][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 18:23:19,127][ceph23][WARNING] 
[2016-07-15 18:23:20,193][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 18:23:20,193][ceph23][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 18:23:20,194][ceph23][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 18:23:20,194][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 18:23:20,194][ceph23][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 18:23:20,194][ceph23][DEBUG ] other utilities.
[2016-07-15 18:23:20,194][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-15 18:23:21,211][ceph23][DEBUG ] Creating new GPT entries.
[2016-07-15 18:23:21,211][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:23:21,211][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-15 18:23:21,212][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 18:23:21,212][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 18:23:21,212][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 18:23:21,220][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 18:23:21,235][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 18:23:21,270][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 18:23:21,272][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 18:23:21,287][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 18:23:21,303][ceph23][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-15 18:23:21,303][ceph23][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-15 18:23:21,304][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:0d3788f4-2392-43ba-aeb2-a59ba264ea00 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-15 18:23:22,370][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:23:22,370][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 18:23:22,371][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 18:23:22,485][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 18:23:22,549][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/0d3788f4-2392-43ba-aeb2-a59ba264ea00
[2016-07-15 18:23:22,549][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/0d3788f4-2392-43ba-aeb2-a59ba264ea00
[2016-07-15 18:23:22,549][ceph23][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-15 18:23:22,549][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:1e10c68c-c778-4b12-91f3-af514d28dbad --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-15 18:23:23,565][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:23:23,567][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-15 18:23:23,567][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 18:23:23,831][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 18:23:23,863][ceph23][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-15 18:23:23,863][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-15 18:23:24,629][ceph23][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-15 18:23:24,629][ceph23][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 18:23:24,629][ceph23][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-15 18:23:24,629][ceph23][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 18:23:24,629][ceph23][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 18:23:24,630][ceph23][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-15 18:23:24,630][ceph23][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 18:23:24,630][ceph23][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 18:23:24,630][ceph23][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt.eNtAEl with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 18:23:24,630][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt.eNtAEl
[2016-07-15 18:23:24,630][ceph23][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.eNtAEl
[2016-07-15 18:23:24,630][ceph23][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.eNtAEl/journal -> /dev/disk/by-partuuid/0d3788f4-2392-43ba-aeb2-a59ba264ea00
[2016-07-15 18:23:24,638][ceph23][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.eNtAEl
[2016-07-15 18:23:24,638][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.eNtAEl
[2016-07-15 18:23:24,670][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-15 18:23:25,736][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 18:23:25,737][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 18:23:25,737][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 18:23:31,906][ceph23][INFO  ] checking OSD status...
[2016-07-15 18:23:31,906][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:23:31,910][ceph23][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 18:23:32,126][ceph_deploy.osd][DEBUG ] Host ceph23 is now ready for osd use.
[2016-07-15 18:25:20,530][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 18:25:20,531][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf admin ceph21 ceph22 ceph23
[2016-07-15 18:25:20,531][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 18:25:20,531][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 18:25:20,531][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 18:25:20,531][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-15 18:25:20,531][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 18:25:20,531][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3a875f05a8>
[2016-07-15 18:25:20,531][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 18:25:20,531][ceph_deploy.cli][INFO  ]  client                        : ['ceph21', 'ceph22', 'ceph23']
[2016-07-15 18:25:20,531][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f3a87f137d0>
[2016-07-15 18:25:20,532][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 18:25:20,532][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 18:25:20,533][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph21
[2016-07-15 18:25:21,251][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 18:25:21,252][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 18:25:21,270][ceph21][DEBUG ] detect machine type
[2016-07-15 18:25:21,273][ceph21][DEBUG ] find the location of an executable
[2016-07-15 18:25:21,276][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:25:21,288][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 18:25:21,291][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph22
[2016-07-15 18:25:21,989][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 18:25:21,991][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 18:25:22,007][ceph22][DEBUG ] detect machine type
[2016-07-15 18:25:22,012][ceph22][DEBUG ] find the location of an executable
[2016-07-15 18:25:22,015][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:25:22,023][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 18:25:22,027][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph23
[2016-07-15 18:25:22,741][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 18:25:22,742][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 18:25:22,768][ceph23][DEBUG ] detect machine type
[2016-07-15 18:25:22,773][ceph23][DEBUG ] find the location of an executable
[2016-07-15 18:25:22,776][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 18:25:22,793][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 19:18:43,753][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 19:18:43,754][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph21
[2016-07-15 19:18:43,754][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 19:18:43,754][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 19:18:43,754][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 19:18:43,754][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 19:18:43,754][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 19:18:43,754][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f821d28cb00>
[2016-07-15 19:18:43,755][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 19:18:43,755][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-15 19:18:43,755][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f821dba31b8>
[2016-07-15 19:18:43,755][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 19:18:43,755][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 19:18:43,755][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 19:18:43,755][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 19:18:43,755][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph21
[2016-07-15 19:18:43,755][ceph_deploy.install][DEBUG ] Detecting platform for host ceph21 ...
[2016-07-15 19:18:44,436][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 19:18:44,437][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 19:18:44,452][ceph21][DEBUG ] detect machine type
[2016-07-15 19:18:44,456][ceph21][DEBUG ] find the location of an executable
[2016-07-15 19:18:44,458][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:18:44,469][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 19:18:44,469][ceph21][INFO  ] Purging Ceph on ceph21
[2016-07-15 19:18:44,471][ceph21][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 19:18:44,839][ceph21][DEBUG ] Reading package lists...
[2016-07-15 19:18:45,153][ceph21][DEBUG ] Building dependency tree...
[2016-07-15 19:18:45,154][ceph21][DEBUG ] Reading state information...
[2016-07-15 19:18:45,318][ceph21][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 19:18:45,318][ceph21][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 19:18:45,318][ceph21][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 19:18:45,318][ceph21][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 19:18:45,318][ceph21][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 19:18:45,318][ceph21][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-15 19:18:45,318][ceph21][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libnspr4
[2016-07-15 19:18:45,318][ceph21][DEBUG ]   libnss3 libnss3-nssdb libxslt1.1 xmlstarlet
[2016-07-15 19:18:45,318][ceph21][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-15 19:18:45,326][ceph21][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 216 not upgraded.
[2016-07-15 19:18:45,430][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 19:18:45,430][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph21
[2016-07-15 19:18:45,430][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 19:18:45,431][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 19:18:45,431][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 19:18:45,431][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 19:18:45,431][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 19:18:45,431][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6182b241b8>
[2016-07-15 19:18:45,431][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 19:18:45,431][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-15 19:18:45,432][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f6183433230>
[2016-07-15 19:18:45,432][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 19:18:45,432][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 19:18:45,432][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph21
[2016-07-15 19:18:46,127][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 19:18:46,129][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 19:18:46,145][ceph21][DEBUG ] detect machine type
[2016-07-15 19:18:46,149][ceph21][DEBUG ] find the location of an executable
[2016-07-15 19:18:46,151][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:18:46,164][ceph21][DEBUG ] find the location of an executable
[2016-07-15 19:18:46,837][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 19:18:46,838][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 19:18:46,862][ceph21][DEBUG ] detect machine type
[2016-07-15 19:18:46,866][ceph21][DEBUG ] find the location of an executable
[2016-07-15 19:18:46,869][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:18:46,886][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 19:18:46,886][ceph21][INFO  ] purging data on ceph21
[2016-07-15 19:18:46,888][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 19:18:46,898][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 19:18:56,715][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 19:18:56,715][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph22
[2016-07-15 19:18:56,715][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 19:18:56,716][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 19:18:56,716][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 19:18:56,716][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 19:18:56,716][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 19:18:56,716][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f047f85cb00>
[2016-07-15 19:18:56,716][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 19:18:56,716][ceph_deploy.cli][INFO  ]  host                          : ['ceph22']
[2016-07-15 19:18:56,716][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f04801731b8>
[2016-07-15 19:18:56,717][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 19:18:56,717][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 19:18:56,717][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 19:18:56,717][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 19:18:56,717][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph22
[2016-07-15 19:18:56,717][ceph_deploy.install][DEBUG ] Detecting platform for host ceph22 ...
[2016-07-15 19:18:57,377][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 19:18:57,378][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 19:18:57,393][ceph22][DEBUG ] detect machine type
[2016-07-15 19:18:57,397][ceph22][DEBUG ] find the location of an executable
[2016-07-15 19:18:57,399][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:18:57,409][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 19:18:57,409][ceph22][INFO  ] Purging Ceph on ceph22
[2016-07-15 19:18:57,411][ceph22][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 19:18:57,627][ceph22][DEBUG ] Reading package lists...
[2016-07-15 19:18:57,942][ceph22][DEBUG ] Building dependency tree...
[2016-07-15 19:18:57,942][ceph22][DEBUG ] Reading state information...
[2016-07-15 19:18:58,106][ceph22][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 19:18:58,107][ceph22][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 19:18:58,107][ceph22][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 19:18:58,107][ceph22][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 19:18:58,107][ceph22][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 19:18:58,107][ceph22][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 218 not upgraded.
[2016-07-15 19:18:58,200][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 19:18:58,201][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph22
[2016-07-15 19:18:58,201][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 19:18:58,201][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 19:18:58,201][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 19:18:58,201][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 19:18:58,201][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 19:18:58,202][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fed9d8bc1b8>
[2016-07-15 19:18:58,202][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 19:18:58,202][ceph_deploy.cli][INFO  ]  host                          : ['ceph22']
[2016-07-15 19:18:58,202][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7fed9e1cb230>
[2016-07-15 19:18:58,202][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 19:18:58,202][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 19:18:58,202][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph22
[2016-07-15 19:18:58,884][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 19:18:58,885][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 19:18:58,902][ceph22][DEBUG ] detect machine type
[2016-07-15 19:18:58,906][ceph22][DEBUG ] find the location of an executable
[2016-07-15 19:18:58,908][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:18:58,920][ceph22][DEBUG ] find the location of an executable
[2016-07-15 19:18:59,583][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 19:18:59,584][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 19:18:59,601][ceph22][DEBUG ] detect machine type
[2016-07-15 19:18:59,605][ceph22][DEBUG ] find the location of an executable
[2016-07-15 19:18:59,607][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:18:59,617][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 19:18:59,617][ceph22][INFO  ] purging data on ceph22
[2016-07-15 19:18:59,618][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 19:18:59,627][ceph22][WARNING] OSDs may still be mounted, trying to unmount them
[2016-07-15 19:18:59,629][ceph22][INFO  ] Running command: find /var/lib/ceph -mindepth 1 -maxdepth 2 -type d -exec umount {} ;
[2016-07-15 19:18:59,639][ceph22][WARNING] umount: /var/lib/ceph/osd: not mounted
[2016-07-15 19:18:59,704][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 19:18:59,716][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 19:19:10,234][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 19:19:10,235][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph23
[2016-07-15 19:19:10,235][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 19:19:10,235][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 19:19:10,235][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 19:19:10,235][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 19:19:10,235][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 19:19:10,236][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f685ad95b00>
[2016-07-15 19:19:10,236][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 19:19:10,236][ceph_deploy.cli][INFO  ]  host                          : ['ceph23']
[2016-07-15 19:19:10,236][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f685b6ac1b8>
[2016-07-15 19:19:10,236][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 19:19:10,236][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 19:19:10,236][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-15 19:19:10,236][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-15 19:19:10,237][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph23
[2016-07-15 19:19:10,237][ceph_deploy.install][DEBUG ] Detecting platform for host ceph23 ...
[2016-07-15 19:19:10,923][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 19:19:10,924][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 19:19:10,939][ceph23][DEBUG ] detect machine type
[2016-07-15 19:19:10,942][ceph23][DEBUG ] find the location of an executable
[2016-07-15 19:19:10,944][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:19:10,954][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 19:19:10,955][ceph23][INFO  ] Purging Ceph on ceph23
[2016-07-15 19:19:10,956][ceph23][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-15 19:19:11,323][ceph23][DEBUG ] Reading package lists...
[2016-07-15 19:19:11,639][ceph23][DEBUG ] Building dependency tree...
[2016-07-15 19:19:11,644][ceph23][DEBUG ] Reading state information...
[2016-07-15 19:19:11,859][ceph23][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-15 19:19:11,859][ceph23][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-15 19:19:11,859][ceph23][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-15 19:19:11,859][ceph23][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-15 19:19:11,859][ceph23][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-15 19:19:11,859][ceph23][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-15 19:19:11,859][ceph23][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libxslt1.1
[2016-07-15 19:19:11,859][ceph23][DEBUG ]   xmlstarlet
[2016-07-15 19:19:11,860][ceph23][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-15 19:19:11,875][ceph23][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 218 not upgraded.
[2016-07-15 19:19:11,979][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 19:19:11,979][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph23
[2016-07-15 19:19:11,979][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 19:19:11,979][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 19:19:11,980][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 19:19:11,980][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 19:19:11,980][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 19:19:11,980][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa91a20f1b8>
[2016-07-15 19:19:11,980][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 19:19:11,980][ceph_deploy.cli][INFO  ]  host                          : ['ceph23']
[2016-07-15 19:19:11,980][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7fa91ab1e230>
[2016-07-15 19:19:11,980][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 19:19:11,980][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 19:19:11,980][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph23
[2016-07-15 19:19:12,681][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 19:19:12,682][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 19:19:12,699][ceph23][DEBUG ] detect machine type
[2016-07-15 19:19:12,703][ceph23][DEBUG ] find the location of an executable
[2016-07-15 19:19:12,705][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:19:12,716][ceph23][DEBUG ] find the location of an executable
[2016-07-15 19:19:13,402][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 19:19:13,403][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 19:19:13,420][ceph23][DEBUG ] detect machine type
[2016-07-15 19:19:13,424][ceph23][DEBUG ] find the location of an executable
[2016-07-15 19:19:13,426][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:19:13,443][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 19:19:13,443][ceph23][INFO  ] purging data on ceph23
[2016-07-15 19:19:13,445][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 19:19:13,454][ceph23][WARNING] OSDs may still be mounted, trying to unmount them
[2016-07-15 19:19:13,455][ceph23][INFO  ] Running command: find /var/lib/ceph -mindepth 1 -maxdepth 2 -type d -exec umount {} ;
[2016-07-15 19:19:13,465][ceph23][WARNING] umount: /var/lib/ceph/osd: not mounted
[2016-07-15 19:19:13,530][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-15 19:19:13,542][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-15 19:20:46,947][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 19:20:46,947][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy new ceph21
[2016-07-15 19:20:46,947][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 19:20:46,948][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 19:20:46,948][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f334e2a7410>
[2016-07-15 19:20:46,948][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 19:20:46,948][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 19:20:46,948][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 19:20:46,949][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f334da09ef0>
[2016-07-15 19:20:46,949][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 19:20:46,949][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2016-07-15 19:20:46,949][ceph_deploy.cli][INFO  ]  mon                           : ['ceph21']
[2016-07-15 19:20:46,949][ceph_deploy.cli][INFO  ]  public_network                : None
[2016-07-15 19:20:46,949][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 19:20:46,949][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2016-07-15 19:20:46,950][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 19:20:46,950][ceph_deploy.cli][INFO  ]  fsid                          : None
[2016-07-15 19:20:46,950][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2016-07-15 19:20:46,950][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2016-07-15 19:20:46,980][ceph21][DEBUG ] connected to host: cephAdmin 
[2016-07-15 19:20:46,985][ceph21][INFO  ] Running command: ssh -CT -o BatchMode=yes ceph21
[2016-07-15 19:20:48,034][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 19:20:48,035][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 19:20:48,051][ceph21][DEBUG ] detect machine type
[2016-07-15 19:20:48,055][ceph21][DEBUG ] find the location of an executable
[2016-07-15 19:20:48,057][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:20:48,066][ceph21][DEBUG ] find the location of an executable
[2016-07-15 19:20:48,068][ceph21][INFO  ] Running command: /bin/ip link show
[2016-07-15 19:20:48,078][ceph21][INFO  ] Running command: /bin/ip addr show
[2016-07-15 19:20:48,088][ceph21][DEBUG ] IP addresses found: ['10.1.0.44']
[2016-07-15 19:20:48,088][ceph_deploy.new][DEBUG ] Resolving host ceph21
[2016-07-15 19:20:48,089][ceph_deploy.new][DEBUG ] Monitor ceph21 at 10.1.0.44
[2016-07-15 19:20:48,089][ceph_deploy.new][DEBUG ] Monitor initial members are ['ceph21']
[2016-07-15 19:20:48,089][ceph_deploy.new][DEBUG ] Monitor addrs are ['10.1.0.44']
[2016-07-15 19:20:48,090][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2016-07-15 19:20:48,090][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2016-07-15 19:20:48,090][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2016-07-15 19:23:02,965][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 19:23:02,965][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy mon create-initial
[2016-07-15 19:23:02,965][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 19:23:02,965][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 19:23:02,966][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 19:23:02,966][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-15 19:23:02,966][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2016-07-15 19:23:02,966][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 19:23:02,966][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f2a7afd2290>
[2016-07-15 19:23:02,966][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 19:23:02,966][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f2a7afb36e0>
[2016-07-15 19:23:02,966][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 19:23:02,967][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 19:23:02,967][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2016-07-15 19:23:02,969][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts ceph21
[2016-07-15 19:23:02,969][ceph_deploy.mon][DEBUG ] detecting platform for host ceph21 ...
[2016-07-15 19:23:03,649][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 19:23:03,650][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 19:23:03,666][ceph21][DEBUG ] detect machine type
[2016-07-15 19:23:03,669][ceph21][DEBUG ] find the location of an executable
[2016-07-15 19:23:03,672][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:23:03,683][ceph21][DEBUG ] find the location of an executable
[2016-07-15 19:23:03,684][ceph_deploy.mon][INFO  ] distro info: Ubuntu 14.04 trusty
[2016-07-15 19:23:03,684][ceph21][DEBUG ] determining if provided host has same hostname in remote
[2016-07-15 19:23:03,684][ceph21][DEBUG ] get remote short hostname
[2016-07-15 19:23:03,685][ceph21][DEBUG ] deploying mon to ceph21
[2016-07-15 19:23:03,685][ceph21][DEBUG ] get remote short hostname
[2016-07-15 19:23:03,686][ceph21][DEBUG ] remote hostname: ceph21
[2016-07-15 19:23:03,689][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 19:23:03,690][ceph21][DEBUG ] create the mon path if it does not exist
[2016-07-15 19:23:03,691][ceph21][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-15 19:23:03,692][ceph21][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-15 19:23:03,693][ceph21][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 19:23:03,694][ceph21][DEBUG ] create the monitor keyring file
[2016-07-15 19:23:03,696][ceph21][INFO  ] Running command: ceph-mon --cluster ceph --mkfs -i ceph21 --keyring /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 19:23:03,731][ceph21][DEBUG ] ceph-mon: mon.noname-a 10.1.0.44:6789/0 is local, renaming to mon.ceph21
[2016-07-15 19:23:03,731][ceph21][DEBUG ] ceph-mon: set fsid to 7a06687b-d531-47f3-a1c8-e92c28a1cee7
[2016-07-15 19:23:03,731][ceph21][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-ceph21 for mon.ceph21
[2016-07-15 19:23:03,731][ceph21][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-15 19:23:03,732][ceph21][DEBUG ] create a done file to avoid re-doing the mon deployment
[2016-07-15 19:23:03,733][ceph21][DEBUG ] create the init path if it does not exist
[2016-07-15 19:23:03,735][ceph21][INFO  ] Running command: initctl emit ceph-mon cluster=ceph id=ceph21
[2016-07-15 19:23:05,775][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 19:23:05,841][ceph21][DEBUG ] ********************************************************************************
[2016-07-15 19:23:05,841][ceph21][DEBUG ] status for monitor: mon.ceph21
[2016-07-15 19:23:05,842][ceph21][DEBUG ] {
[2016-07-15 19:23:05,842][ceph21][DEBUG ]   "election_epoch": 2, 
[2016-07-15 19:23:05,842][ceph21][DEBUG ]   "extra_probe_peers": [], 
[2016-07-15 19:23:05,842][ceph21][DEBUG ]   "monmap": {
[2016-07-15 19:23:05,842][ceph21][DEBUG ]     "created": "0.000000", 
[2016-07-15 19:23:05,842][ceph21][DEBUG ]     "epoch": 1, 
[2016-07-15 19:23:05,842][ceph21][DEBUG ]     "fsid": "7a06687b-d531-47f3-a1c8-e92c28a1cee7", 
[2016-07-15 19:23:05,843][ceph21][DEBUG ]     "modified": "0.000000", 
[2016-07-15 19:23:05,843][ceph21][DEBUG ]     "mons": [
[2016-07-15 19:23:05,843][ceph21][DEBUG ]       {
[2016-07-15 19:23:05,843][ceph21][DEBUG ]         "addr": "10.1.0.44:6789/0", 
[2016-07-15 19:23:05,843][ceph21][DEBUG ]         "name": "ceph21", 
[2016-07-15 19:23:05,843][ceph21][DEBUG ]         "rank": 0
[2016-07-15 19:23:05,843][ceph21][DEBUG ]       }
[2016-07-15 19:23:05,843][ceph21][DEBUG ]     ]
[2016-07-15 19:23:05,843][ceph21][DEBUG ]   }, 
[2016-07-15 19:23:05,844][ceph21][DEBUG ]   "name": "ceph21", 
[2016-07-15 19:23:05,844][ceph21][DEBUG ]   "outside_quorum": [], 
[2016-07-15 19:23:05,844][ceph21][DEBUG ]   "quorum": [
[2016-07-15 19:23:05,844][ceph21][DEBUG ]     0
[2016-07-15 19:23:05,844][ceph21][DEBUG ]   ], 
[2016-07-15 19:23:05,844][ceph21][DEBUG ]   "rank": 0, 
[2016-07-15 19:23:05,844][ceph21][DEBUG ]   "state": "leader", 
[2016-07-15 19:23:05,844][ceph21][DEBUG ]   "sync_provider": []
[2016-07-15 19:23:05,845][ceph21][DEBUG ] }
[2016-07-15 19:23:05,845][ceph21][DEBUG ] ********************************************************************************
[2016-07-15 19:23:05,845][ceph21][INFO  ] monitor: mon.ceph21 is running
[2016-07-15 19:23:05,847][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 19:23:05,912][ceph_deploy.mon][INFO  ] processing monitor mon.ceph21
[2016-07-15 19:23:06,588][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 19:23:06,589][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 19:23:06,605][ceph21][DEBUG ] detect machine type
[2016-07-15 19:23:06,609][ceph21][DEBUG ] find the location of an executable
[2016-07-15 19:23:06,612][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:23:06,621][ceph21][DEBUG ] find the location of an executable
[2016-07-15 19:23:06,623][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-15 19:23:06,689][ceph_deploy.mon][INFO  ] mon.ceph21 monitor has reached quorum!
[2016-07-15 19:23:06,689][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2016-07-15 19:23:06,689][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2016-07-15 19:23:06,689][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /etc/ceph/ceph.client.admin.keyring
[2016-07-15 19:23:07,373][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 19:23:07,374][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 19:23:07,391][ceph21][DEBUG ] detect machine type
[2016-07-15 19:23:07,395][ceph21][DEBUG ] find the location of an executable
[2016-07-15 19:23:07,398][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:23:07,415][ceph21][DEBUG ] fetch remote file
[2016-07-15 19:23:07,416][ceph_deploy.gatherkeys][DEBUG ] Got ceph.client.admin.keyring key from ceph21.
[2016-07-15 19:23:07,417][ceph_deploy.gatherkeys][DEBUG ] Have ceph.mon.keyring
[2016-07-15 19:23:07,417][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-osd/ceph.keyring
[2016-07-15 19:23:08,086][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 19:23:08,087][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 19:23:08,106][ceph21][DEBUG ] detect machine type
[2016-07-15 19:23:08,110][ceph21][DEBUG ] find the location of an executable
[2016-07-15 19:23:08,112][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:23:08,121][ceph21][DEBUG ] fetch remote file
[2016-07-15 19:23:08,122][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-osd.keyring key from ceph21.
[2016-07-15 19:23:08,123][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-mds/ceph.keyring
[2016-07-15 19:23:08,811][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 19:23:08,813][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 19:23:08,829][ceph21][DEBUG ] detect machine type
[2016-07-15 19:23:08,833][ceph21][DEBUG ] find the location of an executable
[2016-07-15 19:23:08,836][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:23:08,846][ceph21][DEBUG ] fetch remote file
[2016-07-15 19:23:08,847][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-mds.keyring key from ceph21.
[2016-07-15 19:23:08,847][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-rgw/ceph.keyring
[2016-07-15 19:23:09,554][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-15 19:23:09,555][ceph21][DEBUG ] detect platform information from remote host
[2016-07-15 19:23:09,572][ceph21][DEBUG ] detect machine type
[2016-07-15 19:23:09,576][ceph21][DEBUG ] find the location of an executable
[2016-07-15 19:23:09,578][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:23:09,587][ceph21][DEBUG ] fetch remote file
[2016-07-15 19:23:09,588][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-rgw.keyring key from ceph21.
[2016-07-15 19:23:27,890][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-15 19:23:27,891][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf osd create --zap-disk ceph22:/dev/vdb ceph22:/dev/vdc ceph23:/dev/vdb ceph23:/dev/vdc
[2016-07-15 19:23:27,891][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-15 19:23:27,891][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-15 19:23:27,891][ceph_deploy.cli][INFO  ]  disk                          : [('ceph22', '/dev/vdb', None), ('ceph22', '/dev/vdc', None), ('ceph23', '/dev/vdb', None), ('ceph23', '/dev/vdc', None)]
[2016-07-15 19:23:27,891][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2016-07-15 19:23:27,892][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-15 19:23:27,892][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2016-07-15 19:23:27,892][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-15 19:23:27,892][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-15 19:23:27,892][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2016-07-15 19:23:27,892][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-15 19:23:27,892][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb3855e11b8>
[2016-07-15 19:23:27,892][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-15 19:23:27,892][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2016-07-15 19:23:27,893][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fb3855b2578>
[2016-07-15 19:23:27,893][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-15 19:23:27,893][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-15 19:23:27,893][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2016-07-15 19:23:27,894][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks ceph22:/dev/vdb: ceph22:/dev/vdc: ceph23:/dev/vdb: ceph23:/dev/vdc:
[2016-07-15 19:23:28,579][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 19:23:28,580][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 19:23:28,597][ceph22][DEBUG ] detect machine type
[2016-07-15 19:23:28,602][ceph22][DEBUG ] find the location of an executable
[2016-07-15 19:23:28,604][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:23:28,615][ceph22][DEBUG ] find the location of an executable
[2016-07-15 19:23:28,616][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 19:23:28,616][ceph_deploy.osd][DEBUG ] Deploying osd to ceph22
[2016-07-15 19:23:28,617][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 19:23:28,619][ceph22][WARNING] osd keyring does not exist yet, creating one
[2016-07-15 19:23:28,619][ceph22][DEBUG ] create a keyring file
[2016-07-15 19:23:28,620][ceph_deploy.osd][DEBUG ] Preparing host ceph22 disk /dev/vdb journal None activate True
[2016-07-15 19:23:28,621][ceph22][DEBUG ] find the location of an executable
[2016-07-15 19:23:28,623][ceph22][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-15 19:23:28,689][ceph22][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-15 19:23:28,690][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-15 19:23:28,690][ceph22][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 19:23:28,691][ceph22][WARNING] backup header from main header.
[2016-07-15 19:23:28,691][ceph22][WARNING] 
[2016-07-15 19:23:28,691][ceph22][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 19:23:28,691][ceph22][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 19:23:28,691][ceph22][WARNING] 
[2016-07-15 19:23:28,691][ceph22][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 19:23:28,691][ceph22][WARNING] 
[2016-07-15 19:23:29,758][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 19:23:29,758][ceph22][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 19:23:29,758][ceph22][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 19:23:29,759][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 19:23:29,759][ceph22][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 19:23:29,759][ceph22][DEBUG ] other utilities.
[2016-07-15 19:23:29,760][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-15 19:23:30,775][ceph22][DEBUG ] Creating new GPT entries.
[2016-07-15 19:23:30,776][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 19:23:30,776][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-15 19:23:30,776][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 19:23:30,776][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 19:23:30,777][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 19:23:30,778][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 19:23:30,793][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 19:23:30,809][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 19:23:30,817][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 19:23:30,833][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 19:23:30,841][ceph22][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-15 19:23:30,841][ceph22][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-15 19:23:30,841][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:0d295d24-2e78-4f5d-a814-51c49385ddb0 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-15 19:23:31,908][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 19:23:31,908][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 19:23:31,908][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 19:23:32,022][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 19:23:32,086][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/0d295d24-2e78-4f5d-a814-51c49385ddb0
[2016-07-15 19:23:32,087][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/0d295d24-2e78-4f5d-a814-51c49385ddb0
[2016-07-15 19:23:32,087][ceph22][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-15 19:23:32,087][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:1805a176-530b-4b33-9fe2-b793b607b599 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-15 19:23:33,104][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 19:23:33,104][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-15 19:23:33,104][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 19:23:33,368][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 19:23:33,432][ceph22][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-15 19:23:33,433][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-15 19:23:34,198][ceph22][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-15 19:23:34,199][ceph22][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 19:23:34,199][ceph22][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-15 19:23:34,199][ceph22][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 19:23:34,199][ceph22][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 19:23:34,200][ceph22][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-15 19:23:34,200][ceph22][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 19:23:34,200][ceph22][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 19:23:34,200][ceph22][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.bcE7Sr with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 19:23:34,200][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.bcE7Sr
[2016-07-15 19:23:34,201][ceph22][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.bcE7Sr
[2016-07-15 19:23:34,201][ceph22][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.bcE7Sr/journal -> /dev/disk/by-partuuid/0d295d24-2e78-4f5d-a814-51c49385ddb0
[2016-07-15 19:23:34,201][ceph22][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.bcE7Sr
[2016-07-15 19:23:34,201][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.bcE7Sr
[2016-07-15 19:23:34,233][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-15 19:23:35,249][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 19:23:35,249][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 19:23:35,250][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 19:23:41,472][ceph22][INFO  ] checking OSD status...
[2016-07-15 19:23:41,472][ceph22][DEBUG ] find the location of an executable
[2016-07-15 19:23:41,475][ceph22][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 19:23:41,690][ceph_deploy.osd][DEBUG ] Host ceph22 is now ready for osd use.
[2016-07-15 19:23:42,383][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-15 19:23:42,385][ceph22][DEBUG ] detect platform information from remote host
[2016-07-15 19:23:42,400][ceph22][DEBUG ] detect machine type
[2016-07-15 19:23:42,404][ceph22][DEBUG ] find the location of an executable
[2016-07-15 19:23:42,406][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:23:42,415][ceph22][DEBUG ] find the location of an executable
[2016-07-15 19:23:42,416][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 19:23:42,416][ceph_deploy.osd][DEBUG ] Preparing host ceph22 disk /dev/vdc journal None activate True
[2016-07-15 19:23:42,417][ceph22][DEBUG ] find the location of an executable
[2016-07-15 19:23:42,419][ceph22][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-15 19:23:42,486][ceph22][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-15 19:23:42,486][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-15 19:23:42,487][ceph22][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 19:23:42,487][ceph22][WARNING] backup header from main header.
[2016-07-15 19:23:42,487][ceph22][WARNING] 
[2016-07-15 19:23:42,487][ceph22][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 19:23:42,487][ceph22][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 19:23:42,487][ceph22][WARNING] 
[2016-07-15 19:23:42,487][ceph22][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 19:23:42,488][ceph22][WARNING] 
[2016-07-15 19:23:43,504][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 19:23:43,504][ceph22][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 19:23:43,504][ceph22][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 19:23:43,505][ceph22][DEBUG ] ****************************************************************************
[2016-07-15 19:23:43,506][ceph22][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 19:23:43,506][ceph22][DEBUG ] other utilities.
[2016-07-15 19:23:43,507][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-15 19:23:44,573][ceph22][DEBUG ] Creating new GPT entries.
[2016-07-15 19:23:44,573][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 19:23:44,573][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-15 19:23:44,574][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 19:23:44,574][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 19:23:44,574][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 19:23:44,574][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 19:23:44,589][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 19:23:44,597][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 19:23:44,612][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 19:23:44,620][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 19:23:44,635][ceph22][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-15 19:23:44,636][ceph22][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-15 19:23:44,636][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:8f06ddde-a1f2-48b4-a8ce-a309efbb275a --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-15 19:23:45,652][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 19:23:45,652][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 19:23:45,652][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 19:23:45,817][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 19:23:45,881][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/8f06ddde-a1f2-48b4-a8ce-a309efbb275a
[2016-07-15 19:23:45,881][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/8f06ddde-a1f2-48b4-a8ce-a309efbb275a
[2016-07-15 19:23:45,881][ceph22][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-15 19:23:45,881][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:b201700f-91d2-4676-99a1-09620512f379 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-15 19:23:46,897][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 19:23:46,898][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-15 19:23:46,898][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 19:23:47,162][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 19:23:47,194][ceph22][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-15 19:23:47,194][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-15 19:23:47,960][ceph22][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-15 19:23:47,960][ceph22][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 19:23:47,960][ceph22][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-15 19:23:47,960][ceph22][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 19:23:47,961][ceph22][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 19:23:47,961][ceph22][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-15 19:23:47,961][ceph22][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 19:23:47,961][ceph22][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 19:23:47,961][ceph22][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt.YmM6uL with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 19:23:47,962][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt.YmM6uL
[2016-07-15 19:23:47,962][ceph22][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.YmM6uL
[2016-07-15 19:23:47,962][ceph22][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.YmM6uL/journal -> /dev/disk/by-partuuid/8f06ddde-a1f2-48b4-a8ce-a309efbb275a
[2016-07-15 19:23:47,965][ceph22][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.YmM6uL
[2016-07-15 19:23:47,965][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.YmM6uL
[2016-07-15 19:23:47,997][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-15 19:23:49,013][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-15 19:23:49,013][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 19:23:49,014][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 19:23:55,135][ceph22][INFO  ] checking OSD status...
[2016-07-15 19:23:55,135][ceph22][DEBUG ] find the location of an executable
[2016-07-15 19:23:55,138][ceph22][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 19:23:55,354][ceph_deploy.osd][DEBUG ] Host ceph22 is now ready for osd use.
[2016-07-15 19:23:56,074][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 19:23:56,075][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 19:23:56,091][ceph23][DEBUG ] detect machine type
[2016-07-15 19:23:56,095][ceph23][DEBUG ] find the location of an executable
[2016-07-15 19:23:56,107][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:23:56,124][ceph23][DEBUG ] find the location of an executable
[2016-07-15 19:23:56,125][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 19:23:56,125][ceph_deploy.osd][DEBUG ] Deploying osd to ceph23
[2016-07-15 19:23:56,126][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-15 19:23:56,128][ceph23][WARNING] osd keyring does not exist yet, creating one
[2016-07-15 19:23:56,129][ceph23][DEBUG ] create a keyring file
[2016-07-15 19:23:56,130][ceph_deploy.osd][DEBUG ] Preparing host ceph23 disk /dev/vdb journal None activate True
[2016-07-15 19:23:56,130][ceph23][DEBUG ] find the location of an executable
[2016-07-15 19:23:56,132][ceph23][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-15 19:23:56,249][ceph23][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-15 19:23:56,250][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-15 19:23:56,250][ceph23][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 19:23:56,250][ceph23][WARNING] backup header from main header.
[2016-07-15 19:23:56,250][ceph23][WARNING] 
[2016-07-15 19:23:56,250][ceph23][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 19:23:56,251][ceph23][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 19:23:56,251][ceph23][WARNING] 
[2016-07-15 19:23:56,251][ceph23][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 19:23:56,251][ceph23][WARNING] 
[2016-07-15 19:23:57,267][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 19:23:57,268][ceph23][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 19:23:57,268][ceph23][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 19:23:57,268][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 19:23:57,269][ceph23][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 19:23:57,269][ceph23][DEBUG ] other utilities.
[2016-07-15 19:23:57,269][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-15 19:23:58,285][ceph23][DEBUG ] Creating new GPT entries.
[2016-07-15 19:23:58,285][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 19:23:58,286][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-15 19:23:58,286][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 19:23:58,286][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 19:23:58,301][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 19:23:58,317][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 19:23:58,333][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 19:23:58,341][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 19:23:58,356][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 19:23:58,364][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 19:23:58,379][ceph23][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-15 19:23:58,380][ceph23][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-15 19:23:58,380][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:a0fc56fe-b087-4024-9576-f92b81242d6a --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-15 19:23:59,396][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 19:23:59,396][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 19:23:59,397][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 19:23:59,561][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 19:23:59,675][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/a0fc56fe-b087-4024-9576-f92b81242d6a
[2016-07-15 19:23:59,675][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/a0fc56fe-b087-4024-9576-f92b81242d6a
[2016-07-15 19:23:59,675][ceph23][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-15 19:23:59,675][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:ed8cd4e4-7e3d-4332-9bf3-006dc4bf9f3b --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-15 19:24:00,692][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 19:24:00,692][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-15 19:24:00,692][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 19:24:00,956][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 19:24:00,988][ceph23][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-15 19:24:00,989][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-15 19:24:01,754][ceph23][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-15 19:24:01,755][ceph23][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 19:24:01,755][ceph23][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-15 19:24:01,756][ceph23][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 19:24:01,756][ceph23][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 19:24:01,756][ceph23][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-15 19:24:01,756][ceph23][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 19:24:01,757][ceph23][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 19:24:01,757][ceph23][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.pJ7r8D with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 19:24:01,757][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.pJ7r8D
[2016-07-15 19:24:01,757][ceph23][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.pJ7r8D
[2016-07-15 19:24:01,758][ceph23][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.pJ7r8D/journal -> /dev/disk/by-partuuid/a0fc56fe-b087-4024-9576-f92b81242d6a
[2016-07-15 19:24:01,765][ceph23][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.pJ7r8D
[2016-07-15 19:24:01,766][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.pJ7r8D
[2016-07-15 19:24:01,797][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-15 19:24:02,814][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 19:24:02,815][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-15 19:24:02,815][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-15 19:24:09,637][ceph23][INFO  ] checking OSD status...
[2016-07-15 19:24:09,637][ceph23][DEBUG ] find the location of an executable
[2016-07-15 19:24:09,640][ceph23][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 19:24:09,855][ceph_deploy.osd][DEBUG ] Host ceph23 is now ready for osd use.
[2016-07-15 19:24:10,553][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-15 19:24:10,554][ceph23][DEBUG ] detect platform information from remote host
[2016-07-15 19:24:10,571][ceph23][DEBUG ] detect machine type
[2016-07-15 19:24:10,575][ceph23][DEBUG ] find the location of an executable
[2016-07-15 19:24:10,578][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-15 19:24:10,595][ceph23][DEBUG ] find the location of an executable
[2016-07-15 19:24:10,596][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-15 19:24:10,596][ceph_deploy.osd][DEBUG ] Preparing host ceph23 disk /dev/vdc journal None activate True
[2016-07-15 19:24:10,596][ceph23][DEBUG ] find the location of an executable
[2016-07-15 19:24:10,598][ceph23][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-15 19:24:10,665][ceph23][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-15 19:24:10,665][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-15 19:24:10,666][ceph23][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-15 19:24:10,667][ceph23][WARNING] backup header from main header.
[2016-07-15 19:24:10,667][ceph23][WARNING] 
[2016-07-15 19:24:10,674][ceph23][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-15 19:24:10,674][ceph23][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-15 19:24:10,674][ceph23][WARNING] 
[2016-07-15 19:24:10,674][ceph23][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-15 19:24:10,675][ceph23][WARNING] 
[2016-07-15 19:24:11,741][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 19:24:11,741][ceph23][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-15 19:24:11,741][ceph23][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-15 19:24:11,741][ceph23][DEBUG ] ****************************************************************************
[2016-07-15 19:24:11,742][ceph23][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-15 19:24:11,742][ceph23][DEBUG ] other utilities.
[2016-07-15 19:24:11,742][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-15 19:24:12,758][ceph23][DEBUG ] Creating new GPT entries.
[2016-07-15 19:24:12,758][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 19:24:12,758][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-15 19:24:12,758][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 19:24:12,758][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-15 19:24:12,758][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-15 19:24:12,774][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-15 19:24:12,782][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-15 19:24:12,797][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-15 19:24:12,805][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-15 19:24:12,821][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-15 19:24:12,836][ceph23][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-15 19:24:12,836][ceph23][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-15 19:24:12,836][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:21dc3b8d-ef41-4f0c-b951-4f195e03468b --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-15 19:24:13,853][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 19:24:13,853][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 19:24:13,853][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 19:24:14,017][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 19:24:14,081][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/21dc3b8d-ef41-4f0c-b951-4f195e03468b
[2016-07-15 19:24:14,081][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/21dc3b8d-ef41-4f0c-b951-4f195e03468b
[2016-07-15 19:24:14,082][ceph23][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-15 19:24:14,082][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:4ad8adf3-b29b-4564-a026-37552fccc2ad --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-15 19:24:15,098][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 19:24:15,098][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-15 19:24:15,098][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 19:24:15,363][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-15 19:24:15,395][ceph23][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-15 19:24:15,395][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-15 19:24:16,160][ceph23][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-15 19:24:16,161][ceph23][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-15 19:24:16,161][ceph23][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-15 19:24:16,161][ceph23][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-15 19:24:16,161][ceph23][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-15 19:24:16,162][ceph23][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-15 19:24:16,162][ceph23][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-15 19:24:16,162][ceph23][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-15 19:24:16,162][ceph23][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt.JNhV3h with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-15 19:24:16,162][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt.JNhV3h
[2016-07-15 19:24:16,165][ceph23][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.JNhV3h
[2016-07-15 19:24:16,166][ceph23][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.JNhV3h/journal -> /dev/disk/by-partuuid/21dc3b8d-ef41-4f0c-b951-4f195e03468b
[2016-07-15 19:24:16,173][ceph23][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.JNhV3h
[2016-07-15 19:24:16,173][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.JNhV3h
[2016-07-15 19:24:16,237][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-15 19:24:17,254][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-15 19:24:17,254][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-15 19:24:17,254][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-15 19:24:23,326][ceph23][INFO  ] checking OSD status...
[2016-07-15 19:24:23,326][ceph23][DEBUG ] find the location of an executable
[2016-07-15 19:24:23,329][ceph23][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-15 19:24:23,545][ceph_deploy.osd][DEBUG ] Host ceph23 is now ready for osd use.
[2016-07-17 07:44:46,464][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-17 07:44:46,464][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy rgw create ceph21
[2016-07-17 07:44:46,464][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-17 07:44:46,465][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-17 07:44:46,465][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-17 07:44:46,465][ceph_deploy.cli][INFO  ]  rgw                           : [('ceph21', 'rgw.ceph21')]
[2016-07-17 07:44:46,465][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-17 07:44:46,465][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-17 07:44:46,465][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-17 07:44:46,465][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f1611141680>
[2016-07-17 07:44:46,466][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-17 07:44:46,466][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f1611a086e0>
[2016-07-17 07:44:46,466][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-17 07:44:46,466][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-17 07:44:46,467][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts ceph21:rgw.ceph21
[2016-07-17 07:44:47,135][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-17 07:44:47,135][ceph21][DEBUG ] detect platform information from remote host
[2016-07-17 07:44:47,151][ceph21][DEBUG ] detect machine type
[2016-07-17 07:44:47,155][ceph21][DEBUG ] find the location of an executable
[2016-07-17 07:44:47,157][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-17 07:44:47,169][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-17 07:44:47,169][ceph_deploy.rgw][DEBUG ] remote host will use upstart
[2016-07-17 07:44:47,169][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to ceph21
[2016-07-17 07:44:47,169][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-17 07:44:47,172][ceph21][DEBUG ] create path recursively if it doesn't exist
[2016-07-17 07:44:47,174][ceph21][INFO  ] Running command: ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.ceph21 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.ceph21/keyring
[2016-07-17 07:44:47,393][ceph21][INFO  ] Running command: initctl emit radosgw cluster=ceph id=rgw.ceph21
[2016-07-17 07:44:47,412][ceph_deploy.rgw][INFO  ] The Ceph Object Gateway (RGW) is now running on host ceph21 and default port 7480
[2016-07-17 07:57:35,614][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-17 07:57:35,614][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf config push ceph21
[2016-07-17 07:57:35,614][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-17 07:57:35,615][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-17 07:57:35,615][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-17 07:57:35,615][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-17 07:57:35,615][ceph_deploy.cli][INFO  ]  subcommand                    : push
[2016-07-17 07:57:35,615][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-17 07:57:35,615][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ffef4a73518>
[2016-07-17 07:57:35,615][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-17 07:57:35,615][ceph_deploy.cli][INFO  ]  client                        : ['ceph21']
[2016-07-17 07:57:35,616][ceph_deploy.cli][INFO  ]  func                          : <function config at 0x7ffef4abc938>
[2016-07-17 07:57:35,616][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-17 07:57:35,616][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-17 07:57:35,616][ceph_deploy.config][DEBUG ] Pushing config to ceph21
[2016-07-17 07:57:36,321][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-17 07:57:36,322][ceph21][DEBUG ] detect platform information from remote host
[2016-07-17 07:57:36,339][ceph21][DEBUG ] detect machine type
[2016-07-17 07:57:36,343][ceph21][DEBUG ] find the location of an executable
[2016-07-17 07:57:36,346][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-17 07:57:36,365][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-17 08:51:19,711][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-17 08:51:19,711][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf config push ceph22 ceph23
[2016-07-17 08:51:19,712][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-17 08:51:19,712][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-17 08:51:19,712][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-17 08:51:19,712][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-17 08:51:19,712][ceph_deploy.cli][INFO  ]  subcommand                    : push
[2016-07-17 08:51:19,712][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-17 08:51:19,712][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb2ba2bf518>
[2016-07-17 08:51:19,712][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-17 08:51:19,712][ceph_deploy.cli][INFO  ]  client                        : ['ceph22', 'ceph23']
[2016-07-17 08:51:19,712][ceph_deploy.cli][INFO  ]  func                          : <function config at 0x7fb2ba308938>
[2016-07-17 08:51:19,712][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-17 08:51:19,712][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-17 08:51:19,712][ceph_deploy.config][DEBUG ] Pushing config to ceph22
[2016-07-17 08:51:20,427][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-17 08:51:20,428][ceph22][DEBUG ] detect platform information from remote host
[2016-07-17 08:51:20,444][ceph22][DEBUG ] detect machine type
[2016-07-17 08:51:20,448][ceph22][DEBUG ] find the location of an executable
[2016-07-17 08:51:20,451][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-17 08:51:20,470][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-17 08:51:20,473][ceph_deploy.config][DEBUG ] Pushing config to ceph23
[2016-07-17 08:51:21,165][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-17 08:51:21,167][ceph23][DEBUG ] detect platform information from remote host
[2016-07-17 08:51:21,187][ceph23][DEBUG ] detect machine type
[2016-07-17 08:51:21,190][ceph23][DEBUG ] find the location of an executable
[2016-07-17 08:51:21,192][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-17 08:51:21,201][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-18 09:02:59,312][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-18 09:02:59,312][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph21
[2016-07-18 09:02:59,313][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-18 09:02:59,313][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-18 09:02:59,313][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-18 09:02:59,313][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-18 09:02:59,314][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-18 09:02:59,314][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe3a6d92b00>
[2016-07-18 09:02:59,314][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-18 09:02:59,314][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-18 09:02:59,315][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fe3a76a91b8>
[2016-07-18 09:02:59,315][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-18 09:02:59,315][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-18 09:02:59,315][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-18 09:02:59,315][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-18 09:02:59,315][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph21
[2016-07-18 09:02:59,316][ceph_deploy.install][DEBUG ] Detecting platform for host ceph21 ...
[2016-07-18 09:02:59,997][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-18 09:02:59,998][ceph21][DEBUG ] detect platform information from remote host
[2016-07-18 09:03:00,015][ceph21][DEBUG ] detect machine type
[2016-07-18 09:03:00,019][ceph21][DEBUG ] find the location of an executable
[2016-07-18 09:03:00,021][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:03:00,057][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-18 09:03:00,057][ceph21][INFO  ] Purging Ceph on ceph21
[2016-07-18 09:03:00,059][ceph21][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-18 09:03:00,577][ceph21][DEBUG ] Reading package lists...
[2016-07-18 09:03:00,891][ceph21][DEBUG ] Building dependency tree...
[2016-07-18 09:03:00,891][ceph21][DEBUG ] Reading state information...
[2016-07-18 09:03:01,106][ceph21][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-18 09:03:01,106][ceph21][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-18 09:03:01,106][ceph21][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-18 09:03:01,106][ceph21][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-18 09:03:01,106][ceph21][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-18 09:03:01,107][ceph21][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-18 09:03:01,107][ceph21][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libnspr4
[2016-07-18 09:03:01,107][ceph21][DEBUG ]   libnss3 libnss3-nssdb libxslt1.1 xmlstarlet
[2016-07-18 09:03:01,107][ceph21][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-18 09:03:01,171][ceph21][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 216 not upgraded.
[2016-07-18 09:03:01,265][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-18 09:03:01,266][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph21
[2016-07-18 09:03:01,266][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-18 09:03:01,266][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-18 09:03:01,266][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-18 09:03:01,266][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-18 09:03:01,266][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-18 09:03:01,267][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa75222f1b8>
[2016-07-18 09:03:01,267][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-18 09:03:01,267][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-18 09:03:01,267][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7fa752b3e230>
[2016-07-18 09:03:01,267][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-18 09:03:01,267][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-18 09:03:01,267][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph21
[2016-07-18 09:03:01,959][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-18 09:03:01,960][ceph21][DEBUG ] detect platform information from remote host
[2016-07-18 09:03:01,980][ceph21][DEBUG ] detect machine type
[2016-07-18 09:03:01,984][ceph21][DEBUG ] find the location of an executable
[2016-07-18 09:03:01,988][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:03:02,007][ceph21][DEBUG ] find the location of an executable
[2016-07-18 09:03:02,737][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-18 09:03:02,738][ceph21][DEBUG ] detect platform information from remote host
[2016-07-18 09:03:02,755][ceph21][DEBUG ] detect machine type
[2016-07-18 09:03:02,760][ceph21][DEBUG ] find the location of an executable
[2016-07-18 09:03:02,762][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:03:02,780][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-18 09:03:02,780][ceph21][INFO  ] purging data on ceph21
[2016-07-18 09:03:02,782][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-18 09:03:02,792][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-18 09:03:13,972][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-18 09:03:13,972][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph22
[2016-07-18 09:03:13,972][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-18 09:03:13,972][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-18 09:03:13,972][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-18 09:03:13,973][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-18 09:03:13,973][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-18 09:03:13,973][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe33179bb00>
[2016-07-18 09:03:13,973][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-18 09:03:13,973][ceph_deploy.cli][INFO  ]  host                          : ['ceph22']
[2016-07-18 09:03:13,973][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fe3320b21b8>
[2016-07-18 09:03:13,973][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-18 09:03:13,973][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-18 09:03:13,974][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-18 09:03:13,974][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-18 09:03:13,974][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph22
[2016-07-18 09:03:13,974][ceph_deploy.install][DEBUG ] Detecting platform for host ceph22 ...
[2016-07-18 09:03:14,660][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-18 09:03:14,661][ceph22][DEBUG ] detect platform information from remote host
[2016-07-18 09:03:14,676][ceph22][DEBUG ] detect machine type
[2016-07-18 09:03:14,680][ceph22][DEBUG ] find the location of an executable
[2016-07-18 09:03:14,682][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:03:14,694][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-18 09:03:14,694][ceph22][INFO  ] Purging Ceph on ceph22
[2016-07-18 09:03:14,696][ceph22][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-18 09:03:15,066][ceph22][DEBUG ] Reading package lists...
[2016-07-18 09:03:15,380][ceph22][DEBUG ] Building dependency tree...
[2016-07-18 09:03:15,381][ceph22][DEBUG ] Reading state information...
[2016-07-18 09:03:15,595][ceph22][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-18 09:03:15,595][ceph22][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-18 09:03:15,595][ceph22][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-18 09:03:15,595][ceph22][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-18 09:03:15,595][ceph22][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-18 09:03:15,596][ceph22][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 218 not upgraded.
[2016-07-18 09:03:15,691][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-18 09:03:15,692][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph22
[2016-07-18 09:03:15,692][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-18 09:03:15,692][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-18 09:03:15,692][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-18 09:03:15,692][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-18 09:03:15,692][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-18 09:03:15,693][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5c8d2191b8>
[2016-07-18 09:03:15,693][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-18 09:03:15,693][ceph_deploy.cli][INFO  ]  host                          : ['ceph22']
[2016-07-18 09:03:15,693][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f5c8db28230>
[2016-07-18 09:03:15,693][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-18 09:03:15,693][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-18 09:03:15,693][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph22
[2016-07-18 09:03:16,407][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-18 09:03:16,408][ceph22][DEBUG ] detect platform information from remote host
[2016-07-18 09:03:16,424][ceph22][DEBUG ] detect machine type
[2016-07-18 09:03:16,428][ceph22][DEBUG ] find the location of an executable
[2016-07-18 09:03:16,430][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:03:16,441][ceph22][DEBUG ] find the location of an executable
[2016-07-18 09:03:17,102][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-18 09:03:17,103][ceph22][DEBUG ] detect platform information from remote host
[2016-07-18 09:03:17,120][ceph22][DEBUG ] detect machine type
[2016-07-18 09:03:17,124][ceph22][DEBUG ] find the location of an executable
[2016-07-18 09:03:17,126][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:03:17,136][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-18 09:03:17,136][ceph22][INFO  ] purging data on ceph22
[2016-07-18 09:03:17,138][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-18 09:03:17,148][ceph22][WARNING] OSDs may still be mounted, trying to unmount them
[2016-07-18 09:03:17,149][ceph22][INFO  ] Running command: find /var/lib/ceph -mindepth 1 -maxdepth 2 -type d -exec umount {} ;
[2016-07-18 09:03:17,162][ceph22][WARNING] umount: /var/lib/ceph/osd: not mounted
[2016-07-18 09:03:17,278][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-18 09:03:17,290][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-18 09:03:27,938][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-18 09:03:27,939][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph23
[2016-07-18 09:03:27,939][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-18 09:03:27,939][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-18 09:03:27,939][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-18 09:03:27,939][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-18 09:03:27,939][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-18 09:03:27,939][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc1b2e9fb00>
[2016-07-18 09:03:27,940][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-18 09:03:27,940][ceph_deploy.cli][INFO  ]  host                          : ['ceph23']
[2016-07-18 09:03:27,940][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fc1b37b61b8>
[2016-07-18 09:03:27,940][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-18 09:03:27,940][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-18 09:03:27,940][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-18 09:03:27,940][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-18 09:03:27,940][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph23
[2016-07-18 09:03:27,941][ceph_deploy.install][DEBUG ] Detecting platform for host ceph23 ...
[2016-07-18 09:03:28,648][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-18 09:03:28,648][ceph23][DEBUG ] detect platform information from remote host
[2016-07-18 09:03:28,667][ceph23][DEBUG ] detect machine type
[2016-07-18 09:03:28,670][ceph23][DEBUG ] find the location of an executable
[2016-07-18 09:03:28,673][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:03:28,683][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-18 09:03:28,684][ceph23][INFO  ] Purging Ceph on ceph23
[2016-07-18 09:03:28,685][ceph23][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-18 09:03:29,103][ceph23][DEBUG ] Reading package lists...
[2016-07-18 09:03:29,367][ceph23][DEBUG ] Building dependency tree...
[2016-07-18 09:03:29,368][ceph23][DEBUG ] Reading state information...
[2016-07-18 09:03:29,582][ceph23][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-18 09:03:29,582][ceph23][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-18 09:03:29,582][ceph23][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-18 09:03:29,583][ceph23][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-18 09:03:29,583][ceph23][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-18 09:03:29,583][ceph23][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-18 09:03:29,583][ceph23][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libxslt1.1
[2016-07-18 09:03:29,583][ceph23][DEBUG ]   xmlstarlet
[2016-07-18 09:03:29,583][ceph23][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-18 09:03:29,647][ceph23][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 218 not upgraded.
[2016-07-18 09:03:29,743][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-18 09:03:29,744][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph23
[2016-07-18 09:03:29,744][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-18 09:03:29,744][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-18 09:03:29,744][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-18 09:03:29,744][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-18 09:03:29,744][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-18 09:03:29,744][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f1ea7e741b8>
[2016-07-18 09:03:29,744][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-18 09:03:29,744][ceph_deploy.cli][INFO  ]  host                          : ['ceph23']
[2016-07-18 09:03:29,744][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f1ea8783230>
[2016-07-18 09:03:29,744][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-18 09:03:29,745][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-18 09:03:29,745][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph23
[2016-07-18 09:03:30,461][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-18 09:03:30,462][ceph23][DEBUG ] detect platform information from remote host
[2016-07-18 09:03:30,478][ceph23][DEBUG ] detect machine type
[2016-07-18 09:03:30,482][ceph23][DEBUG ] find the location of an executable
[2016-07-18 09:03:30,484][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:03:30,495][ceph23][DEBUG ] find the location of an executable
[2016-07-18 09:03:31,190][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-18 09:03:31,192][ceph23][DEBUG ] detect platform information from remote host
[2016-07-18 09:03:31,209][ceph23][DEBUG ] detect machine type
[2016-07-18 09:03:31,213][ceph23][DEBUG ] find the location of an executable
[2016-07-18 09:03:31,217][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:03:31,233][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-18 09:03:31,234][ceph23][INFO  ] purging data on ceph23
[2016-07-18 09:03:31,235][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-18 09:03:31,245][ceph23][WARNING] OSDs may still be mounted, trying to unmount them
[2016-07-18 09:03:31,246][ceph23][INFO  ] Running command: find /var/lib/ceph -mindepth 1 -maxdepth 2 -type d -exec umount {} ;
[2016-07-18 09:03:31,265][ceph23][WARNING] umount: /var/lib/ceph/osd: not mounted
[2016-07-18 09:03:31,381][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-18 09:03:31,393][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-18 09:04:09,901][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-18 09:04:09,902][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy new ceph21
[2016-07-18 09:04:09,902][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-18 09:04:09,902][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-18 09:04:09,903][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f3b293b0410>
[2016-07-18 09:04:09,903][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-18 09:04:09,903][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-18 09:04:09,903][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-18 09:04:09,903][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3b28b12ef0>
[2016-07-18 09:04:09,903][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-18 09:04:09,903][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2016-07-18 09:04:09,904][ceph_deploy.cli][INFO  ]  mon                           : ['ceph21']
[2016-07-18 09:04:09,904][ceph_deploy.cli][INFO  ]  public_network                : None
[2016-07-18 09:04:09,904][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-18 09:04:09,904][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2016-07-18 09:04:09,904][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-18 09:04:09,904][ceph_deploy.cli][INFO  ]  fsid                          : None
[2016-07-18 09:04:09,904][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2016-07-18 09:04:09,905][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2016-07-18 09:04:09,932][ceph21][DEBUG ] connected to host: cephAdmin 
[2016-07-18 09:04:09,936][ceph21][INFO  ] Running command: ssh -CT -o BatchMode=yes ceph21
[2016-07-18 09:04:10,992][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-18 09:04:10,993][ceph21][DEBUG ] detect platform information from remote host
[2016-07-18 09:04:11,009][ceph21][DEBUG ] detect machine type
[2016-07-18 09:04:11,013][ceph21][DEBUG ] find the location of an executable
[2016-07-18 09:04:11,016][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:04:11,024][ceph21][DEBUG ] find the location of an executable
[2016-07-18 09:04:11,026][ceph21][INFO  ] Running command: /bin/ip link show
[2016-07-18 09:04:11,035][ceph21][INFO  ] Running command: /bin/ip addr show
[2016-07-18 09:04:11,044][ceph21][DEBUG ] IP addresses found: ['10.1.0.44']
[2016-07-18 09:04:11,044][ceph_deploy.new][DEBUG ] Resolving host ceph21
[2016-07-18 09:04:11,045][ceph_deploy.new][DEBUG ] Monitor ceph21 at 10.1.0.44
[2016-07-18 09:04:11,045][ceph_deploy.new][DEBUG ] Monitor initial members are ['ceph21']
[2016-07-18 09:04:11,045][ceph_deploy.new][DEBUG ] Monitor addrs are ['10.1.0.44']
[2016-07-18 09:04:11,045][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2016-07-18 09:04:11,045][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2016-07-18 09:04:11,045][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2016-07-18 09:04:11,149][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-18 09:04:11,149][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy mon create-initial
[2016-07-18 09:04:11,149][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-18 09:04:11,149][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-18 09:04:11,149][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-18 09:04:11,149][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-18 09:04:11,150][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2016-07-18 09:04:11,150][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-18 09:04:11,150][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f904ec5d290>
[2016-07-18 09:04:11,150][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-18 09:04:11,150][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f904ec3e6e0>
[2016-07-18 09:04:11,150][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-18 09:04:11,150][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-18 09:04:11,150][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2016-07-18 09:04:11,152][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts ceph21
[2016-07-18 09:04:11,152][ceph_deploy.mon][DEBUG ] detecting platform for host ceph21 ...
[2016-07-18 09:04:11,837][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-18 09:04:11,838][ceph21][DEBUG ] detect platform information from remote host
[2016-07-18 09:04:11,854][ceph21][DEBUG ] detect machine type
[2016-07-18 09:04:11,858][ceph21][DEBUG ] find the location of an executable
[2016-07-18 09:04:11,860][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:04:11,871][ceph21][DEBUG ] find the location of an executable
[2016-07-18 09:04:11,872][ceph_deploy.mon][INFO  ] distro info: Ubuntu 14.04 trusty
[2016-07-18 09:04:11,872][ceph21][DEBUG ] determining if provided host has same hostname in remote
[2016-07-18 09:04:11,872][ceph21][DEBUG ] get remote short hostname
[2016-07-18 09:04:11,873][ceph21][DEBUG ] deploying mon to ceph21
[2016-07-18 09:04:11,873][ceph21][DEBUG ] get remote short hostname
[2016-07-18 09:04:11,874][ceph21][DEBUG ] remote hostname: ceph21
[2016-07-18 09:04:11,877][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-18 09:04:11,878][ceph21][DEBUG ] create the mon path if it does not exist
[2016-07-18 09:04:11,879][ceph21][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-18 09:04:11,880][ceph21][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-18 09:04:11,881][ceph21][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-18 09:04:11,881][ceph21][DEBUG ] create the monitor keyring file
[2016-07-18 09:04:11,883][ceph21][INFO  ] Running command: ceph-mon --cluster ceph --mkfs -i ceph21 --keyring /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-18 09:04:11,918][ceph21][DEBUG ] ceph-mon: mon.noname-a 10.1.0.44:6789/0 is local, renaming to mon.ceph21
[2016-07-18 09:04:11,918][ceph21][DEBUG ] ceph-mon: set fsid to b0809e36-838b-4852-9d2a-6712452a3ce7
[2016-07-18 09:04:11,918][ceph21][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-ceph21 for mon.ceph21
[2016-07-18 09:04:11,919][ceph21][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-18 09:04:11,920][ceph21][DEBUG ] create a done file to avoid re-doing the mon deployment
[2016-07-18 09:04:11,921][ceph21][DEBUG ] create the init path if it does not exist
[2016-07-18 09:04:11,923][ceph21][INFO  ] Running command: initctl emit ceph-mon cluster=ceph id=ceph21
[2016-07-18 09:04:13,962][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-18 09:04:14,028][ceph21][DEBUG ] ********************************************************************************
[2016-07-18 09:04:14,028][ceph21][DEBUG ] status for monitor: mon.ceph21
[2016-07-18 09:04:14,028][ceph21][DEBUG ] {
[2016-07-18 09:04:14,029][ceph21][DEBUG ]   "election_epoch": 2, 
[2016-07-18 09:04:14,029][ceph21][DEBUG ]   "extra_probe_peers": [], 
[2016-07-18 09:04:14,029][ceph21][DEBUG ]   "monmap": {
[2016-07-18 09:04:14,029][ceph21][DEBUG ]     "created": "0.000000", 
[2016-07-18 09:04:14,029][ceph21][DEBUG ]     "epoch": 1, 
[2016-07-18 09:04:14,029][ceph21][DEBUG ]     "fsid": "b0809e36-838b-4852-9d2a-6712452a3ce7", 
[2016-07-18 09:04:14,029][ceph21][DEBUG ]     "modified": "0.000000", 
[2016-07-18 09:04:14,029][ceph21][DEBUG ]     "mons": [
[2016-07-18 09:04:14,029][ceph21][DEBUG ]       {
[2016-07-18 09:04:14,030][ceph21][DEBUG ]         "addr": "10.1.0.44:6789/0", 
[2016-07-18 09:04:14,030][ceph21][DEBUG ]         "name": "ceph21", 
[2016-07-18 09:04:14,030][ceph21][DEBUG ]         "rank": 0
[2016-07-18 09:04:14,030][ceph21][DEBUG ]       }
[2016-07-18 09:04:14,030][ceph21][DEBUG ]     ]
[2016-07-18 09:04:14,030][ceph21][DEBUG ]   }, 
[2016-07-18 09:04:14,030][ceph21][DEBUG ]   "name": "ceph21", 
[2016-07-18 09:04:14,030][ceph21][DEBUG ]   "outside_quorum": [], 
[2016-07-18 09:04:14,031][ceph21][DEBUG ]   "quorum": [
[2016-07-18 09:04:14,031][ceph21][DEBUG ]     0
[2016-07-18 09:04:14,031][ceph21][DEBUG ]   ], 
[2016-07-18 09:04:14,031][ceph21][DEBUG ]   "rank": 0, 
[2016-07-18 09:04:14,031][ceph21][DEBUG ]   "state": "leader", 
[2016-07-18 09:04:14,031][ceph21][DEBUG ]   "sync_provider": []
[2016-07-18 09:04:14,031][ceph21][DEBUG ] }
[2016-07-18 09:04:14,031][ceph21][DEBUG ] ********************************************************************************
[2016-07-18 09:04:14,032][ceph21][INFO  ] monitor: mon.ceph21 is running
[2016-07-18 09:04:14,033][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-18 09:04:14,099][ceph_deploy.mon][INFO  ] processing monitor mon.ceph21
[2016-07-18 09:04:14,778][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-18 09:04:14,779][ceph21][DEBUG ] detect platform information from remote host
[2016-07-18 09:04:14,795][ceph21][DEBUG ] detect machine type
[2016-07-18 09:04:14,799][ceph21][DEBUG ] find the location of an executable
[2016-07-18 09:04:14,801][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:04:14,818][ceph21][DEBUG ] find the location of an executable
[2016-07-18 09:04:14,822][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-18 09:04:14,888][ceph_deploy.mon][INFO  ] mon.ceph21 monitor has reached quorum!
[2016-07-18 09:04:14,888][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2016-07-18 09:04:14,889][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2016-07-18 09:04:14,889][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /etc/ceph/ceph.client.admin.keyring
[2016-07-18 09:04:15,610][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-18 09:04:15,611][ceph21][DEBUG ] detect platform information from remote host
[2016-07-18 09:04:15,633][ceph21][DEBUG ] detect machine type
[2016-07-18 09:04:15,637][ceph21][DEBUG ] find the location of an executable
[2016-07-18 09:04:15,639][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:04:15,648][ceph21][DEBUG ] fetch remote file
[2016-07-18 09:04:15,649][ceph_deploy.gatherkeys][DEBUG ] Got ceph.client.admin.keyring key from ceph21.
[2016-07-18 09:04:15,649][ceph_deploy.gatherkeys][DEBUG ] Have ceph.mon.keyring
[2016-07-18 09:04:15,649][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-osd/ceph.keyring
[2016-07-18 09:04:16,341][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-18 09:04:16,342][ceph21][DEBUG ] detect platform information from remote host
[2016-07-18 09:04:16,360][ceph21][DEBUG ] detect machine type
[2016-07-18 09:04:16,364][ceph21][DEBUG ] find the location of an executable
[2016-07-18 09:04:16,366][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:04:16,375][ceph21][DEBUG ] fetch remote file
[2016-07-18 09:04:16,376][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-osd.keyring key from ceph21.
[2016-07-18 09:04:16,376][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-mds/ceph.keyring
[2016-07-18 09:04:17,050][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-18 09:04:17,051][ceph21][DEBUG ] detect platform information from remote host
[2016-07-18 09:04:17,070][ceph21][DEBUG ] detect machine type
[2016-07-18 09:04:17,074][ceph21][DEBUG ] find the location of an executable
[2016-07-18 09:04:17,076][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:04:17,085][ceph21][DEBUG ] fetch remote file
[2016-07-18 09:04:17,086][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-mds.keyring key from ceph21.
[2016-07-18 09:04:17,087][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-rgw/ceph.keyring
[2016-07-18 09:04:17,751][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-18 09:04:17,752][ceph21][DEBUG ] detect platform information from remote host
[2016-07-18 09:04:17,767][ceph21][DEBUG ] detect machine type
[2016-07-18 09:04:17,771][ceph21][DEBUG ] find the location of an executable
[2016-07-18 09:04:17,773][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:04:17,782][ceph21][DEBUG ] fetch remote file
[2016-07-18 09:04:17,783][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-rgw.keyring key from ceph21.
[2016-07-18 09:04:17,903][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-18 09:04:17,903][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf osd create --zap-disk ceph22:/dev/vdb ceph22:/dev/vdc ceph23:/dev/vdb ceph23:/dev/vdc
[2016-07-18 09:04:17,903][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-18 09:04:17,904][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-18 09:04:17,904][ceph_deploy.cli][INFO  ]  disk                          : [('ceph22', '/dev/vdb', None), ('ceph22', '/dev/vdc', None), ('ceph23', '/dev/vdb', None), ('ceph23', '/dev/vdc', None)]
[2016-07-18 09:04:17,904][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2016-07-18 09:04:17,904][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-18 09:04:17,904][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2016-07-18 09:04:17,904][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-18 09:04:17,904][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-18 09:04:17,904][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2016-07-18 09:04:17,905][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-18 09:04:17,905][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb3ef4f01b8>
[2016-07-18 09:04:17,905][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-18 09:04:17,905][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2016-07-18 09:04:17,905][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fb3ef4c1578>
[2016-07-18 09:04:17,905][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-18 09:04:17,905][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-18 09:04:17,906][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2016-07-18 09:04:17,907][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks ceph22:/dev/vdb: ceph22:/dev/vdc: ceph23:/dev/vdb: ceph23:/dev/vdc:
[2016-07-18 09:04:18,616][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-18 09:04:18,617][ceph22][DEBUG ] detect platform information from remote host
[2016-07-18 09:04:18,633][ceph22][DEBUG ] detect machine type
[2016-07-18 09:04:18,637][ceph22][DEBUG ] find the location of an executable
[2016-07-18 09:04:18,640][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:04:18,653][ceph22][DEBUG ] find the location of an executable
[2016-07-18 09:04:18,654][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-18 09:04:18,654][ceph_deploy.osd][DEBUG ] Deploying osd to ceph22
[2016-07-18 09:04:18,655][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-18 09:04:18,657][ceph22][WARNING] osd keyring does not exist yet, creating one
[2016-07-18 09:04:18,657][ceph22][DEBUG ] create a keyring file
[2016-07-18 09:04:18,658][ceph_deploy.osd][DEBUG ] Preparing host ceph22 disk /dev/vdb journal None activate True
[2016-07-18 09:04:18,658][ceph22][DEBUG ] find the location of an executable
[2016-07-18 09:04:18,660][ceph22][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-18 09:04:18,727][ceph22][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-18 09:04:18,727][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-18 09:04:18,727][ceph22][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-18 09:04:18,727][ceph22][WARNING] backup header from main header.
[2016-07-18 09:04:18,727][ceph22][WARNING] 
[2016-07-18 09:04:18,728][ceph22][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-18 09:04:18,728][ceph22][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-18 09:04:18,728][ceph22][WARNING] 
[2016-07-18 09:04:18,728][ceph22][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-18 09:04:18,728][ceph22][WARNING] 
[2016-07-18 09:04:19,744][ceph22][DEBUG ] ****************************************************************************
[2016-07-18 09:04:19,744][ceph22][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-18 09:04:19,744][ceph22][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-18 09:04:19,744][ceph22][DEBUG ] ****************************************************************************
[2016-07-18 09:04:19,744][ceph22][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-18 09:04:19,745][ceph22][DEBUG ] other utilities.
[2016-07-18 09:04:19,745][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-18 09:04:20,811][ceph22][DEBUG ] Creating new GPT entries.
[2016-07-18 09:04:20,811][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-18 09:04:20,811][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-18 09:04:20,812][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-18 09:04:20,812][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-18 09:04:20,812][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-18 09:04:20,812][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-18 09:04:20,819][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-18 09:04:20,835][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-18 09:04:20,842][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-18 09:04:20,858][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-18 09:04:20,865][ceph22][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-18 09:04:20,866][ceph22][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-18 09:04:20,866][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:450266cd-499a-4094-8ffc-8b9d1ee34bff --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-18 09:04:21,882][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-18 09:04:21,883][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-18 09:04:21,884][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-18 09:04:22,048][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-18 09:04:22,112][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/450266cd-499a-4094-8ffc-8b9d1ee34bff
[2016-07-18 09:04:22,112][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/450266cd-499a-4094-8ffc-8b9d1ee34bff
[2016-07-18 09:04:22,112][ceph22][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-18 09:04:22,112][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:3ae35d6a-f05f-44ee-ae09-e11e57470fe5 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-18 09:04:23,129][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-18 09:04:23,129][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-18 09:04:23,129][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-18 09:04:23,397][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-18 09:04:23,429][ceph22][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-18 09:04:23,429][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-18 09:04:24,195][ceph22][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-18 09:04:24,195][ceph22][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-18 09:04:24,196][ceph22][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-18 09:04:24,196][ceph22][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-18 09:04:24,196][ceph22][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.4j9EHU with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-18 09:04:24,196][ceph22][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-18 09:04:24,196][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.4j9EHU
[2016-07-18 09:04:24,196][ceph22][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-18 09:04:24,196][ceph22][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-18 09:04:24,196][ceph22][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-18 09:04:24,200][ceph22][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.4j9EHU
[2016-07-18 09:04:24,200][ceph22][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.4j9EHU/journal -> /dev/disk/by-partuuid/450266cd-499a-4094-8ffc-8b9d1ee34bff
[2016-07-18 09:04:24,231][ceph22][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.4j9EHU
[2016-07-18 09:04:24,232][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.4j9EHU
[2016-07-18 09:04:24,263][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-18 09:04:25,279][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-18 09:04:25,280][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-18 09:04:25,280][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-18 09:04:31,401][ceph22][INFO  ] checking OSD status...
[2016-07-18 09:04:31,402][ceph22][DEBUG ] find the location of an executable
[2016-07-18 09:04:31,405][ceph22][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-18 09:04:31,621][ceph_deploy.osd][DEBUG ] Host ceph22 is now ready for osd use.
[2016-07-18 09:04:32,315][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-18 09:04:32,316][ceph22][DEBUG ] detect platform information from remote host
[2016-07-18 09:04:32,339][ceph22][DEBUG ] detect machine type
[2016-07-18 09:04:32,343][ceph22][DEBUG ] find the location of an executable
[2016-07-18 09:04:32,346][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:04:32,362][ceph22][DEBUG ] find the location of an executable
[2016-07-18 09:04:32,364][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-18 09:04:32,364][ceph_deploy.osd][DEBUG ] Preparing host ceph22 disk /dev/vdc journal None activate True
[2016-07-18 09:04:32,364][ceph22][DEBUG ] find the location of an executable
[2016-07-18 09:04:32,366][ceph22][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-18 09:04:32,433][ceph22][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-18 09:04:32,434][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-18 09:04:32,434][ceph22][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-18 09:04:32,434][ceph22][WARNING] backup header from main header.
[2016-07-18 09:04:32,434][ceph22][WARNING] 
[2016-07-18 09:04:32,434][ceph22][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-18 09:04:32,435][ceph22][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-18 09:04:32,435][ceph22][WARNING] 
[2016-07-18 09:04:32,435][ceph22][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-18 09:04:32,435][ceph22][WARNING] 
[2016-07-18 09:04:33,451][ceph22][DEBUG ] ****************************************************************************
[2016-07-18 09:04:33,452][ceph22][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-18 09:04:33,452][ceph22][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-18 09:04:33,452][ceph22][DEBUG ] ****************************************************************************
[2016-07-18 09:04:33,452][ceph22][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-18 09:04:33,452][ceph22][DEBUG ] other utilities.
[2016-07-18 09:04:33,452][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-18 09:04:34,519][ceph22][DEBUG ] Creating new GPT entries.
[2016-07-18 09:04:34,519][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-18 09:04:34,519][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-18 09:04:34,519][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-18 09:04:34,520][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-18 09:04:34,520][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-18 09:04:34,520][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-18 09:04:34,527][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-18 09:04:34,543][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-18 09:04:34,559][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-18 09:04:34,566][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-18 09:04:34,582][ceph22][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-18 09:04:34,582][ceph22][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-18 09:04:34,582][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:4b4e28ed-94fb-4b79-809d-2ee704c64ad6 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-18 09:04:35,600][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-18 09:04:35,601][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-18 09:04:35,601][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-18 09:04:35,765][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-18 09:04:35,829][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/4b4e28ed-94fb-4b79-809d-2ee704c64ad6
[2016-07-18 09:04:35,829][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/4b4e28ed-94fb-4b79-809d-2ee704c64ad6
[2016-07-18 09:04:35,829][ceph22][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-18 09:04:35,829][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:bc32839d-b413-416e-ba58-e49b1931d2b8 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-18 09:04:36,845][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-18 09:04:36,846][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-18 09:04:36,847][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-18 09:04:37,111][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-18 09:04:37,143][ceph22][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-18 09:04:37,143][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-18 09:04:37,908][ceph22][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-18 09:04:37,909][ceph22][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-18 09:04:37,909][ceph22][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-18 09:04:37,909][ceph22][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-18 09:04:37,909][ceph22][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-18 09:04:37,909][ceph22][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-18 09:04:37,909][ceph22][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-18 09:04:37,910][ceph22][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-18 09:04:37,910][ceph22][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt.ktV_Kw with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-18 09:04:37,910][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt.ktV_Kw
[2016-07-18 09:04:37,917][ceph22][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.ktV_Kw
[2016-07-18 09:04:37,917][ceph22][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.ktV_Kw/journal -> /dev/disk/by-partuuid/4b4e28ed-94fb-4b79-809d-2ee704c64ad6
[2016-07-18 09:04:37,949][ceph22][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.ktV_Kw
[2016-07-18 09:04:37,950][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.ktV_Kw
[2016-07-18 09:04:37,981][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-18 09:04:38,997][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-18 09:04:38,998][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-18 09:04:38,998][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-18 09:04:45,170][ceph22][INFO  ] checking OSD status...
[2016-07-18 09:04:45,170][ceph22][DEBUG ] find the location of an executable
[2016-07-18 09:04:45,174][ceph22][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-18 09:04:45,389][ceph_deploy.osd][DEBUG ] Host ceph22 is now ready for osd use.
[2016-07-18 09:04:46,083][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-18 09:04:46,085][ceph23][DEBUG ] detect platform information from remote host
[2016-07-18 09:04:46,100][ceph23][DEBUG ] detect machine type
[2016-07-18 09:04:46,104][ceph23][DEBUG ] find the location of an executable
[2016-07-18 09:04:46,107][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:04:46,124][ceph23][DEBUG ] find the location of an executable
[2016-07-18 09:04:46,125][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-18 09:04:46,126][ceph_deploy.osd][DEBUG ] Deploying osd to ceph23
[2016-07-18 09:04:46,126][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-18 09:04:46,129][ceph23][WARNING] osd keyring does not exist yet, creating one
[2016-07-18 09:04:46,129][ceph23][DEBUG ] create a keyring file
[2016-07-18 09:04:46,130][ceph_deploy.osd][DEBUG ] Preparing host ceph23 disk /dev/vdb journal None activate True
[2016-07-18 09:04:46,130][ceph23][DEBUG ] find the location of an executable
[2016-07-18 09:04:46,132][ceph23][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-18 09:04:46,200][ceph23][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-18 09:04:46,200][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-18 09:04:46,200][ceph23][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-18 09:04:46,201][ceph23][WARNING] backup header from main header.
[2016-07-18 09:04:46,201][ceph23][WARNING] 
[2016-07-18 09:04:46,201][ceph23][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-18 09:04:46,201][ceph23][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-18 09:04:46,201][ceph23][WARNING] 
[2016-07-18 09:04:46,202][ceph23][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-18 09:04:46,202][ceph23][WARNING] 
[2016-07-18 09:04:47,268][ceph23][DEBUG ] ****************************************************************************
[2016-07-18 09:04:47,268][ceph23][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-18 09:04:47,269][ceph23][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-18 09:04:47,269][ceph23][DEBUG ] ****************************************************************************
[2016-07-18 09:04:47,269][ceph23][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-18 09:04:47,270][ceph23][DEBUG ] other utilities.
[2016-07-18 09:04:47,270][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-18 09:04:48,286][ceph23][DEBUG ] Creating new GPT entries.
[2016-07-18 09:04:48,287][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-18 09:04:48,287][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-18 09:04:48,287][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-18 09:04:48,287][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-18 09:04:48,287][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-18 09:04:48,291][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-18 09:04:48,306][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-18 09:04:48,322][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-18 09:04:48,338][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-18 09:04:48,345][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-18 09:04:48,361][ceph23][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-18 09:04:48,361][ceph23][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-18 09:04:48,362][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:ba11f39c-f132-482e-bbfd-0c50ae1dd2c5 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-18 09:04:49,428][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-18 09:04:49,428][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-18 09:04:49,428][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-18 09:04:49,542][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-18 09:04:49,606][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/ba11f39c-f132-482e-bbfd-0c50ae1dd2c5
[2016-07-18 09:04:49,607][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/ba11f39c-f132-482e-bbfd-0c50ae1dd2c5
[2016-07-18 09:04:49,607][ceph23][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-18 09:04:49,607][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:6f432778-6dfe-4256-9862-da5f5394a869 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-18 09:04:50,623][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-18 09:04:50,624][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-18 09:04:50,624][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-18 09:04:50,888][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-18 09:04:50,952][ceph23][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-18 09:04:50,953][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-18 09:04:51,718][ceph23][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-18 09:04:51,719][ceph23][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-18 09:04:51,719][ceph23][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-18 09:04:51,719][ceph23][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-18 09:04:51,720][ceph23][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-18 09:04:51,720][ceph23][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-18 09:04:51,720][ceph23][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-18 09:04:51,720][ceph23][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-18 09:04:51,721][ceph23][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.I4jgAe with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-18 09:04:51,721][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.I4jgAe
[2016-07-18 09:04:51,721][ceph23][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.I4jgAe
[2016-07-18 09:04:51,721][ceph23][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.I4jgAe/journal -> /dev/disk/by-partuuid/ba11f39c-f132-482e-bbfd-0c50ae1dd2c5
[2016-07-18 09:04:51,737][ceph23][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.I4jgAe
[2016-07-18 09:04:51,737][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.I4jgAe
[2016-07-18 09:04:51,801][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-18 09:04:52,818][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-18 09:04:52,818][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-18 09:04:52,818][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-18 09:04:59,140][ceph23][INFO  ] checking OSD status...
[2016-07-18 09:04:59,141][ceph23][DEBUG ] find the location of an executable
[2016-07-18 09:04:59,144][ceph23][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-18 09:04:59,359][ceph_deploy.osd][DEBUG ] Host ceph23 is now ready for osd use.
[2016-07-18 09:05:00,002][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-18 09:05:00,003][ceph23][DEBUG ] detect platform information from remote host
[2016-07-18 09:05:00,019][ceph23][DEBUG ] detect machine type
[2016-07-18 09:05:00,022][ceph23][DEBUG ] find the location of an executable
[2016-07-18 09:05:00,025][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:05:00,035][ceph23][DEBUG ] find the location of an executable
[2016-07-18 09:05:00,036][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-18 09:05:00,036][ceph_deploy.osd][DEBUG ] Preparing host ceph23 disk /dev/vdc journal None activate True
[2016-07-18 09:05:00,036][ceph23][DEBUG ] find the location of an executable
[2016-07-18 09:05:00,038][ceph23][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-18 09:05:00,105][ceph23][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-18 09:05:00,105][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-18 09:05:00,105][ceph23][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-18 09:05:00,105][ceph23][WARNING] backup header from main header.
[2016-07-18 09:05:00,105][ceph23][WARNING] 
[2016-07-18 09:05:00,106][ceph23][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-18 09:05:00,106][ceph23][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-18 09:05:00,106][ceph23][WARNING] 
[2016-07-18 09:05:00,106][ceph23][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-18 09:05:00,106][ceph23][WARNING] 
[2016-07-18 09:05:01,172][ceph23][DEBUG ] ****************************************************************************
[2016-07-18 09:05:01,172][ceph23][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-18 09:05:01,172][ceph23][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-18 09:05:01,173][ceph23][DEBUG ] ****************************************************************************
[2016-07-18 09:05:01,173][ceph23][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-18 09:05:01,173][ceph23][DEBUG ] other utilities.
[2016-07-18 09:05:01,173][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-18 09:05:02,189][ceph23][DEBUG ] Creating new GPT entries.
[2016-07-18 09:05:02,189][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-18 09:05:02,189][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-18 09:05:02,190][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-18 09:05:02,190][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-18 09:05:02,190][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-18 09:05:02,190][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-18 09:05:02,198][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-18 09:05:02,213][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-18 09:05:02,229][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-18 09:05:02,245][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-18 09:05:02,248][ceph23][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-18 09:05:02,248][ceph23][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-18 09:05:02,249][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:60b2a022-d2de-409f-8902-6d75c298068e --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-18 09:05:03,315][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-18 09:05:03,315][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-18 09:05:03,316][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-18 09:05:03,429][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-18 09:05:03,493][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/60b2a022-d2de-409f-8902-6d75c298068e
[2016-07-18 09:05:03,494][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/60b2a022-d2de-409f-8902-6d75c298068e
[2016-07-18 09:05:03,494][ceph23][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-18 09:05:03,494][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:5658bd4d-c8af-4593-a139-3fb10d199d0a --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-18 09:05:04,510][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-18 09:05:04,510][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-18 09:05:04,511][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-18 09:05:04,775][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-18 09:05:04,839][ceph23][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-18 09:05:04,840][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-18 09:05:05,605][ceph23][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-18 09:05:05,606][ceph23][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-18 09:05:05,606][ceph23][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-18 09:05:05,606][ceph23][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-18 09:05:05,606][ceph23][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-18 09:05:05,606][ceph23][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-18 09:05:05,607][ceph23][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-18 09:05:05,607][ceph23][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-18 09:05:05,607][ceph23][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt.7gm6nd with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-18 09:05:05,607][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt.7gm6nd
[2016-07-18 09:05:05,607][ceph23][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.7gm6nd
[2016-07-18 09:05:05,608][ceph23][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.7gm6nd/journal -> /dev/disk/by-partuuid/60b2a022-d2de-409f-8902-6d75c298068e
[2016-07-18 09:05:05,623][ceph23][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.7gm6nd
[2016-07-18 09:05:05,623][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.7gm6nd
[2016-07-18 09:05:05,655][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-18 09:05:06,671][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-18 09:05:06,671][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-18 09:05:06,672][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-18 09:05:12,840][ceph23][INFO  ] checking OSD status...
[2016-07-18 09:05:12,840][ceph23][DEBUG ] find the location of an executable
[2016-07-18 09:05:12,843][ceph23][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-18 09:05:13,059][ceph_deploy.osd][DEBUG ] Host ceph23 is now ready for osd use.
[2016-07-18 09:05:13,164][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-18 09:05:13,164][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf admin ceph21 ceph22 ceph23
[2016-07-18 09:05:13,164][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-18 09:05:13,164][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-18 09:05:13,165][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-18 09:05:13,165][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-18 09:05:13,165][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-18 09:05:13,165][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6dd65a05a8>
[2016-07-18 09:05:13,165][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-18 09:05:13,165][ceph_deploy.cli][INFO  ]  client                        : ['ceph21', 'ceph22', 'ceph23']
[2016-07-18 09:05:13,165][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f6dd6ec27d0>
[2016-07-18 09:05:13,165][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-18 09:05:13,166][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-18 09:05:13,167][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph21
[2016-07-18 09:05:13,934][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-18 09:05:13,935][ceph21][DEBUG ] detect platform information from remote host
[2016-07-18 09:05:13,959][ceph21][DEBUG ] detect machine type
[2016-07-18 09:05:13,963][ceph21][DEBUG ] find the location of an executable
[2016-07-18 09:05:13,966][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:05:13,985][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-18 09:05:13,988][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph22
[2016-07-18 09:05:14,679][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-18 09:05:14,680][ceph22][DEBUG ] detect platform information from remote host
[2016-07-18 09:05:14,697][ceph22][DEBUG ] detect machine type
[2016-07-18 09:05:14,701][ceph22][DEBUG ] find the location of an executable
[2016-07-18 09:05:14,703][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:05:14,712][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-18 09:05:14,715][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph23
[2016-07-18 09:05:15,428][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-18 09:05:15,429][ceph23][DEBUG ] detect platform information from remote host
[2016-07-18 09:05:15,446][ceph23][DEBUG ] detect machine type
[2016-07-18 09:05:15,449][ceph23][DEBUG ] find the location of an executable
[2016-07-18 09:05:15,451][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:05:15,460][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-18 09:06:39,440][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-18 09:06:39,441][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf config push ceph21 ceph22 ceph23
[2016-07-18 09:06:39,441][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-18 09:06:39,441][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-18 09:06:39,441][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-18 09:06:39,441][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-18 09:06:39,441][ceph_deploy.cli][INFO  ]  subcommand                    : push
[2016-07-18 09:06:39,442][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-18 09:06:39,442][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fefc7321518>
[2016-07-18 09:06:39,442][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-18 09:06:39,442][ceph_deploy.cli][INFO  ]  client                        : ['ceph21', 'ceph22', 'ceph23']
[2016-07-18 09:06:39,442][ceph_deploy.cli][INFO  ]  func                          : <function config at 0x7fefc736a938>
[2016-07-18 09:06:39,442][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-18 09:06:39,442][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-18 09:06:39,442][ceph_deploy.config][DEBUG ] Pushing config to ceph21
[2016-07-18 09:06:40,164][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-18 09:06:40,165][ceph21][DEBUG ] detect platform information from remote host
[2016-07-18 09:06:40,182][ceph21][DEBUG ] detect machine type
[2016-07-18 09:06:40,186][ceph21][DEBUG ] find the location of an executable
[2016-07-18 09:06:40,188][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:06:40,200][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-18 09:06:40,202][ceph_deploy.config][DEBUG ] Pushing config to ceph22
[2016-07-18 09:06:40,874][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-18 09:06:40,875][ceph22][DEBUG ] detect platform information from remote host
[2016-07-18 09:06:40,890][ceph22][DEBUG ] detect machine type
[2016-07-18 09:06:40,894][ceph22][DEBUG ] find the location of an executable
[2016-07-18 09:06:40,896][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:06:40,913][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-18 09:06:40,916][ceph_deploy.config][DEBUG ] Pushing config to ceph23
[2016-07-18 09:06:41,655][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-18 09:06:41,656][ceph23][DEBUG ] detect platform information from remote host
[2016-07-18 09:06:41,674][ceph23][DEBUG ] detect machine type
[2016-07-18 09:06:41,679][ceph23][DEBUG ] find the location of an executable
[2016-07-18 09:06:41,682][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:06:41,699][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-18 09:09:41,927][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-18 09:09:41,927][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy rgw create ceph21
[2016-07-18 09:09:41,927][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-18 09:09:41,927][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-18 09:09:41,927][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-18 09:09:41,927][ceph_deploy.cli][INFO  ]  rgw                           : [('ceph21', 'rgw.ceph21')]
[2016-07-18 09:09:41,928][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-18 09:09:41,928][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-18 09:09:41,928][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-18 09:09:41,928][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3912dd1680>
[2016-07-18 09:09:41,928][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-18 09:09:41,928][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f39136986e0>
[2016-07-18 09:09:41,928][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-18 09:09:41,928][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-18 09:09:41,929][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts ceph21:rgw.ceph21
[2016-07-18 09:09:42,704][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-18 09:09:42,705][ceph21][DEBUG ] detect platform information from remote host
[2016-07-18 09:09:42,722][ceph21][DEBUG ] detect machine type
[2016-07-18 09:09:42,726][ceph21][DEBUG ] find the location of an executable
[2016-07-18 09:09:42,728][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:09:42,739][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-18 09:09:42,739][ceph_deploy.rgw][DEBUG ] remote host will use upstart
[2016-07-18 09:09:42,740][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to ceph21
[2016-07-18 09:09:42,740][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-18 09:09:42,742][ceph_deploy.rgw][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2016-07-18 09:09:42,742][ceph_deploy][ERROR ] GenericError: Failed to create 1 RGWs

[2016-07-18 09:10:20,161][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-18 09:10:20,161][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf rgw create ceph21
[2016-07-18 09:10:20,161][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-18 09:10:20,161][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-18 09:10:20,161][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-18 09:10:20,162][ceph_deploy.cli][INFO  ]  rgw                           : [('ceph21', 'rgw.ceph21')]
[2016-07-18 09:10:20,162][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-18 09:10:20,162][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-18 09:10:20,162][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-18 09:10:20,162][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f918f567680>
[2016-07-18 09:10:20,162][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-18 09:10:20,162][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f918fe2e6e0>
[2016-07-18 09:10:20,162][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-18 09:10:20,162][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-18 09:10:20,163][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts ceph21:rgw.ceph21
[2016-07-18 09:10:20,901][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-18 09:10:20,902][ceph21][DEBUG ] detect platform information from remote host
[2016-07-18 09:10:20,920][ceph21][DEBUG ] detect machine type
[2016-07-18 09:10:20,924][ceph21][DEBUG ] find the location of an executable
[2016-07-18 09:10:20,927][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:10:20,938][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-18 09:10:20,938][ceph_deploy.rgw][DEBUG ] remote host will use upstart
[2016-07-18 09:10:20,938][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to ceph21
[2016-07-18 09:10:20,939][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-18 09:10:20,942][ceph21][DEBUG ] create path recursively if it doesn't exist
[2016-07-18 09:10:20,947][ceph21][INFO  ] Running command: ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.ceph21 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.ceph21/keyring
[2016-07-18 09:10:21,174][ceph21][INFO  ] Running command: initctl emit radosgw cluster=ceph id=rgw.ceph21
[2016-07-18 09:10:21,193][ceph_deploy.rgw][INFO  ] The Ceph Object Gateway (RGW) is now running on host ceph21 and default port 7480
[2016-07-18 09:15:54,513][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-18 09:15:54,513][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf config push ceph21
[2016-07-18 09:15:54,513][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-18 09:15:54,514][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-18 09:15:54,514][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-18 09:15:54,514][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-18 09:15:54,514][ceph_deploy.cli][INFO  ]  subcommand                    : push
[2016-07-18 09:15:54,514][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-18 09:15:54,514][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5d371de518>
[2016-07-18 09:15:54,514][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-18 09:15:54,514][ceph_deploy.cli][INFO  ]  client                        : ['ceph21']
[2016-07-18 09:15:54,514][ceph_deploy.cli][INFO  ]  func                          : <function config at 0x7f5d37227938>
[2016-07-18 09:15:54,514][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-18 09:15:54,514][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-18 09:15:54,514][ceph_deploy.config][DEBUG ] Pushing config to ceph21
[2016-07-18 09:15:55,208][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-18 09:15:55,210][ceph21][DEBUG ] detect platform information from remote host
[2016-07-18 09:15:55,225][ceph21][DEBUG ] detect machine type
[2016-07-18 09:15:55,229][ceph21][DEBUG ] find the location of an executable
[2016-07-18 09:15:55,232][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-18 09:15:55,243][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 14:56:03,196][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 14:56:03,196][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf osd create --zap-disk ceph21:/dev/vdb ceph21:/dev/vdc
[2016-07-20 14:56:03,197][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 14:56:03,197][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 14:56:03,197][ceph_deploy.cli][INFO  ]  disk                          : [('ceph21', '/dev/vdb', None), ('ceph21', '/dev/vdc', None)]
[2016-07-20 14:56:03,197][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2016-07-20 14:56:03,197][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 14:56:03,197][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2016-07-20 14:56:03,197][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-20 14:56:03,197][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-20 14:56:03,197][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2016-07-20 14:56:03,197][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 14:56:03,198][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc4408c71b8>
[2016-07-20 14:56:03,198][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 14:56:03,198][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2016-07-20 14:56:03,198][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fc440898578>
[2016-07-20 14:56:03,198][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 14:56:03,198][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 14:56:03,198][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2016-07-20 14:56:03,199][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks ceph21:/dev/vdb: ceph21:/dev/vdc:
[2016-07-20 14:56:03,926][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 14:56:03,927][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 14:56:03,944][ceph21][DEBUG ] detect machine type
[2016-07-20 14:56:03,947][ceph21][DEBUG ] find the location of an executable
[2016-07-20 14:56:03,950][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 14:56:03,962][ceph21][DEBUG ] find the location of an executable
[2016-07-20 14:56:03,963][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-20 14:56:03,963][ceph_deploy.osd][DEBUG ] Deploying osd to ceph21
[2016-07-20 14:56:03,963][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 14:56:03,965][ceph_deploy.osd][DEBUG ] Preparing host ceph21 disk /dev/vdb journal None activate True
[2016-07-20 14:56:03,965][ceph21][DEBUG ] find the location of an executable
[2016-07-20 14:56:03,967][ceph21][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-20 14:56:04,085][ceph21][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-20 14:56:04,086][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-20 14:56:05,102][ceph21][DEBUG ] Creating new GPT entries.
[2016-07-20 14:56:05,102][ceph21][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-20 14:56:05,102][ceph21][DEBUG ] other utilities.
[2016-07-20 14:56:05,102][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-20 14:56:06,118][ceph21][DEBUG ] Creating new GPT entries.
[2016-07-20 14:56:06,118][ceph21][DEBUG ] The operation has completed successfully.
[2016-07-20 14:56:06,118][ceph21][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-20 14:56:06,119][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-20 14:56:06,232][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-20 14:56:06,233][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-20 14:56:06,233][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-20 14:56:06,248][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-20 14:56:06,264][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-20 14:56:06,280][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-20 14:56:06,296][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-20 14:56:06,311][ceph21][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-20 14:56:06,311][ceph21][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-20 14:56:06,312][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:8f077780-3e09-4e52-8c01-8534795749a7 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-20 14:56:07,378][ceph21][DEBUG ] The operation has completed successfully.
[2016-07-20 14:56:07,378][ceph21][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-20 14:56:07,379][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-20 14:56:07,543][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-20 14:56:07,543][ceph21][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/8f077780-3e09-4e52-8c01-8534795749a7
[2016-07-20 14:56:07,543][ceph21][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/8f077780-3e09-4e52-8c01-8534795749a7
[2016-07-20 14:56:07,544][ceph21][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-20 14:56:07,544][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:80c910ea-c01f-40e1-a0d4-f641659f6628 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-20 14:56:08,610][ceph21][DEBUG ] The operation has completed successfully.
[2016-07-20 14:56:08,610][ceph21][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-20 14:56:08,611][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-20 14:56:08,774][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-20 14:56:08,889][ceph21][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-20 14:56:08,889][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-20 14:56:09,705][ceph21][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-20 14:56:09,705][ceph21][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-20 14:56:09,705][ceph21][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-20 14:56:09,705][ceph21][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-20 14:56:09,705][ceph21][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-20 14:56:09,706][ceph21][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-20 14:56:09,706][ceph21][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-20 14:56:09,706][ceph21][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-20 14:56:09,706][ceph21][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.2dUSPl with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-20 14:56:09,706][ceph21][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.2dUSPl
[2016-07-20 14:56:09,706][ceph21][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.2dUSPl
[2016-07-20 14:56:09,706][ceph21][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.2dUSPl/journal -> /dev/disk/by-partuuid/8f077780-3e09-4e52-8c01-8534795749a7
[2016-07-20 14:56:09,708][ceph21][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.2dUSPl
[2016-07-20 14:56:09,708][ceph21][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.2dUSPl
[2016-07-20 14:56:09,739][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-20 14:56:10,755][ceph21][DEBUG ] The operation has completed successfully.
[2016-07-20 14:56:10,755][ceph21][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-20 14:56:10,755][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-20 14:56:16,877][ceph21][INFO  ] checking OSD status...
[2016-07-20 14:56:16,877][ceph21][DEBUG ] find the location of an executable
[2016-07-20 14:56:16,880][ceph21][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-20 14:56:17,095][ceph_deploy.osd][DEBUG ] Host ceph21 is now ready for osd use.
[2016-07-20 14:56:17,779][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 14:56:17,780][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 14:56:17,796][ceph21][DEBUG ] detect machine type
[2016-07-20 14:56:17,799][ceph21][DEBUG ] find the location of an executable
[2016-07-20 14:56:17,802][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 14:56:17,810][ceph21][DEBUG ] find the location of an executable
[2016-07-20 14:56:17,811][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-20 14:56:17,811][ceph_deploy.osd][DEBUG ] Preparing host ceph21 disk /dev/vdc journal None activate True
[2016-07-20 14:56:17,812][ceph21][DEBUG ] find the location of an executable
[2016-07-20 14:56:17,814][ceph21][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-20 14:56:17,931][ceph21][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-20 14:56:17,931][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-20 14:56:17,931][ceph21][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-20 14:56:17,932][ceph21][WARNING] backup header from main header.
[2016-07-20 14:56:17,932][ceph21][WARNING] 
[2016-07-20 14:56:17,932][ceph21][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-20 14:56:17,932][ceph21][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-20 14:56:17,932][ceph21][WARNING] 
[2016-07-20 14:56:17,932][ceph21][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-20 14:56:17,932][ceph21][WARNING] 
[2016-07-20 14:56:18,948][ceph21][DEBUG ] ****************************************************************************
[2016-07-20 14:56:18,948][ceph21][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-20 14:56:18,948][ceph21][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-20 14:56:18,948][ceph21][DEBUG ] ****************************************************************************
[2016-07-20 14:56:18,948][ceph21][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-20 14:56:18,948][ceph21][DEBUG ] other utilities.
[2016-07-20 14:56:18,949][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-20 14:56:19,965][ceph21][DEBUG ] Creating new GPT entries.
[2016-07-20 14:56:19,965][ceph21][DEBUG ] The operation has completed successfully.
[2016-07-20 14:56:19,965][ceph21][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-20 14:56:19,965][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-20 14:56:19,965][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-20 14:56:19,980][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-20 14:56:19,996][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-20 14:56:20,003][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-20 14:56:20,035][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-20 14:56:20,038][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-20 14:56:20,054][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-20 14:56:20,069][ceph21][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-20 14:56:20,070][ceph21][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-20 14:56:20,070][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:16033b01-ca44-4ec1-8459-977b0c406d10 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-20 14:56:21,136][ceph21][DEBUG ] The operation has completed successfully.
[2016-07-20 14:56:21,136][ceph21][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-20 14:56:21,136][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-20 14:56:21,300][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-20 14:56:21,300][ceph21][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/16033b01-ca44-4ec1-8459-977b0c406d10
[2016-07-20 14:56:21,301][ceph21][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/16033b01-ca44-4ec1-8459-977b0c406d10
[2016-07-20 14:56:21,301][ceph21][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-20 14:56:21,301][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:a16e3775-d111-4aa5-a5d1-0acec8670614 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-20 14:56:22,367][ceph21][DEBUG ] The operation has completed successfully.
[2016-07-20 14:56:22,367][ceph21][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-20 14:56:22,367][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-20 14:56:22,631][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-20 14:56:22,635][ceph21][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-20 14:56:22,635][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-20 14:56:23,400][ceph21][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-20 14:56:23,400][ceph21][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-20 14:56:23,400][ceph21][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-20 14:56:23,401][ceph21][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-20 14:56:23,401][ceph21][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-20 14:56:23,401][ceph21][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-20 14:56:23,401][ceph21][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-20 14:56:23,401][ceph21][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-20 14:56:23,401][ceph21][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt.dPTgno with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-20 14:56:23,402][ceph21][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt.dPTgno
[2016-07-20 14:56:23,417][ceph21][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.dPTgno
[2016-07-20 14:56:23,417][ceph21][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.dPTgno/journal -> /dev/disk/by-partuuid/16033b01-ca44-4ec1-8459-977b0c406d10
[2016-07-20 14:56:23,449][ceph21][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.dPTgno
[2016-07-20 14:56:23,449][ceph21][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.dPTgno
[2016-07-20 14:56:23,465][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-20 14:56:24,531][ceph21][DEBUG ] The operation has completed successfully.
[2016-07-20 14:56:24,532][ceph21][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-20 14:56:24,532][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-20 14:56:30,703][ceph21][INFO  ] checking OSD status...
[2016-07-20 14:56:30,703][ceph21][DEBUG ] find the location of an executable
[2016-07-20 14:56:30,706][ceph21][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-20 14:56:30,922][ceph_deploy.osd][DEBUG ] Host ceph21 is now ready for osd use.
[2016-07-20 15:00:35,205][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:00:35,206][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy mon add ceph22
[2016-07-20 15:00:35,206][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:00:35,206][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:00:35,206][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:00:35,206][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-20 15:00:35,206][ceph_deploy.cli][INFO  ]  subcommand                    : add
[2016-07-20 15:00:35,206][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:00:35,206][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe080a56290>
[2016-07-20 15:00:35,207][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:00:35,207][ceph_deploy.cli][INFO  ]  mon                           : ['ceph22']
[2016-07-20 15:00:35,207][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7fe080a386e0>
[2016-07-20 15:00:35,207][ceph_deploy.cli][INFO  ]  address                       : None
[2016-07-20 15:00:35,207][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:00:35,207][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:00:35,208][ceph_deploy.mon][INFO  ] ensuring configuration of new mon host: ceph22
[2016-07-20 15:00:35,209][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph22
[2016-07-20 15:00:35,989][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-20 15:00:35,990][ceph22][DEBUG ] detect platform information from remote host
[2016-07-20 15:00:36,007][ceph22][DEBUG ] detect machine type
[2016-07-20 15:00:36,011][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:00:36,013][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:00:36,032][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:00:36,034][ceph_deploy.admin][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2016-07-20 15:00:36,034][ceph_deploy][ERROR ] GenericError: Failed to configure 1 admin hosts

[2016-07-20 15:02:45,288][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:02:45,289][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf mon add ceph22
[2016-07-20 15:02:45,289][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:02:45,289][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:02:45,289][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:02:45,289][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-20 15:02:45,289][ceph_deploy.cli][INFO  ]  subcommand                    : add
[2016-07-20 15:02:45,289][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:02:45,289][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f38eb2ec290>
[2016-07-20 15:02:45,290][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:02:45,290][ceph_deploy.cli][INFO  ]  mon                           : ['ceph22']
[2016-07-20 15:02:45,290][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f38eb2cd6e0>
[2016-07-20 15:02:45,290][ceph_deploy.cli][INFO  ]  address                       : None
[2016-07-20 15:02:45,290][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:02:45,290][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:02:45,291][ceph_deploy.mon][INFO  ] ensuring configuration of new mon host: ceph22
[2016-07-20 15:02:45,292][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph22
[2016-07-20 15:02:45,989][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-20 15:02:45,991][ceph22][DEBUG ] detect platform information from remote host
[2016-07-20 15:02:46,008][ceph22][DEBUG ] detect machine type
[2016-07-20 15:02:46,013][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:02:46,015][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:02:46,027][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:02:46,030][ceph_deploy.mon][DEBUG ] Adding mon to cluster ceph, host ceph22
[2016-07-20 15:02:46,030][ceph_deploy.mon][DEBUG ] using mon address by resolving host: 10.1.0.45
[2016-07-20 15:02:46,030][ceph_deploy.mon][DEBUG ] detecting platform for host ceph22 ...
[2016-07-20 15:02:46,710][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-20 15:02:46,711][ceph22][DEBUG ] detect platform information from remote host
[2016-07-20 15:02:46,727][ceph22][DEBUG ] detect machine type
[2016-07-20 15:02:46,731][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:02:46,733][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:02:46,742][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:02:46,743][ceph_deploy.mon][INFO  ] distro info: Ubuntu 14.04 trusty
[2016-07-20 15:02:46,743][ceph22][DEBUG ] determining if provided host has same hostname in remote
[2016-07-20 15:02:46,743][ceph22][DEBUG ] get remote short hostname
[2016-07-20 15:02:46,744][ceph22][DEBUG ] adding mon to ceph22
[2016-07-20 15:02:46,744][ceph22][DEBUG ] get remote short hostname
[2016-07-20 15:02:46,748][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:02:46,750][ceph22][DEBUG ] create the mon path if it does not exist
[2016-07-20 15:02:46,751][ceph22][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph22/done
[2016-07-20 15:02:46,752][ceph22][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph22/done
[2016-07-20 15:02:46,753][ceph22][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph22.mon.keyring
[2016-07-20 15:02:46,753][ceph22][DEBUG ] create the monitor keyring file
[2016-07-20 15:02:46,756][ceph22][INFO  ] Running command: ceph mon getmap -o /var/lib/ceph/tmp/ceph.ceph22.monmap
[2016-07-20 15:02:46,923][ceph22][WARNING] got monmap epoch 1
[2016-07-20 15:02:46,925][ceph22][INFO  ] Running command: ceph-mon --cluster ceph --mkfs -i ceph22 --monmap /var/lib/ceph/tmp/ceph.ceph22.monmap --keyring /var/lib/ceph/tmp/ceph-ceph22.mon.keyring
[2016-07-20 15:02:46,960][ceph22][DEBUG ] ceph-mon: set fsid to b0809e36-838b-4852-9d2a-6712452a3ce7
[2016-07-20 15:02:46,961][ceph22][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-ceph22 for mon.ceph22
[2016-07-20 15:02:46,961][ceph22][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph22.mon.keyring
[2016-07-20 15:02:46,962][ceph22][DEBUG ] create a done file to avoid re-doing the mon deployment
[2016-07-20 15:02:46,963][ceph22][DEBUG ] create the init path if it does not exist
[2016-07-20 15:02:46,966][ceph22][INFO  ] Running command: ceph-mon -i ceph22 --pid-file /var/run/ceph/mon.ceph22.pid --public-addr 10.1.0.45
[2016-07-20 15:02:49,037][ceph22][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph22.asok mon_status
[2016-07-20 15:02:49,102][ceph22][WARNING] ceph22 is not defined in `mon initial members`
[2016-07-20 15:02:49,103][ceph22][WARNING] monitor ceph22 does not exist in monmap
[2016-07-20 15:02:49,103][ceph22][WARNING] neither `public_addr` nor `public_network` keys are defined for monitors
[2016-07-20 15:02:49,103][ceph22][WARNING] monitors may not be able to form quorum
[2016-07-20 15:02:49,104][ceph22][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph22.asok mon_status
[2016-07-20 15:02:49,170][ceph22][DEBUG ] ********************************************************************************
[2016-07-20 15:02:49,170][ceph22][DEBUG ] status for monitor: mon.ceph22
[2016-07-20 15:02:49,170][ceph22][DEBUG ] {
[2016-07-20 15:02:49,170][ceph22][DEBUG ]   "election_epoch": 0, 
[2016-07-20 15:02:49,170][ceph22][DEBUG ]   "extra_probe_peers": [], 
[2016-07-20 15:02:49,170][ceph22][DEBUG ]   "monmap": {
[2016-07-20 15:02:49,171][ceph22][DEBUG ]     "created": "0.000000", 
[2016-07-20 15:02:49,171][ceph22][DEBUG ]     "epoch": 1, 
[2016-07-20 15:02:49,171][ceph22][DEBUG ]     "fsid": "b0809e36-838b-4852-9d2a-6712452a3ce7", 
[2016-07-20 15:02:49,171][ceph22][DEBUG ]     "modified": "0.000000", 
[2016-07-20 15:02:49,171][ceph22][DEBUG ]     "mons": [
[2016-07-20 15:02:49,171][ceph22][DEBUG ]       {
[2016-07-20 15:02:49,171][ceph22][DEBUG ]         "addr": "10.1.0.44:6789/0", 
[2016-07-20 15:02:49,171][ceph22][DEBUG ]         "name": "ceph21", 
[2016-07-20 15:02:49,171][ceph22][DEBUG ]         "rank": 0
[2016-07-20 15:02:49,172][ceph22][DEBUG ]       }
[2016-07-20 15:02:49,172][ceph22][DEBUG ]     ]
[2016-07-20 15:02:49,172][ceph22][DEBUG ]   }, 
[2016-07-20 15:02:49,172][ceph22][DEBUG ]   "name": "ceph22", 
[2016-07-20 15:02:49,172][ceph22][DEBUG ]   "outside_quorum": [], 
[2016-07-20 15:02:49,172][ceph22][DEBUG ]   "quorum": [], 
[2016-07-20 15:02:49,172][ceph22][DEBUG ]   "rank": -1, 
[2016-07-20 15:02:49,172][ceph22][DEBUG ]   "state": "probing", 
[2016-07-20 15:02:49,172][ceph22][DEBUG ]   "sync_provider": []
[2016-07-20 15:02:49,173][ceph22][DEBUG ] }
[2016-07-20 15:02:49,173][ceph22][DEBUG ] ********************************************************************************
[2016-07-20 15:02:49,173][ceph22][INFO  ] monitor: mon.ceph22 is currently at the state of probing
[2016-07-20 15:02:52,753][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:02:52,753][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf mon add ceph23
[2016-07-20 15:02:52,753][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:02:52,754][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:02:52,754][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:02:52,754][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-20 15:02:52,754][ceph_deploy.cli][INFO  ]  subcommand                    : add
[2016-07-20 15:02:52,754][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:02:52,754][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f72aab19290>
[2016-07-20 15:02:52,754][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:02:52,754][ceph_deploy.cli][INFO  ]  mon                           : ['ceph23']
[2016-07-20 15:02:52,754][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f72aaafa6e0>
[2016-07-20 15:02:52,755][ceph_deploy.cli][INFO  ]  address                       : None
[2016-07-20 15:02:52,755][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:02:52,755][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:02:52,757][ceph_deploy.mon][INFO  ] ensuring configuration of new mon host: ceph23
[2016-07-20 15:02:52,759][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph23
[2016-07-20 15:02:53,526][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-20 15:02:53,527][ceph23][DEBUG ] detect platform information from remote host
[2016-07-20 15:02:53,544][ceph23][DEBUG ] detect machine type
[2016-07-20 15:02:53,548][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:02:53,550][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:02:53,569][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:02:53,572][ceph_deploy.mon][DEBUG ] Adding mon to cluster ceph, host ceph23
[2016-07-20 15:02:53,573][ceph_deploy.mon][DEBUG ] using mon address by resolving host: 10.1.0.48
[2016-07-20 15:02:53,573][ceph_deploy.mon][DEBUG ] detecting platform for host ceph23 ...
[2016-07-20 15:02:54,270][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-20 15:02:54,271][ceph23][DEBUG ] detect platform information from remote host
[2016-07-20 15:02:54,288][ceph23][DEBUG ] detect machine type
[2016-07-20 15:02:54,292][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:02:54,294][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:02:54,303][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:02:54,304][ceph_deploy.mon][INFO  ] distro info: Ubuntu 14.04 trusty
[2016-07-20 15:02:54,304][ceph23][DEBUG ] determining if provided host has same hostname in remote
[2016-07-20 15:02:54,304][ceph23][DEBUG ] get remote short hostname
[2016-07-20 15:02:54,305][ceph23][DEBUG ] adding mon to ceph23
[2016-07-20 15:02:54,305][ceph23][DEBUG ] get remote short hostname
[2016-07-20 15:02:54,308][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:02:54,310][ceph23][DEBUG ] create the mon path if it does not exist
[2016-07-20 15:02:54,311][ceph23][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph23/done
[2016-07-20 15:02:54,311][ceph23][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph23/done
[2016-07-20 15:02:54,312][ceph23][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph23.mon.keyring
[2016-07-20 15:02:54,312][ceph23][DEBUG ] create the monitor keyring file
[2016-07-20 15:02:54,315][ceph23][INFO  ] Running command: ceph mon getmap -o /var/lib/ceph/tmp/ceph.ceph23.monmap
[2016-07-20 15:02:54,482][ceph23][WARNING] got monmap epoch 2
[2016-07-20 15:02:54,499][ceph23][INFO  ] Running command: ceph-mon --cluster ceph --mkfs -i ceph23 --monmap /var/lib/ceph/tmp/ceph.ceph23.monmap --keyring /var/lib/ceph/tmp/ceph-ceph23.mon.keyring
[2016-07-20 15:02:54,534][ceph23][DEBUG ] ceph-mon: set fsid to b0809e36-838b-4852-9d2a-6712452a3ce7
[2016-07-20 15:02:54,534][ceph23][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-ceph23 for mon.ceph23
[2016-07-20 15:02:54,536][ceph23][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph23.mon.keyring
[2016-07-20 15:02:54,536][ceph23][DEBUG ] create a done file to avoid re-doing the mon deployment
[2016-07-20 15:02:54,537][ceph23][DEBUG ] create the init path if it does not exist
[2016-07-20 15:02:54,539][ceph23][INFO  ] Running command: ceph-mon -i ceph23 --pid-file /var/run/ceph/mon.ceph23.pid --public-addr 10.1.0.48
[2016-07-20 15:02:56,611][ceph23][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph23.asok mon_status
[2016-07-20 15:02:56,676][ceph23][WARNING] ceph23 is not defined in `mon initial members`
[2016-07-20 15:02:56,677][ceph23][WARNING] monitor ceph23 does not exist in monmap
[2016-07-20 15:02:56,677][ceph23][WARNING] neither `public_addr` nor `public_network` keys are defined for monitors
[2016-07-20 15:02:56,677][ceph23][WARNING] monitors may not be able to form quorum
[2016-07-20 15:02:56,679][ceph23][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph23.asok mon_status
[2016-07-20 15:02:56,743][ceph23][DEBUG ] ********************************************************************************
[2016-07-20 15:02:56,744][ceph23][DEBUG ] status for monitor: mon.ceph23
[2016-07-20 15:02:56,744][ceph23][DEBUG ] {
[2016-07-20 15:02:56,744][ceph23][DEBUG ]   "election_epoch": 0, 
[2016-07-20 15:02:56,744][ceph23][DEBUG ]   "extra_probe_peers": [
[2016-07-20 15:02:56,744][ceph23][DEBUG ]     "10.1.0.45:6789/0"
[2016-07-20 15:02:56,745][ceph23][DEBUG ]   ], 
[2016-07-20 15:02:56,745][ceph23][DEBUG ]   "monmap": {
[2016-07-20 15:02:56,745][ceph23][DEBUG ]     "created": "0.000000", 
[2016-07-20 15:02:56,745][ceph23][DEBUG ]     "epoch": 2, 
[2016-07-20 15:02:56,745][ceph23][DEBUG ]     "fsid": "b0809e36-838b-4852-9d2a-6712452a3ce7", 
[2016-07-20 15:02:56,745][ceph23][DEBUG ]     "modified": "2016-07-20 15:02:47.947910", 
[2016-07-20 15:02:56,745][ceph23][DEBUG ]     "mons": [
[2016-07-20 15:02:56,745][ceph23][DEBUG ]       {
[2016-07-20 15:02:56,745][ceph23][DEBUG ]         "addr": "10.1.0.44:6789/0", 
[2016-07-20 15:02:56,746][ceph23][DEBUG ]         "name": "ceph21", 
[2016-07-20 15:02:56,746][ceph23][DEBUG ]         "rank": 0
[2016-07-20 15:02:56,746][ceph23][DEBUG ]       }, 
[2016-07-20 15:02:56,746][ceph23][DEBUG ]       {
[2016-07-20 15:02:56,746][ceph23][DEBUG ]         "addr": "10.1.0.45:6789/0", 
[2016-07-20 15:02:56,746][ceph23][DEBUG ]         "name": "ceph22", 
[2016-07-20 15:02:56,746][ceph23][DEBUG ]         "rank": 1
[2016-07-20 15:02:56,747][ceph23][DEBUG ]       }
[2016-07-20 15:02:56,747][ceph23][DEBUG ]     ]
[2016-07-20 15:02:56,747][ceph23][DEBUG ]   }, 
[2016-07-20 15:02:56,747][ceph23][DEBUG ]   "name": "ceph23", 
[2016-07-20 15:02:56,747][ceph23][DEBUG ]   "outside_quorum": [], 
[2016-07-20 15:02:56,747][ceph23][DEBUG ]   "quorum": [], 
[2016-07-20 15:02:56,747][ceph23][DEBUG ]   "rank": -1, 
[2016-07-20 15:02:56,747][ceph23][DEBUG ]   "state": "probing", 
[2016-07-20 15:02:56,748][ceph23][DEBUG ]   "sync_provider": []
[2016-07-20 15:02:56,748][ceph23][DEBUG ] }
[2016-07-20 15:02:56,748][ceph23][DEBUG ] ********************************************************************************
[2016-07-20 15:02:56,748][ceph23][INFO  ] monitor: mon.ceph23 is currently at the state of probing
[2016-07-20 15:07:06,872][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:07:06,872][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy new ceph21 ceph22 ceph23
[2016-07-20 15:07:06,873][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:07:06,873][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:07:06,873][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f3cf0ac8410>
[2016-07-20 15:07:06,873][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:07:06,873][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-20 15:07:06,873][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:07:06,873][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3cf022aef0>
[2016-07-20 15:07:06,874][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:07:06,874][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2016-07-20 15:07:06,874][ceph_deploy.cli][INFO  ]  mon                           : ['ceph21', 'ceph22', 'ceph23']
[2016-07-20 15:07:06,874][ceph_deploy.cli][INFO  ]  public_network                : None
[2016-07-20 15:07:06,874][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:07:06,874][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2016-07-20 15:07:06,874][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:07:06,874][ceph_deploy.cli][INFO  ]  fsid                          : None
[2016-07-20 15:07:06,874][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2016-07-20 15:07:06,875][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2016-07-20 15:07:06,901][ceph21][DEBUG ] connected to host: cephAdmin 
[2016-07-20 15:07:06,906][ceph21][INFO  ] Running command: ssh -CT -o BatchMode=yes ceph21
[2016-07-20 15:07:07,997][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 15:07:07,998][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 15:07:08,031][ceph21][DEBUG ] detect machine type
[2016-07-20 15:07:08,037][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:07:08,039][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:07:08,056][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:07:08,059][ceph21][INFO  ] Running command: /bin/ip link show
[2016-07-20 15:07:08,069][ceph21][INFO  ] Running command: /bin/ip addr show
[2016-07-20 15:07:08,079][ceph21][DEBUG ] IP addresses found: ['10.1.0.44']
[2016-07-20 15:07:08,079][ceph_deploy.new][DEBUG ] Resolving host ceph21
[2016-07-20 15:07:08,079][ceph_deploy.new][DEBUG ] Monitor ceph21 at 10.1.0.44
[2016-07-20 15:07:08,080][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2016-07-20 15:07:08,095][ceph22][DEBUG ] connected to host: cephAdmin 
[2016-07-20 15:07:08,099][ceph22][INFO  ] Running command: ssh -CT -o BatchMode=yes ceph22
[2016-07-20 15:07:09,096][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-20 15:07:09,098][ceph22][DEBUG ] detect platform information from remote host
[2016-07-20 15:07:09,114][ceph22][DEBUG ] detect machine type
[2016-07-20 15:07:09,118][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:07:09,121][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:07:09,129][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:07:09,132][ceph22][INFO  ] Running command: /bin/ip link show
[2016-07-20 15:07:09,141][ceph22][INFO  ] Running command: /bin/ip addr show
[2016-07-20 15:07:09,150][ceph22][DEBUG ] IP addresses found: ['10.1.0.45']
[2016-07-20 15:07:09,150][ceph_deploy.new][DEBUG ] Resolving host ceph22
[2016-07-20 15:07:09,150][ceph_deploy.new][DEBUG ] Monitor ceph22 at 10.1.0.45
[2016-07-20 15:07:09,150][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2016-07-20 15:07:09,165][ceph23][DEBUG ] connected to host: cephAdmin 
[2016-07-20 15:07:09,170][ceph23][INFO  ] Running command: ssh -CT -o BatchMode=yes ceph23
[2016-07-20 15:07:10,242][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-20 15:07:10,243][ceph23][DEBUG ] detect platform information from remote host
[2016-07-20 15:07:10,260][ceph23][DEBUG ] detect machine type
[2016-07-20 15:07:10,265][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:07:10,267][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:07:10,285][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:07:10,288][ceph23][INFO  ] Running command: /bin/ip link show
[2016-07-20 15:07:10,298][ceph23][INFO  ] Running command: /bin/ip addr show
[2016-07-20 15:07:10,307][ceph23][DEBUG ] IP addresses found: ['10.1.0.48']
[2016-07-20 15:07:10,307][ceph_deploy.new][DEBUG ] Resolving host ceph23
[2016-07-20 15:07:10,308][ceph_deploy.new][DEBUG ] Monitor ceph23 at 10.1.0.48
[2016-07-20 15:07:10,308][ceph_deploy.new][DEBUG ] Monitor initial members are ['ceph21', 'ceph22', 'ceph23']
[2016-07-20 15:07:10,308][ceph_deploy.new][DEBUG ] Monitor addrs are ['10.1.0.44', '10.1.0.45', '10.1.0.48']
[2016-07-20 15:07:10,308][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2016-07-20 15:07:10,309][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2016-07-20 15:07:10,309][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2016-07-20 15:07:10,442][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:07:10,443][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy mon create-initial
[2016-07-20 15:07:10,443][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:07:10,443][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:07:10,443][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:07:10,443][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-20 15:07:10,443][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2016-07-20 15:07:10,443][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:07:10,443][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6989c97290>
[2016-07-20 15:07:10,444][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:07:10,444][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f6989c786e0>
[2016-07-20 15:07:10,444][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:07:10,444][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:07:10,444][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2016-07-20 15:07:10,446][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts ceph21 ceph22 ceph23
[2016-07-20 15:07:10,446][ceph_deploy.mon][DEBUG ] detecting platform for host ceph21 ...
[2016-07-20 15:07:11,164][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 15:07:11,165][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 15:07:11,184][ceph21][DEBUG ] detect machine type
[2016-07-20 15:07:11,188][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:07:11,190][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:07:11,202][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:07:11,203][ceph_deploy.mon][INFO  ] distro info: Ubuntu 14.04 trusty
[2016-07-20 15:07:11,203][ceph21][DEBUG ] determining if provided host has same hostname in remote
[2016-07-20 15:07:11,204][ceph21][DEBUG ] get remote short hostname
[2016-07-20 15:07:11,204][ceph21][DEBUG ] deploying mon to ceph21
[2016-07-20 15:07:11,205][ceph21][DEBUG ] get remote short hostname
[2016-07-20 15:07:11,205][ceph21][DEBUG ] remote hostname: ceph21
[2016-07-20 15:07:11,208][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:07:11,210][ceph_deploy.mon][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2016-07-20 15:07:11,210][ceph_deploy.mon][DEBUG ] detecting platform for host ceph22 ...
[2016-07-20 15:07:11,907][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-20 15:07:11,908][ceph22][DEBUG ] detect platform information from remote host
[2016-07-20 15:07:11,928][ceph22][DEBUG ] detect machine type
[2016-07-20 15:07:11,933][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:07:11,936][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:07:11,944][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:07:11,945][ceph_deploy.mon][INFO  ] distro info: Ubuntu 14.04 trusty
[2016-07-20 15:07:11,945][ceph22][DEBUG ] determining if provided host has same hostname in remote
[2016-07-20 15:07:11,946][ceph22][DEBUG ] get remote short hostname
[2016-07-20 15:07:11,946][ceph22][DEBUG ] deploying mon to ceph22
[2016-07-20 15:07:11,947][ceph22][DEBUG ] get remote short hostname
[2016-07-20 15:07:11,947][ceph22][DEBUG ] remote hostname: ceph22
[2016-07-20 15:07:11,950][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:07:11,952][ceph_deploy.mon][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2016-07-20 15:07:11,952][ceph_deploy.mon][DEBUG ] detecting platform for host ceph23 ...
[2016-07-20 15:07:12,652][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-20 15:07:12,653][ceph23][DEBUG ] detect platform information from remote host
[2016-07-20 15:07:12,680][ceph23][DEBUG ] detect machine type
[2016-07-20 15:07:12,684][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:07:12,686][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:07:12,695][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:07:12,696][ceph_deploy.mon][INFO  ] distro info: Ubuntu 14.04 trusty
[2016-07-20 15:07:12,696][ceph23][DEBUG ] determining if provided host has same hostname in remote
[2016-07-20 15:07:12,696][ceph23][DEBUG ] get remote short hostname
[2016-07-20 15:07:12,696][ceph23][DEBUG ] deploying mon to ceph23
[2016-07-20 15:07:12,697][ceph23][DEBUG ] get remote short hostname
[2016-07-20 15:07:12,697][ceph23][DEBUG ] remote hostname: ceph23
[2016-07-20 15:07:12,699][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:07:12,701][ceph_deploy.mon][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2016-07-20 15:07:12,701][ceph_deploy][ERROR ] GenericError: Failed to create 3 monitors

[2016-07-20 15:07:12,807][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:07:12,807][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf osd create --zap-disk ceph21:/dev/vdb ceph21:/dev/vdc ceph22:/dev/vdb ceph22:/dev/vdc ceph23:/dev/vdb ceph23:/dev/vdc
[2016-07-20 15:07:12,807][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:07:12,807][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:07:12,807][ceph_deploy.cli][INFO  ]  disk                          : [('ceph21', '/dev/vdb', None), ('ceph21', '/dev/vdc', None), ('ceph22', '/dev/vdb', None), ('ceph22', '/dev/vdc', None), ('ceph23', '/dev/vdb', None), ('ceph23', '/dev/vdc', None)]
[2016-07-20 15:07:12,808][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2016-07-20 15:07:12,808][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:07:12,808][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2016-07-20 15:07:12,808][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-20 15:07:12,808][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-20 15:07:12,808][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2016-07-20 15:07:12,809][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:07:12,809][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f4542e041b8>
[2016-07-20 15:07:12,809][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:07:12,809][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2016-07-20 15:07:12,809][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f4542dd5578>
[2016-07-20 15:07:12,809][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:07:12,809][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:07:12,809][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2016-07-20 15:07:12,811][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks ceph21:/dev/vdb: ceph21:/dev/vdc: ceph22:/dev/vdb: ceph22:/dev/vdc: ceph23:/dev/vdb: ceph23:/dev/vdc:
[2016-07-20 15:07:12,811][ceph_deploy][ERROR ] RuntimeError: bootstrap-osd keyring not found; run 'gatherkeys'

[2016-07-20 15:07:12,910][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:07:12,911][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf admin ceph21 ceph22 ceph23
[2016-07-20 15:07:12,911][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:07:12,911][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:07:12,911][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:07:12,911][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-20 15:07:12,911][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:07:12,911][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ffaf22405a8>
[2016-07-20 15:07:12,912][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:07:12,912][ceph_deploy.cli][INFO  ]  client                        : ['ceph21', 'ceph22', 'ceph23']
[2016-07-20 15:07:12,912][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7ffaf2b627d0>
[2016-07-20 15:07:12,912][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:07:12,912][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:07:12,913][ceph_deploy][ERROR ] RuntimeError: ceph.client.admin.keyring not found

[2016-07-20 15:07:13,001][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:07:13,001][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf config push ceph21 ceph22 ceph23
[2016-07-20 15:07:13,001][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:07:13,001][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:07:13,002][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:07:13,002][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-20 15:07:13,002][ceph_deploy.cli][INFO  ]  subcommand                    : push
[2016-07-20 15:07:13,002][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:07:13,002][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6cb6be8518>
[2016-07-20 15:07:13,002][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:07:13,002][ceph_deploy.cli][INFO  ]  client                        : ['ceph21', 'ceph22', 'ceph23']
[2016-07-20 15:07:13,002][ceph_deploy.cli][INFO  ]  func                          : <function config at 0x7f6cb6c31938>
[2016-07-20 15:07:13,002][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:07:13,003][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:07:13,003][ceph_deploy.config][DEBUG ] Pushing config to ceph21
[2016-07-20 15:07:13,726][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 15:07:13,727][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 15:07:13,744][ceph21][DEBUG ] detect machine type
[2016-07-20 15:07:13,748][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:07:13,750][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:07:13,769][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:07:13,771][ceph_deploy.config][DEBUG ] Pushing config to ceph22
[2016-07-20 15:07:14,449][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-20 15:07:14,450][ceph22][DEBUG ] detect platform information from remote host
[2016-07-20 15:07:14,466][ceph22][DEBUG ] detect machine type
[2016-07-20 15:07:14,469][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:07:14,471][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:07:14,480][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:07:14,482][ceph_deploy.config][DEBUG ] Pushing config to ceph23
[2016-07-20 15:07:15,165][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-20 15:07:15,166][ceph23][DEBUG ] detect platform information from remote host
[2016-07-20 15:07:15,182][ceph23][DEBUG ] detect machine type
[2016-07-20 15:07:15,185][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:07:15,187][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:07:15,196][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:09:01,300][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:09:01,301][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph21
[2016-07-20 15:09:01,301][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:09:01,301][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:09:01,301][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:09:01,301][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-20 15:09:01,301][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:09:01,302][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbbeafccb00>
[2016-07-20 15:09:01,302][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:09:01,302][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-20 15:09:01,302][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fbbeb8e31b8>
[2016-07-20 15:09:01,302][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:09:01,302][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:09:01,302][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-20 15:09:01,302][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-20 15:09:01,302][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph21
[2016-07-20 15:09:01,303][ceph_deploy.install][DEBUG ] Detecting platform for host ceph21 ...
[2016-07-20 15:09:02,013][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 15:09:02,014][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 15:09:02,031][ceph21][DEBUG ] detect machine type
[2016-07-20 15:09:02,034][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:09:02,037][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:09:02,056][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-20 15:09:02,056][ceph21][INFO  ] Purging Ceph on ceph21
[2016-07-20 15:09:02,058][ceph21][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-20 15:09:02,575][ceph21][DEBUG ] Reading package lists...
[2016-07-20 15:09:02,889][ceph21][DEBUG ] Building dependency tree...
[2016-07-20 15:09:02,890][ceph21][DEBUG ] Reading state information...
[2016-07-20 15:09:03,154][ceph21][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-20 15:09:03,154][ceph21][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-20 15:09:03,154][ceph21][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-20 15:09:03,154][ceph21][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-20 15:09:03,154][ceph21][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-20 15:09:03,155][ceph21][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-20 15:09:03,155][ceph21][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libnspr4
[2016-07-20 15:09:03,155][ceph21][DEBUG ]   libnss3 libnss3-nssdb libxslt1.1 xmlstarlet
[2016-07-20 15:09:03,155][ceph21][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-20 15:09:03,162][ceph21][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 217 not upgraded.
[2016-07-20 15:09:03,258][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:09:03,259][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph21
[2016-07-20 15:09:03,259][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:09:03,259][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:09:03,259][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:09:03,259][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-20 15:09:03,259][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:09:03,259][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc1062031b8>
[2016-07-20 15:09:03,260][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:09:03,260][ceph_deploy.cli][INFO  ]  host                          : ['ceph21']
[2016-07-20 15:09:03,260][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7fc106b12230>
[2016-07-20 15:09:03,260][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:09:03,260][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:09:03,260][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph21
[2016-07-20 15:09:03,975][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 15:09:03,977][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 15:09:03,993][ceph21][DEBUG ] detect machine type
[2016-07-20 15:09:03,996][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:09:03,999][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:09:04,018][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:09:04,718][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 15:09:04,719][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 15:09:04,739][ceph21][DEBUG ] detect machine type
[2016-07-20 15:09:04,744][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:09:04,747][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:09:04,764][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-20 15:09:04,764][ceph21][INFO  ] purging data on ceph21
[2016-07-20 15:09:04,767][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-20 15:09:04,785][ceph21][WARNING] OSDs may still be mounted, trying to unmount them
[2016-07-20 15:09:04,787][ceph21][INFO  ] Running command: find /var/lib/ceph -mindepth 1 -maxdepth 2 -type d -exec umount {} ;
[2016-07-20 15:09:04,797][ceph21][WARNING] umount: /var/lib/ceph/osd: not mounted
[2016-07-20 15:09:04,863][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-20 15:09:04,875][ceph21][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-20 15:09:13,334][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:09:13,335][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph22
[2016-07-20 15:09:13,335][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:09:13,335][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:09:13,335][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:09:13,336][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-20 15:09:13,336][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:09:13,336][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7feade3ecb00>
[2016-07-20 15:09:13,336][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:09:13,336][ceph_deploy.cli][INFO  ]  host                          : ['ceph22']
[2016-07-20 15:09:13,336][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7feaded031b8>
[2016-07-20 15:09:13,336][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:09:13,336][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:09:13,336][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-20 15:09:13,336][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-20 15:09:13,336][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph22
[2016-07-20 15:09:13,336][ceph_deploy.install][DEBUG ] Detecting platform for host ceph22 ...
[2016-07-20 15:09:14,057][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-20 15:09:14,058][ceph22][DEBUG ] detect platform information from remote host
[2016-07-20 15:09:14,079][ceph22][DEBUG ] detect machine type
[2016-07-20 15:09:14,083][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:09:14,085][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:09:14,104][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-20 15:09:14,104][ceph22][INFO  ] Purging Ceph on ceph22
[2016-07-20 15:09:14,106][ceph22][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-20 15:09:14,523][ceph22][DEBUG ] Reading package lists...
[2016-07-20 15:09:14,837][ceph22][DEBUG ] Building dependency tree...
[2016-07-20 15:09:14,838][ceph22][DEBUG ] Reading state information...
[2016-07-20 15:09:15,102][ceph22][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-20 15:09:15,102][ceph22][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-20 15:09:15,102][ceph22][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-20 15:09:15,102][ceph22][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-20 15:09:15,103][ceph22][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-20 15:09:15,103][ceph22][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 218 not upgraded.
[2016-07-20 15:09:15,196][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:09:15,197][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph22
[2016-07-20 15:09:15,197][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:09:15,197][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:09:15,197][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:09:15,197][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-20 15:09:15,197][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:09:15,197][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ff003e7b1b8>
[2016-07-20 15:09:15,198][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:09:15,198][ceph_deploy.cli][INFO  ]  host                          : ['ceph22']
[2016-07-20 15:09:15,198][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7ff00478a230>
[2016-07-20 15:09:15,198][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:09:15,198][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:09:15,198][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph22
[2016-07-20 15:09:15,930][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-20 15:09:15,931][ceph22][DEBUG ] detect platform information from remote host
[2016-07-20 15:09:15,947][ceph22][DEBUG ] detect machine type
[2016-07-20 15:09:15,950][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:09:15,953][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:09:15,964][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:09:16,666][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-20 15:09:16,667][ceph22][DEBUG ] detect platform information from remote host
[2016-07-20 15:09:16,684][ceph22][DEBUG ] detect machine type
[2016-07-20 15:09:16,689][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:09:16,691][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:09:16,708][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-20 15:09:16,708][ceph22][INFO  ] purging data on ceph22
[2016-07-20 15:09:16,710][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-20 15:09:16,719][ceph22][WARNING] OSDs may still be mounted, trying to unmount them
[2016-07-20 15:09:16,720][ceph22][INFO  ] Running command: find /var/lib/ceph -mindepth 1 -maxdepth 2 -type d -exec umount {} ;
[2016-07-20 15:09:16,730][ceph22][WARNING] umount: /var/lib/ceph/osd: not mounted
[2016-07-20 15:09:16,796][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-20 15:09:16,808][ceph22][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-20 15:09:24,421][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:09:24,421][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purge ceph23
[2016-07-20 15:09:24,421][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:09:24,421][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:09:24,422][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:09:24,422][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-20 15:09:24,422][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:09:24,422][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb3a8545b00>
[2016-07-20 15:09:24,422][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:09:24,422][ceph_deploy.cli][INFO  ]  host                          : ['ceph23']
[2016-07-20 15:09:24,422][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fb3a8e5c1b8>
[2016-07-20 15:09:24,422][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:09:24,423][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:09:24,423][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2016-07-20 15:09:24,423][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2016-07-20 15:09:24,423][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts ceph23
[2016-07-20 15:09:24,423][ceph_deploy.install][DEBUG ] Detecting platform for host ceph23 ...
[2016-07-20 15:09:25,113][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-20 15:09:25,114][ceph23][DEBUG ] detect platform information from remote host
[2016-07-20 15:09:25,131][ceph23][DEBUG ] detect machine type
[2016-07-20 15:09:25,135][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:09:25,137][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:09:25,148][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-20 15:09:25,148][ceph23][INFO  ] Purging Ceph on ceph23
[2016-07-20 15:09:25,150][ceph23][INFO  ] Running command: env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2016-07-20 15:09:25,517][ceph23][DEBUG ] Reading package lists...
[2016-07-20 15:09:25,833][ceph23][DEBUG ] Building dependency tree...
[2016-07-20 15:09:25,834][ceph23][DEBUG ] Reading state information...
[2016-07-20 15:09:26,050][ceph23][DEBUG ] Package 'ceph' is not installed, so not removed
[2016-07-20 15:09:26,051][ceph23][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2016-07-20 15:09:26,051][ceph23][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2016-07-20 15:09:26,051][ceph23][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2016-07-20 15:09:26,051][ceph23][DEBUG ] Package 'radosgw' is not installed, so not removed
[2016-07-20 15:09:26,051][ceph23][DEBUG ] The following packages were automatically installed and are no longer required:
[2016-07-20 15:09:26,051][ceph23][DEBUG ]   btrfs-tools libboost-random1.54.0 libboost-regex1.54.0 liblzo2-2 libxslt1.1
[2016-07-20 15:09:26,052][ceph23][DEBUG ]   xmlstarlet
[2016-07-20 15:09:26,052][ceph23][DEBUG ] Use 'apt-get autoremove' to remove them.
[2016-07-20 15:09:26,115][ceph23][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 218 not upgraded.
[2016-07-20 15:09:26,211][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:09:26,211][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy purgedata ceph23
[2016-07-20 15:09:26,211][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:09:26,211][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:09:26,212][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:09:26,212][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-20 15:09:26,212][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:09:26,212][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7cd86ac1b8>
[2016-07-20 15:09:26,212][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:09:26,212][ceph_deploy.cli][INFO  ]  host                          : ['ceph23']
[2016-07-20 15:09:26,212][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f7cd8fbb230>
[2016-07-20 15:09:26,212][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:09:26,212][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:09:26,213][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts ceph23
[2016-07-20 15:09:26,942][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-20 15:09:26,944][ceph23][DEBUG ] detect platform information from remote host
[2016-07-20 15:09:26,960][ceph23][DEBUG ] detect machine type
[2016-07-20 15:09:26,964][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:09:26,967][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:09:26,986][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:09:27,670][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-20 15:09:27,670][ceph23][DEBUG ] detect platform information from remote host
[2016-07-20 15:09:27,687][ceph23][DEBUG ] detect machine type
[2016-07-20 15:09:27,690][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:09:27,693][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:09:27,701][ceph_deploy.install][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-20 15:09:27,702][ceph23][INFO  ] purging data on ceph23
[2016-07-20 15:09:27,703][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-20 15:09:27,712][ceph23][WARNING] OSDs may still be mounted, trying to unmount them
[2016-07-20 15:09:27,714][ceph23][INFO  ] Running command: find /var/lib/ceph -mindepth 1 -maxdepth 2 -type d -exec umount {} ;
[2016-07-20 15:09:27,733][ceph23][WARNING] umount: /var/lib/ceph/osd: not mounted
[2016-07-20 15:09:27,799][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /var/lib/ceph
[2016-07-20 15:09:27,811][ceph23][INFO  ] Running command: rm -rf --one-file-system -- /etc/ceph/
[2016-07-20 15:10:06,334][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:10:06,334][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy new ceph21 ceph22 ceph23
[2016-07-20 15:10:06,334][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:10:06,335][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:10:06,335][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f7a1f1c9410>
[2016-07-20 15:10:06,335][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:10:06,335][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-20 15:10:06,335][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:10:06,335][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7a1e92bef0>
[2016-07-20 15:10:06,335][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:10:06,335][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2016-07-20 15:10:06,335][ceph_deploy.cli][INFO  ]  mon                           : ['ceph21', 'ceph22', 'ceph23']
[2016-07-20 15:10:06,336][ceph_deploy.cli][INFO  ]  public_network                : None
[2016-07-20 15:10:06,336][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:10:06,336][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2016-07-20 15:10:06,336][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:10:06,336][ceph_deploy.cli][INFO  ]  fsid                          : None
[2016-07-20 15:10:06,336][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2016-07-20 15:10:06,336][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2016-07-20 15:10:06,364][ceph21][DEBUG ] connected to host: cephAdmin 
[2016-07-20 15:10:06,370][ceph21][INFO  ] Running command: ssh -CT -o BatchMode=yes ceph21
[2016-07-20 15:10:07,479][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 15:10:07,480][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 15:10:07,498][ceph21][DEBUG ] detect machine type
[2016-07-20 15:10:07,502][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:10:07,505][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:10:07,522][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:10:07,525][ceph21][INFO  ] Running command: /bin/ip link show
[2016-07-20 15:10:07,535][ceph21][INFO  ] Running command: /bin/ip addr show
[2016-07-20 15:10:07,544][ceph21][DEBUG ] IP addresses found: ['10.1.0.44']
[2016-07-20 15:10:07,544][ceph_deploy.new][DEBUG ] Resolving host ceph21
[2016-07-20 15:10:07,544][ceph_deploy.new][DEBUG ] Monitor ceph21 at 10.1.0.44
[2016-07-20 15:10:07,545][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2016-07-20 15:10:07,561][ceph22][DEBUG ] connected to host: cephAdmin 
[2016-07-20 15:10:07,565][ceph22][INFO  ] Running command: ssh -CT -o BatchMode=yes ceph22
[2016-07-20 15:10:08,605][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-20 15:10:08,606][ceph22][DEBUG ] detect platform information from remote host
[2016-07-20 15:10:08,621][ceph22][DEBUG ] detect machine type
[2016-07-20 15:10:08,624][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:10:08,626][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:10:08,635][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:10:08,637][ceph22][INFO  ] Running command: /bin/ip link show
[2016-07-20 15:10:08,646][ceph22][INFO  ] Running command: /bin/ip addr show
[2016-07-20 15:10:08,651][ceph22][DEBUG ] IP addresses found: ['10.1.0.45']
[2016-07-20 15:10:08,651][ceph_deploy.new][DEBUG ] Resolving host ceph22
[2016-07-20 15:10:08,651][ceph_deploy.new][DEBUG ] Monitor ceph22 at 10.1.0.45
[2016-07-20 15:10:08,651][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2016-07-20 15:10:08,666][ceph23][DEBUG ] connected to host: cephAdmin 
[2016-07-20 15:10:08,671][ceph23][INFO  ] Running command: ssh -CT -o BatchMode=yes ceph23
[2016-07-20 15:10:09,757][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-20 15:10:09,758][ceph23][DEBUG ] detect platform information from remote host
[2016-07-20 15:10:09,773][ceph23][DEBUG ] detect machine type
[2016-07-20 15:10:09,777][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:10:09,778][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:10:09,787][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:10:09,788][ceph23][INFO  ] Running command: /bin/ip link show
[2016-07-20 15:10:09,798][ceph23][INFO  ] Running command: /bin/ip addr show
[2016-07-20 15:10:09,806][ceph23][DEBUG ] IP addresses found: ['10.1.0.48']
[2016-07-20 15:10:09,807][ceph_deploy.new][DEBUG ] Resolving host ceph23
[2016-07-20 15:10:09,807][ceph_deploy.new][DEBUG ] Monitor ceph23 at 10.1.0.48
[2016-07-20 15:10:09,807][ceph_deploy.new][DEBUG ] Monitor initial members are ['ceph21', 'ceph22', 'ceph23']
[2016-07-20 15:10:09,807][ceph_deploy.new][DEBUG ] Monitor addrs are ['10.1.0.44', '10.1.0.45', '10.1.0.48']
[2016-07-20 15:10:09,807][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2016-07-20 15:10:09,807][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2016-07-20 15:10:09,807][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2016-07-20 15:10:09,904][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:10:09,904][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy mon create-initial
[2016-07-20 15:10:09,904][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:10:09,904][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:10:09,904][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:10:09,904][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2016-07-20 15:10:09,904][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2016-07-20 15:10:09,904][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:10:09,904][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7feb191de290>
[2016-07-20 15:10:09,905][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:10:09,905][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7feb191bf6e0>
[2016-07-20 15:10:09,905][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:10:09,905][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:10:09,905][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2016-07-20 15:10:09,907][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts ceph21 ceph22 ceph23
[2016-07-20 15:10:09,907][ceph_deploy.mon][DEBUG ] detecting platform for host ceph21 ...
[2016-07-20 15:10:10,626][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 15:10:10,627][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 15:10:10,644][ceph21][DEBUG ] detect machine type
[2016-07-20 15:10:10,648][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:10:10,651][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:10:10,664][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:10:10,665][ceph_deploy.mon][INFO  ] distro info: Ubuntu 14.04 trusty
[2016-07-20 15:10:10,665][ceph21][DEBUG ] determining if provided host has same hostname in remote
[2016-07-20 15:10:10,666][ceph21][DEBUG ] get remote short hostname
[2016-07-20 15:10:10,667][ceph21][DEBUG ] deploying mon to ceph21
[2016-07-20 15:10:10,667][ceph21][DEBUG ] get remote short hostname
[2016-07-20 15:10:10,668][ceph21][DEBUG ] remote hostname: ceph21
[2016-07-20 15:10:10,672][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:10:10,673][ceph21][DEBUG ] create the mon path if it does not exist
[2016-07-20 15:10:10,674][ceph21][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-20 15:10:10,675][ceph21][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph21/done
[2016-07-20 15:10:10,677][ceph21][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-20 15:10:10,677][ceph21][DEBUG ] create the monitor keyring file
[2016-07-20 15:10:10,679][ceph21][INFO  ] Running command: ceph-mon --cluster ceph --mkfs -i ceph21 --keyring /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-20 15:10:10,717][ceph21][DEBUG ] ceph-mon: mon.noname-a 10.1.0.44:6789/0 is local, renaming to mon.ceph21
[2016-07-20 15:10:10,717][ceph21][DEBUG ] ceph-mon: set fsid to f562ab3b-a332-4d9c-878e-ba0145af200e
[2016-07-20 15:10:10,718][ceph21][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-ceph21 for mon.ceph21
[2016-07-20 15:10:10,718][ceph21][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph21.mon.keyring
[2016-07-20 15:10:10,719][ceph21][DEBUG ] create a done file to avoid re-doing the mon deployment
[2016-07-20 15:10:10,720][ceph21][DEBUG ] create the init path if it does not exist
[2016-07-20 15:10:10,723][ceph21][INFO  ] Running command: initctl emit ceph-mon cluster=ceph id=ceph21
[2016-07-20 15:10:12,746][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-20 15:10:12,811][ceph21][DEBUG ] ********************************************************************************
[2016-07-20 15:10:12,811][ceph21][DEBUG ] status for monitor: mon.ceph21
[2016-07-20 15:10:12,812][ceph21][DEBUG ] {
[2016-07-20 15:10:12,812][ceph21][DEBUG ]   "election_epoch": 0, 
[2016-07-20 15:10:12,812][ceph21][DEBUG ]   "extra_probe_peers": [
[2016-07-20 15:10:12,812][ceph21][DEBUG ]     "10.1.0.45:6789/0", 
[2016-07-20 15:10:12,812][ceph21][DEBUG ]     "10.1.0.48:6789/0"
[2016-07-20 15:10:12,812][ceph21][DEBUG ]   ], 
[2016-07-20 15:10:12,812][ceph21][DEBUG ]   "monmap": {
[2016-07-20 15:10:12,813][ceph21][DEBUG ]     "created": "0.000000", 
[2016-07-20 15:10:12,813][ceph21][DEBUG ]     "epoch": 0, 
[2016-07-20 15:10:12,813][ceph21][DEBUG ]     "fsid": "f562ab3b-a332-4d9c-878e-ba0145af200e", 
[2016-07-20 15:10:12,813][ceph21][DEBUG ]     "modified": "0.000000", 
[2016-07-20 15:10:12,813][ceph21][DEBUG ]     "mons": [
[2016-07-20 15:10:12,813][ceph21][DEBUG ]       {
[2016-07-20 15:10:12,813][ceph21][DEBUG ]         "addr": "10.1.0.44:6789/0", 
[2016-07-20 15:10:12,813][ceph21][DEBUG ]         "name": "ceph21", 
[2016-07-20 15:10:12,813][ceph21][DEBUG ]         "rank": 0
[2016-07-20 15:10:12,814][ceph21][DEBUG ]       }, 
[2016-07-20 15:10:12,814][ceph21][DEBUG ]       {
[2016-07-20 15:10:12,814][ceph21][DEBUG ]         "addr": "0.0.0.0:0/1", 
[2016-07-20 15:10:12,814][ceph21][DEBUG ]         "name": "ceph22", 
[2016-07-20 15:10:12,814][ceph21][DEBUG ]         "rank": 1
[2016-07-20 15:10:12,814][ceph21][DEBUG ]       }, 
[2016-07-20 15:10:12,814][ceph21][DEBUG ]       {
[2016-07-20 15:10:12,814][ceph21][DEBUG ]         "addr": "0.0.0.0:0/2", 
[2016-07-20 15:10:12,814][ceph21][DEBUG ]         "name": "ceph23", 
[2016-07-20 15:10:12,815][ceph21][DEBUG ]         "rank": 2
[2016-07-20 15:10:12,815][ceph21][DEBUG ]       }
[2016-07-20 15:10:12,815][ceph21][DEBUG ]     ]
[2016-07-20 15:10:12,815][ceph21][DEBUG ]   }, 
[2016-07-20 15:10:12,815][ceph21][DEBUG ]   "name": "ceph21", 
[2016-07-20 15:10:12,815][ceph21][DEBUG ]   "outside_quorum": [
[2016-07-20 15:10:12,815][ceph21][DEBUG ]     "ceph21"
[2016-07-20 15:10:12,815][ceph21][DEBUG ]   ], 
[2016-07-20 15:10:12,815][ceph21][DEBUG ]   "quorum": [], 
[2016-07-20 15:10:12,816][ceph21][DEBUG ]   "rank": 0, 
[2016-07-20 15:10:12,816][ceph21][DEBUG ]   "state": "probing", 
[2016-07-20 15:10:12,816][ceph21][DEBUG ]   "sync_provider": []
[2016-07-20 15:10:12,816][ceph21][DEBUG ] }
[2016-07-20 15:10:12,816][ceph21][DEBUG ] ********************************************************************************
[2016-07-20 15:10:12,816][ceph21][INFO  ] monitor: mon.ceph21 is running
[2016-07-20 15:10:12,818][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-20 15:10:12,883][ceph_deploy.mon][DEBUG ] detecting platform for host ceph22 ...
[2016-07-20 15:10:13,581][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-20 15:10:13,583][ceph22][DEBUG ] detect platform information from remote host
[2016-07-20 15:10:13,598][ceph22][DEBUG ] detect machine type
[2016-07-20 15:10:13,602][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:10:13,604][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:10:13,613][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:10:13,614][ceph_deploy.mon][INFO  ] distro info: Ubuntu 14.04 trusty
[2016-07-20 15:10:13,615][ceph22][DEBUG ] determining if provided host has same hostname in remote
[2016-07-20 15:10:13,615][ceph22][DEBUG ] get remote short hostname
[2016-07-20 15:10:13,616][ceph22][DEBUG ] deploying mon to ceph22
[2016-07-20 15:10:13,616][ceph22][DEBUG ] get remote short hostname
[2016-07-20 15:10:13,617][ceph22][DEBUG ] remote hostname: ceph22
[2016-07-20 15:10:13,619][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:10:13,621][ceph22][DEBUG ] create the mon path if it does not exist
[2016-07-20 15:10:13,622][ceph22][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph22/done
[2016-07-20 15:10:13,623][ceph22][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph22/done
[2016-07-20 15:10:13,623][ceph22][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph22.mon.keyring
[2016-07-20 15:10:13,624][ceph22][DEBUG ] create the monitor keyring file
[2016-07-20 15:10:13,626][ceph22][INFO  ] Running command: ceph-mon --cluster ceph --mkfs -i ceph22 --keyring /var/lib/ceph/tmp/ceph-ceph22.mon.keyring
[2016-07-20 15:10:13,660][ceph22][DEBUG ] ceph-mon: mon.noname-b 10.1.0.45:6789/0 is local, renaming to mon.ceph22
[2016-07-20 15:10:13,660][ceph22][DEBUG ] ceph-mon: set fsid to f562ab3b-a332-4d9c-878e-ba0145af200e
[2016-07-20 15:10:13,660][ceph22][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-ceph22 for mon.ceph22
[2016-07-20 15:10:13,661][ceph22][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph22.mon.keyring
[2016-07-20 15:10:13,662][ceph22][DEBUG ] create a done file to avoid re-doing the mon deployment
[2016-07-20 15:10:13,663][ceph22][DEBUG ] create the init path if it does not exist
[2016-07-20 15:10:13,665][ceph22][INFO  ] Running command: initctl emit ceph-mon cluster=ceph id=ceph22
[2016-07-20 15:10:15,704][ceph22][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph22.asok mon_status
[2016-07-20 15:10:15,769][ceph22][DEBUG ] ********************************************************************************
[2016-07-20 15:10:15,770][ceph22][DEBUG ] status for monitor: mon.ceph22
[2016-07-20 15:10:15,770][ceph22][DEBUG ] {
[2016-07-20 15:10:15,770][ceph22][DEBUG ]   "election_epoch": 1, 
[2016-07-20 15:10:15,770][ceph22][DEBUG ]   "extra_probe_peers": [
[2016-07-20 15:10:15,770][ceph22][DEBUG ]     "10.1.0.44:6789/0", 
[2016-07-20 15:10:15,770][ceph22][DEBUG ]     "10.1.0.48:6789/0"
[2016-07-20 15:10:15,771][ceph22][DEBUG ]   ], 
[2016-07-20 15:10:15,771][ceph22][DEBUG ]   "monmap": {
[2016-07-20 15:10:15,771][ceph22][DEBUG ]     "created": "0.000000", 
[2016-07-20 15:10:15,771][ceph22][DEBUG ]     "epoch": 0, 
[2016-07-20 15:10:15,771][ceph22][DEBUG ]     "fsid": "f562ab3b-a332-4d9c-878e-ba0145af200e", 
[2016-07-20 15:10:15,771][ceph22][DEBUG ]     "modified": "0.000000", 
[2016-07-20 15:10:15,771][ceph22][DEBUG ]     "mons": [
[2016-07-20 15:10:15,771][ceph22][DEBUG ]       {
[2016-07-20 15:10:15,771][ceph22][DEBUG ]         "addr": "10.1.0.44:6789/0", 
[2016-07-20 15:10:15,772][ceph22][DEBUG ]         "name": "ceph21", 
[2016-07-20 15:10:15,772][ceph22][DEBUG ]         "rank": 0
[2016-07-20 15:10:15,772][ceph22][DEBUG ]       }, 
[2016-07-20 15:10:15,772][ceph22][DEBUG ]       {
[2016-07-20 15:10:15,772][ceph22][DEBUG ]         "addr": "10.1.0.45:6789/0", 
[2016-07-20 15:10:15,772][ceph22][DEBUG ]         "name": "ceph22", 
[2016-07-20 15:10:15,772][ceph22][DEBUG ]         "rank": 1
[2016-07-20 15:10:15,772][ceph22][DEBUG ]       }, 
[2016-07-20 15:10:15,773][ceph22][DEBUG ]       {
[2016-07-20 15:10:15,773][ceph22][DEBUG ]         "addr": "0.0.0.0:0/2", 
[2016-07-20 15:10:15,773][ceph22][DEBUG ]         "name": "ceph23", 
[2016-07-20 15:10:15,773][ceph22][DEBUG ]         "rank": 2
[2016-07-20 15:10:15,773][ceph22][DEBUG ]       }
[2016-07-20 15:10:15,773][ceph22][DEBUG ]     ]
[2016-07-20 15:10:15,773][ceph22][DEBUG ]   }, 
[2016-07-20 15:10:15,773][ceph22][DEBUG ]   "name": "ceph22", 
[2016-07-20 15:10:15,773][ceph22][DEBUG ]   "outside_quorum": [], 
[2016-07-20 15:10:15,774][ceph22][DEBUG ]   "quorum": [], 
[2016-07-20 15:10:15,774][ceph22][DEBUG ]   "rank": 1, 
[2016-07-20 15:10:15,774][ceph22][DEBUG ]   "state": "electing", 
[2016-07-20 15:10:15,774][ceph22][DEBUG ]   "sync_provider": []
[2016-07-20 15:10:15,774][ceph22][DEBUG ] }
[2016-07-20 15:10:15,774][ceph22][DEBUG ] ********************************************************************************
[2016-07-20 15:10:15,774][ceph22][INFO  ] monitor: mon.ceph22 is running
[2016-07-20 15:10:15,776][ceph22][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph22.asok mon_status
[2016-07-20 15:10:15,841][ceph_deploy.mon][DEBUG ] detecting platform for host ceph23 ...
[2016-07-20 15:10:16,496][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-20 15:10:16,497][ceph23][DEBUG ] detect platform information from remote host
[2016-07-20 15:10:16,513][ceph23][DEBUG ] detect machine type
[2016-07-20 15:10:16,517][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:10:16,519][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:10:16,527][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:10:16,528][ceph_deploy.mon][INFO  ] distro info: Ubuntu 14.04 trusty
[2016-07-20 15:10:16,529][ceph23][DEBUG ] determining if provided host has same hostname in remote
[2016-07-20 15:10:16,529][ceph23][DEBUG ] get remote short hostname
[2016-07-20 15:10:16,529][ceph23][DEBUG ] deploying mon to ceph23
[2016-07-20 15:10:16,530][ceph23][DEBUG ] get remote short hostname
[2016-07-20 15:10:16,530][ceph23][DEBUG ] remote hostname: ceph23
[2016-07-20 15:10:16,533][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:10:16,534][ceph23][DEBUG ] create the mon path if it does not exist
[2016-07-20 15:10:16,535][ceph23][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph23/done
[2016-07-20 15:10:16,536][ceph23][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph23/done
[2016-07-20 15:10:16,536][ceph23][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph23.mon.keyring
[2016-07-20 15:10:16,536][ceph23][DEBUG ] create the monitor keyring file
[2016-07-20 15:10:16,538][ceph23][INFO  ] Running command: ceph-mon --cluster ceph --mkfs -i ceph23 --keyring /var/lib/ceph/tmp/ceph-ceph23.mon.keyring
[2016-07-20 15:10:16,574][ceph23][DEBUG ] ceph-mon: mon.noname-c 10.1.0.48:6789/0 is local, renaming to mon.ceph23
[2016-07-20 15:10:16,575][ceph23][DEBUG ] ceph-mon: set fsid to f562ab3b-a332-4d9c-878e-ba0145af200e
[2016-07-20 15:10:16,575][ceph23][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-ceph23 for mon.ceph23
[2016-07-20 15:10:16,575][ceph23][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph23.mon.keyring
[2016-07-20 15:10:16,576][ceph23][DEBUG ] create a done file to avoid re-doing the mon deployment
[2016-07-20 15:10:16,577][ceph23][DEBUG ] create the init path if it does not exist
[2016-07-20 15:10:16,579][ceph23][INFO  ] Running command: initctl emit ceph-mon cluster=ceph id=ceph23
[2016-07-20 15:10:18,601][ceph23][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph23.asok mon_status
[2016-07-20 15:10:18,666][ceph23][DEBUG ] ********************************************************************************
[2016-07-20 15:10:18,667][ceph23][DEBUG ] status for monitor: mon.ceph23
[2016-07-20 15:10:18,667][ceph23][DEBUG ] {
[2016-07-20 15:10:18,667][ceph23][DEBUG ]   "election_epoch": 1, 
[2016-07-20 15:10:18,667][ceph23][DEBUG ]   "extra_probe_peers": [
[2016-07-20 15:10:18,667][ceph23][DEBUG ]     "10.1.0.44:6789/0", 
[2016-07-20 15:10:18,668][ceph23][DEBUG ]     "10.1.0.45:6789/0"
[2016-07-20 15:10:18,668][ceph23][DEBUG ]   ], 
[2016-07-20 15:10:18,668][ceph23][DEBUG ]   "monmap": {
[2016-07-20 15:10:18,668][ceph23][DEBUG ]     "created": "0.000000", 
[2016-07-20 15:10:18,668][ceph23][DEBUG ]     "epoch": 0, 
[2016-07-20 15:10:18,668][ceph23][DEBUG ]     "fsid": "f562ab3b-a332-4d9c-878e-ba0145af200e", 
[2016-07-20 15:10:18,668][ceph23][DEBUG ]     "modified": "0.000000", 
[2016-07-20 15:10:18,669][ceph23][DEBUG ]     "mons": [
[2016-07-20 15:10:18,669][ceph23][DEBUG ]       {
[2016-07-20 15:10:18,669][ceph23][DEBUG ]         "addr": "10.1.0.44:6789/0", 
[2016-07-20 15:10:18,669][ceph23][DEBUG ]         "name": "ceph21", 
[2016-07-20 15:10:18,669][ceph23][DEBUG ]         "rank": 0
[2016-07-20 15:10:18,669][ceph23][DEBUG ]       }, 
[2016-07-20 15:10:18,669][ceph23][DEBUG ]       {
[2016-07-20 15:10:18,669][ceph23][DEBUG ]         "addr": "10.1.0.45:6789/0", 
[2016-07-20 15:10:18,670][ceph23][DEBUG ]         "name": "ceph22", 
[2016-07-20 15:10:18,670][ceph23][DEBUG ]         "rank": 1
[2016-07-20 15:10:18,670][ceph23][DEBUG ]       }, 
[2016-07-20 15:10:18,670][ceph23][DEBUG ]       {
[2016-07-20 15:10:18,670][ceph23][DEBUG ]         "addr": "10.1.0.48:6789/0", 
[2016-07-20 15:10:18,670][ceph23][DEBUG ]         "name": "ceph23", 
[2016-07-20 15:10:18,670][ceph23][DEBUG ]         "rank": 2
[2016-07-20 15:10:18,671][ceph23][DEBUG ]       }
[2016-07-20 15:10:18,671][ceph23][DEBUG ]     ]
[2016-07-20 15:10:18,671][ceph23][DEBUG ]   }, 
[2016-07-20 15:10:18,671][ceph23][DEBUG ]   "name": "ceph23", 
[2016-07-20 15:10:18,671][ceph23][DEBUG ]   "outside_quorum": [], 
[2016-07-20 15:10:18,671][ceph23][DEBUG ]   "quorum": [], 
[2016-07-20 15:10:18,671][ceph23][DEBUG ]   "rank": 2, 
[2016-07-20 15:10:18,671][ceph23][DEBUG ]   "state": "electing", 
[2016-07-20 15:10:18,671][ceph23][DEBUG ]   "sync_provider": []
[2016-07-20 15:10:18,672][ceph23][DEBUG ] }
[2016-07-20 15:10:18,672][ceph23][DEBUG ] ********************************************************************************
[2016-07-20 15:10:18,672][ceph23][INFO  ] monitor: mon.ceph23 is running
[2016-07-20 15:10:18,674][ceph23][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph23.asok mon_status
[2016-07-20 15:10:18,739][ceph_deploy.mon][INFO  ] processing monitor mon.ceph21
[2016-07-20 15:10:19,417][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 15:10:19,418][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 15:10:19,434][ceph21][DEBUG ] detect machine type
[2016-07-20 15:10:19,438][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:10:19,441][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:10:19,451][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:10:19,453][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-20 15:10:19,518][ceph_deploy.mon][WARNING] mon.ceph21 monitor is not yet in quorum, tries left: 5
[2016-07-20 15:10:19,518][ceph_deploy.mon][WARNING] waiting 5 seconds before retrying
[2016-07-20 15:10:24,526][ceph21][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph21.asok mon_status
[2016-07-20 15:10:24,591][ceph_deploy.mon][INFO  ] mon.ceph21 monitor has reached quorum!
[2016-07-20 15:10:24,591][ceph_deploy.mon][INFO  ] processing monitor mon.ceph22
[2016-07-20 15:10:25,274][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-20 15:10:25,276][ceph22][DEBUG ] detect platform information from remote host
[2016-07-20 15:10:25,294][ceph22][DEBUG ] detect machine type
[2016-07-20 15:10:25,298][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:10:25,302][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:10:25,319][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:10:25,322][ceph22][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph22.asok mon_status
[2016-07-20 15:10:25,387][ceph_deploy.mon][INFO  ] mon.ceph22 monitor has reached quorum!
[2016-07-20 15:10:25,387][ceph_deploy.mon][INFO  ] processing monitor mon.ceph23
[2016-07-20 15:10:26,073][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-20 15:10:26,074][ceph23][DEBUG ] detect platform information from remote host
[2016-07-20 15:10:26,089][ceph23][DEBUG ] detect machine type
[2016-07-20 15:10:26,093][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:10:26,095][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:10:26,112][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:10:26,114][ceph23][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph23.asok mon_status
[2016-07-20 15:10:26,179][ceph_deploy.mon][INFO  ] mon.ceph23 monitor has reached quorum!
[2016-07-20 15:10:26,179][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2016-07-20 15:10:26,179][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2016-07-20 15:10:26,180][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /etc/ceph/ceph.client.admin.keyring
[2016-07-20 15:10:26,883][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 15:10:26,883][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 15:10:26,902][ceph21][DEBUG ] detect machine type
[2016-07-20 15:10:26,906][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:10:26,908][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:10:26,926][ceph21][DEBUG ] fetch remote file
[2016-07-20 15:10:26,927][ceph_deploy.gatherkeys][DEBUG ] Got ceph.client.admin.keyring key from ceph21.
[2016-07-20 15:10:26,928][ceph_deploy.gatherkeys][DEBUG ] Have ceph.mon.keyring
[2016-07-20 15:10:26,928][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-osd/ceph.keyring
[2016-07-20 15:10:27,616][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 15:10:27,618][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 15:10:27,635][ceph21][DEBUG ] detect machine type
[2016-07-20 15:10:27,639][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:10:27,642][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:10:27,651][ceph21][DEBUG ] fetch remote file
[2016-07-20 15:10:27,652][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-osd.keyring key from ceph21.
[2016-07-20 15:10:27,653][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-mds/ceph.keyring
[2016-07-20 15:10:28,356][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 15:10:28,357][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 15:10:28,380][ceph21][DEBUG ] detect machine type
[2016-07-20 15:10:28,384][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:10:28,386][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:10:28,403][ceph21][DEBUG ] fetch remote file
[2016-07-20 15:10:28,405][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-mds.keyring key from ceph21.
[2016-07-20 15:10:28,405][ceph_deploy.gatherkeys][DEBUG ] Checking ceph21 for /var/lib/ceph/bootstrap-rgw/ceph.keyring
[2016-07-20 15:10:29,212][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 15:10:29,213][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 15:10:29,230][ceph21][DEBUG ] detect machine type
[2016-07-20 15:10:29,234][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:10:29,237][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:10:29,246][ceph21][DEBUG ] fetch remote file
[2016-07-20 15:10:29,247][ceph_deploy.gatherkeys][DEBUG ] Got ceph.bootstrap-rgw.keyring key from ceph21.
[2016-07-20 15:10:29,383][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:10:29,384][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf osd create --zap-disk ceph21:/dev/vdb ceph21:/dev/vdc ceph22:/dev/vdb ceph22:/dev/vdc ceph23:/dev/vdb ceph23:/dev/vdc
[2016-07-20 15:10:29,384][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:10:29,384][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:10:29,384][ceph_deploy.cli][INFO  ]  disk                          : [('ceph21', '/dev/vdb', None), ('ceph21', '/dev/vdc', None), ('ceph22', '/dev/vdb', None), ('ceph22', '/dev/vdc', None), ('ceph23', '/dev/vdb', None), ('ceph23', '/dev/vdc', None)]
[2016-07-20 15:10:29,384][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2016-07-20 15:10:29,385][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:10:29,385][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2016-07-20 15:10:29,385][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-20 15:10:29,385][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-20 15:10:29,385][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2016-07-20 15:10:29,386][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:10:29,386][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbade51d1b8>
[2016-07-20 15:10:29,386][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:10:29,386][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2016-07-20 15:10:29,386][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fbade4ee578>
[2016-07-20 15:10:29,386][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:10:29,387][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:10:29,387][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2016-07-20 15:10:29,389][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks ceph21:/dev/vdb: ceph21:/dev/vdc: ceph22:/dev/vdb: ceph22:/dev/vdc: ceph23:/dev/vdb: ceph23:/dev/vdc:
[2016-07-20 15:10:30,118][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 15:10:30,120][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 15:10:30,137][ceph21][DEBUG ] detect machine type
[2016-07-20 15:10:30,141][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:10:30,145][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:10:30,164][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:10:30,165][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-20 15:10:30,165][ceph_deploy.osd][DEBUG ] Deploying osd to ceph21
[2016-07-20 15:10:30,166][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:10:30,168][ceph_deploy.osd][DEBUG ] Preparing host ceph21 disk /dev/vdb journal None activate True
[2016-07-20 15:10:30,168][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:10:30,171][ceph21][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-20 15:10:30,240][ceph21][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-20 15:10:30,240][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-20 15:10:30,240][ceph21][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-20 15:10:30,241][ceph21][WARNING] backup header from main header.
[2016-07-20 15:10:30,241][ceph21][WARNING] 
[2016-07-20 15:10:30,241][ceph21][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-20 15:10:30,241][ceph21][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-20 15:10:30,241][ceph21][WARNING] 
[2016-07-20 15:10:30,242][ceph21][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-20 15:10:30,242][ceph21][WARNING] 
[2016-07-20 15:10:31,308][ceph21][DEBUG ] ****************************************************************************
[2016-07-20 15:10:31,308][ceph21][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-20 15:10:31,308][ceph21][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-20 15:10:31,309][ceph21][DEBUG ] ****************************************************************************
[2016-07-20 15:10:31,309][ceph21][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-20 15:10:31,309][ceph21][DEBUG ] other utilities.
[2016-07-20 15:10:31,309][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-20 15:10:32,325][ceph21][DEBUG ] Creating new GPT entries.
[2016-07-20 15:10:32,326][ceph21][DEBUG ] The operation has completed successfully.
[2016-07-20 15:10:32,326][ceph21][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-20 15:10:32,326][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-20 15:10:32,326][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-20 15:10:32,326][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-20 15:10:32,342][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-20 15:10:32,357][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-20 15:10:32,373][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-20 15:10:32,389][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-20 15:10:32,389][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-20 15:10:32,405][ceph21][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-20 15:10:32,405][ceph21][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-20 15:10:32,405][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:30b7e6c9-bbad-45ee-970d-286b15f60298 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-20 15:10:33,422][ceph21][DEBUG ] The operation has completed successfully.
[2016-07-20 15:10:33,422][ceph21][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-20 15:10:33,422][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-20 15:10:33,586][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-20 15:10:33,650][ceph21][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/30b7e6c9-bbad-45ee-970d-286b15f60298
[2016-07-20 15:10:33,650][ceph21][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/30b7e6c9-bbad-45ee-970d-286b15f60298
[2016-07-20 15:10:33,651][ceph21][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-20 15:10:33,651][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:a694cddc-6643-4241-96f8-2f17d10480f4 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-20 15:10:34,667][ceph21][DEBUG ] The operation has completed successfully.
[2016-07-20 15:10:34,668][ceph21][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-20 15:10:34,668][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-20 15:10:34,982][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-20 15:10:34,983][ceph21][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-20 15:10:34,983][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-20 15:10:35,748][ceph21][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-20 15:10:35,749][ceph21][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-20 15:10:35,749][ceph21][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-20 15:10:35,749][ceph21][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-20 15:10:35,750][ceph21][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-20 15:10:35,750][ceph21][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-20 15:10:35,750][ceph21][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-20 15:10:35,750][ceph21][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-20 15:10:35,750][ceph21][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.V3oa1i with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-20 15:10:35,751][ceph21][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.V3oa1i
[2016-07-20 15:10:35,751][ceph21][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.V3oa1i
[2016-07-20 15:10:35,751][ceph21][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.V3oa1i/journal -> /dev/disk/by-partuuid/30b7e6c9-bbad-45ee-970d-286b15f60298
[2016-07-20 15:10:35,751][ceph21][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.V3oa1i
[2016-07-20 15:10:35,751][ceph21][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.V3oa1i
[2016-07-20 15:10:35,815][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-20 15:10:36,831][ceph21][DEBUG ] The operation has completed successfully.
[2016-07-20 15:10:36,832][ceph21][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-20 15:10:36,832][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-20 15:10:42,954][ceph21][INFO  ] checking OSD status...
[2016-07-20 15:10:42,954][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:10:42,958][ceph21][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-20 15:10:43,173][ceph_deploy.osd][DEBUG ] Host ceph21 is now ready for osd use.
[2016-07-20 15:10:43,880][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 15:10:43,881][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 15:10:43,897][ceph21][DEBUG ] detect machine type
[2016-07-20 15:10:43,901][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:10:43,904][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:10:43,913][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:10:43,914][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-20 15:10:43,914][ceph_deploy.osd][DEBUG ] Preparing host ceph21 disk /dev/vdc journal None activate True
[2016-07-20 15:10:43,914][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:10:43,916][ceph21][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-20 15:10:43,985][ceph21][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-20 15:10:43,985][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-20 15:10:43,985][ceph21][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-20 15:10:43,985][ceph21][WARNING] backup header from main header.
[2016-07-20 15:10:43,986][ceph21][WARNING] 
[2016-07-20 15:10:43,986][ceph21][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-20 15:10:43,986][ceph21][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-20 15:10:43,987][ceph21][WARNING] 
[2016-07-20 15:10:43,987][ceph21][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-20 15:10:43,987][ceph21][WARNING] 
[2016-07-20 15:10:45,004][ceph21][DEBUG ] ****************************************************************************
[2016-07-20 15:10:45,004][ceph21][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-20 15:10:45,005][ceph21][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-20 15:10:45,005][ceph21][DEBUG ] ****************************************************************************
[2016-07-20 15:10:45,005][ceph21][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-20 15:10:45,005][ceph21][DEBUG ] other utilities.
[2016-07-20 15:10:45,007][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-20 15:10:46,073][ceph21][DEBUG ] Creating new GPT entries.
[2016-07-20 15:10:46,073][ceph21][DEBUG ] The operation has completed successfully.
[2016-07-20 15:10:46,074][ceph21][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-20 15:10:46,074][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-20 15:10:46,074][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-20 15:10:46,074][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-20 15:10:46,074][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-20 15:10:46,082][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-20 15:10:46,097][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-20 15:10:46,113][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-20 15:10:46,121][ceph21][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-20 15:10:46,137][ceph21][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-20 15:10:46,137][ceph21][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-20 15:10:46,137][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:6e240c6f-c8c8-4f59-91b4-a02a5a641c80 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-20 15:10:47,154][ceph21][DEBUG ] The operation has completed successfully.
[2016-07-20 15:10:47,154][ceph21][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-20 15:10:47,154][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-20 15:10:47,318][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-20 15:10:47,382][ceph21][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/6e240c6f-c8c8-4f59-91b4-a02a5a641c80
[2016-07-20 15:10:47,383][ceph21][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/6e240c6f-c8c8-4f59-91b4-a02a5a641c80
[2016-07-20 15:10:47,383][ceph21][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-20 15:10:47,383][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:3324ccd4-b7f6-4836-b6f7-120530efc332 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-20 15:10:48,399][ceph21][DEBUG ] The operation has completed successfully.
[2016-07-20 15:10:48,400][ceph21][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-20 15:10:48,400][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-20 15:10:48,664][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-20 15:10:48,696][ceph21][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-20 15:10:48,696][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-20 15:10:49,462][ceph21][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-20 15:10:49,463][ceph21][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-20 15:10:49,463][ceph21][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-20 15:10:49,463][ceph21][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-20 15:10:49,463][ceph21][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-20 15:10:49,463][ceph21][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-20 15:10:49,463][ceph21][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-20 15:10:49,463][ceph21][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-20 15:10:49,464][ceph21][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt.kg1Mj1 with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-20 15:10:49,464][ceph21][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt.kg1Mj1
[2016-07-20 15:10:49,464][ceph21][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.kg1Mj1
[2016-07-20 15:10:49,464][ceph21][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.kg1Mj1/journal -> /dev/disk/by-partuuid/6e240c6f-c8c8-4f59-91b4-a02a5a641c80
[2016-07-20 15:10:49,468][ceph21][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.kg1Mj1
[2016-07-20 15:10:49,468][ceph21][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.kg1Mj1
[2016-07-20 15:10:49,499][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-20 15:10:50,566][ceph21][DEBUG ] The operation has completed successfully.
[2016-07-20 15:10:50,567][ceph21][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-20 15:10:50,567][ceph21][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-20 15:10:56,784][ceph21][INFO  ] checking OSD status...
[2016-07-20 15:10:56,784][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:10:56,787][ceph21][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-20 15:10:57,002][ceph_deploy.osd][DEBUG ] Host ceph21 is now ready for osd use.
[2016-07-20 15:10:57,702][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-20 15:10:57,703][ceph22][DEBUG ] detect platform information from remote host
[2016-07-20 15:10:57,720][ceph22][DEBUG ] detect machine type
[2016-07-20 15:10:57,724][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:10:57,726][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:10:57,735][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:10:57,736][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-20 15:10:57,736][ceph_deploy.osd][DEBUG ] Deploying osd to ceph22
[2016-07-20 15:10:57,737][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:10:57,740][ceph_deploy.osd][DEBUG ] Preparing host ceph22 disk /dev/vdb journal None activate True
[2016-07-20 15:10:57,740][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:10:57,742][ceph22][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-20 15:10:57,809][ceph22][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-20 15:10:57,810][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-20 15:10:57,810][ceph22][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-20 15:10:57,810][ceph22][WARNING] backup header from main header.
[2016-07-20 15:10:57,810][ceph22][WARNING] 
[2016-07-20 15:10:57,810][ceph22][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-20 15:10:57,811][ceph22][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-20 15:10:57,811][ceph22][WARNING] 
[2016-07-20 15:10:57,811][ceph22][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-20 15:10:57,811][ceph22][WARNING] 
[2016-07-20 15:10:58,827][ceph22][DEBUG ] ****************************************************************************
[2016-07-20 15:10:58,827][ceph22][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-20 15:10:58,827][ceph22][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-20 15:10:58,827][ceph22][DEBUG ] ****************************************************************************
[2016-07-20 15:10:58,827][ceph22][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-20 15:10:58,828][ceph22][DEBUG ] other utilities.
[2016-07-20 15:10:58,828][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-20 15:10:59,843][ceph22][DEBUG ] Creating new GPT entries.
[2016-07-20 15:10:59,844][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-20 15:10:59,844][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-20 15:10:59,844][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-20 15:10:59,876][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-20 15:10:59,879][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-20 15:10:59,895][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-20 15:10:59,910][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-20 15:10:59,926][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-20 15:10:59,933][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-20 15:10:59,949][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-20 15:10:59,957][ceph22][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-20 15:10:59,957][ceph22][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-20 15:10:59,957][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:abd80256-b7bd-49de-b6f4-50ad37f28fdd --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-20 15:11:01,023][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-20 15:11:01,023][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-20 15:11:01,024][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-20 15:11:01,137][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-20 15:11:01,201][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/abd80256-b7bd-49de-b6f4-50ad37f28fdd
[2016-07-20 15:11:01,202][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/abd80256-b7bd-49de-b6f4-50ad37f28fdd
[2016-07-20 15:11:01,202][ceph22][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-20 15:11:01,202][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:edc59c5f-ab69-4378-9a9c-2c455faf1a91 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-20 15:11:02,218][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-20 15:11:02,219][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-20 15:11:02,219][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-20 15:11:02,483][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-20 15:11:02,515][ceph22][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-20 15:11:02,515][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-20 15:11:03,280][ceph22][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-20 15:11:03,281][ceph22][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-20 15:11:03,281][ceph22][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-20 15:11:03,281][ceph22][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-20 15:11:03,281][ceph22][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-20 15:11:03,281][ceph22][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-20 15:11:03,281][ceph22][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-20 15:11:03,282][ceph22][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-20 15:11:03,282][ceph22][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.GN6CBI with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-20 15:11:03,282][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.GN6CBI
[2016-07-20 15:11:03,282][ceph22][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.GN6CBI
[2016-07-20 15:11:03,282][ceph22][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.GN6CBI/journal -> /dev/disk/by-partuuid/abd80256-b7bd-49de-b6f4-50ad37f28fdd
[2016-07-20 15:11:03,290][ceph22][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.GN6CBI
[2016-07-20 15:11:03,290][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.GN6CBI
[2016-07-20 15:11:03,322][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-20 15:11:04,338][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-20 15:11:04,338][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-20 15:11:04,338][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-20 15:11:10,459][ceph22][INFO  ] checking OSD status...
[2016-07-20 15:11:10,460][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:11:10,463][ceph22][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-20 15:11:10,628][ceph_deploy.osd][DEBUG ] Host ceph22 is now ready for osd use.
[2016-07-20 15:11:11,290][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-20 15:11:11,291][ceph22][DEBUG ] detect platform information from remote host
[2016-07-20 15:11:11,308][ceph22][DEBUG ] detect machine type
[2016-07-20 15:11:11,312][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:11:11,314][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:11:11,323][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:11:11,324][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-20 15:11:11,325][ceph_deploy.osd][DEBUG ] Preparing host ceph22 disk /dev/vdc journal None activate True
[2016-07-20 15:11:11,325][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:11:11,327][ceph22][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-20 15:11:11,394][ceph22][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-20 15:11:11,394][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-20 15:11:11,394][ceph22][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-20 15:11:11,395][ceph22][WARNING] backup header from main header.
[2016-07-20 15:11:11,395][ceph22][WARNING] 
[2016-07-20 15:11:11,395][ceph22][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-20 15:11:11,395][ceph22][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-20 15:11:11,395][ceph22][WARNING] 
[2016-07-20 15:11:11,395][ceph22][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-20 15:11:11,396][ceph22][WARNING] 
[2016-07-20 15:11:12,462][ceph22][DEBUG ] ****************************************************************************
[2016-07-20 15:11:12,462][ceph22][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-20 15:11:12,462][ceph22][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-20 15:11:12,463][ceph22][DEBUG ] ****************************************************************************
[2016-07-20 15:11:12,463][ceph22][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-20 15:11:12,463][ceph22][DEBUG ] other utilities.
[2016-07-20 15:11:12,463][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-20 15:11:13,479][ceph22][DEBUG ] Creating new GPT entries.
[2016-07-20 15:11:13,480][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-20 15:11:13,480][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-20 15:11:13,480][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-20 15:11:13,480][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-20 15:11:13,480][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-20 15:11:13,481][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-20 15:11:13,488][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-20 15:11:13,503][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-20 15:11:13,519][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-20 15:11:13,535][ceph22][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-20 15:11:13,542][ceph22][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-20 15:11:13,542][ceph22][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-20 15:11:13,543][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:8aa18d15-79c7-4d98-9d48-b0186a33f963 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-20 15:11:14,609][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-20 15:11:14,609][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-20 15:11:14,609][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-20 15:11:14,773][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-20 15:11:14,774][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/8aa18d15-79c7-4d98-9d48-b0186a33f963
[2016-07-20 15:11:14,774][ceph22][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/8aa18d15-79c7-4d98-9d48-b0186a33f963
[2016-07-20 15:11:14,774][ceph22][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-20 15:11:14,774][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:4d2166e2-8dc8-4789-98b8-d97cb2913187 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-20 15:11:15,790][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-20 15:11:15,790][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-20 15:11:15,790][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-20 15:11:16,055][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-20 15:11:16,118][ceph22][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-20 15:11:16,119][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-20 15:11:16,934][ceph22][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-20 15:11:16,935][ceph22][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-20 15:11:16,935][ceph22][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-20 15:11:16,935][ceph22][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-20 15:11:16,935][ceph22][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-20 15:11:16,935][ceph22][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-20 15:11:16,935][ceph22][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-20 15:11:16,936][ceph22][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-20 15:11:16,936][ceph22][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt.56_3_H with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-20 15:11:16,936][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt.56_3_H
[2016-07-20 15:11:16,936][ceph22][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.56_3_H
[2016-07-20 15:11:16,936][ceph22][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.56_3_H/journal -> /dev/disk/by-partuuid/8aa18d15-79c7-4d98-9d48-b0186a33f963
[2016-07-20 15:11:16,943][ceph22][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.56_3_H
[2016-07-20 15:11:16,944][ceph22][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.56_3_H
[2016-07-20 15:11:16,975][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-20 15:11:18,041][ceph22][DEBUG ] The operation has completed successfully.
[2016-07-20 15:11:18,042][ceph22][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-20 15:11:18,042][ceph22][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-20 15:11:24,314][ceph22][INFO  ] checking OSD status...
[2016-07-20 15:11:24,314][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:11:24,317][ceph22][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-20 15:11:24,532][ceph_deploy.osd][DEBUG ] Host ceph22 is now ready for osd use.
[2016-07-20 15:11:25,194][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-20 15:11:25,195][ceph23][DEBUG ] detect platform information from remote host
[2016-07-20 15:11:25,211][ceph23][DEBUG ] detect machine type
[2016-07-20 15:11:25,214][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:11:25,216][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:11:25,224][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:11:25,225][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-20 15:11:25,225][ceph_deploy.osd][DEBUG ] Deploying osd to ceph23
[2016-07-20 15:11:25,226][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:11:25,228][ceph_deploy.osd][DEBUG ] Preparing host ceph23 disk /dev/vdb journal None activate True
[2016-07-20 15:11:25,228][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:11:25,229][ceph23][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdb
[2016-07-20 15:11:25,296][ceph23][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdb
[2016-07-20 15:11:25,296][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdb
[2016-07-20 15:11:25,296][ceph23][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-20 15:11:25,297][ceph23][WARNING] backup header from main header.
[2016-07-20 15:11:25,297][ceph23][WARNING] 
[2016-07-20 15:11:25,297][ceph23][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-20 15:11:25,297][ceph23][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-20 15:11:25,297][ceph23][WARNING] 
[2016-07-20 15:11:25,297][ceph23][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-20 15:11:25,297][ceph23][WARNING] 
[2016-07-20 15:11:26,363][ceph23][DEBUG ] ****************************************************************************
[2016-07-20 15:11:26,364][ceph23][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-20 15:11:26,364][ceph23][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-20 15:11:26,364][ceph23][DEBUG ] ****************************************************************************
[2016-07-20 15:11:26,365][ceph23][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-20 15:11:26,365][ceph23][DEBUG ] other utilities.
[2016-07-20 15:11:26,365][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdb
[2016-07-20 15:11:27,381][ceph23][DEBUG ] Creating new GPT entries.
[2016-07-20 15:11:27,381][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-20 15:11:27,382][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdb
[2016-07-20 15:11:27,382][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-20 15:11:27,382][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-20 15:11:27,382][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-20 15:11:27,383][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-20 15:11:27,398][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-20 15:11:27,414][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-20 15:11:27,430][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-20 15:11:27,446][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-20 15:11:27,462][ceph23][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdb
[2016-07-20 15:11:27,463][ceph23][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdb
[2016-07-20 15:11:27,463][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:0a2a1b9c-2f96-4e23-91c6-f4c12d92b53e --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdb
[2016-07-20 15:11:28,529][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-20 15:11:28,530][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-20 15:11:28,530][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-20 15:11:28,694][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-20 15:11:28,694][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/0a2a1b9c-2f96-4e23-91c6-f4c12d92b53e
[2016-07-20 15:11:28,694][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/0a2a1b9c-2f96-4e23-91c6-f4c12d92b53e
[2016-07-20 15:11:28,695][ceph23][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdb
[2016-07-20 15:11:28,695][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:4ae19641-e351-4149-a0b0-018688caa69f --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdb
[2016-07-20 15:11:29,762][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-20 15:11:29,762][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdb
[2016-07-20 15:11:29,762][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-20 15:11:30,027][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-20 15:11:30,027][ceph23][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdb1
[2016-07-20 15:11:30,027][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdb1
[2016-07-20 15:11:30,793][ceph23][DEBUG ] meta-data=/dev/vdb1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-20 15:11:30,793][ceph23][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-20 15:11:30,794][ceph23][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-20 15:11:30,794][ceph23][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-20 15:11:30,794][ceph23][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-20 15:11:30,794][ceph23][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-20 15:11:30,794][ceph23][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-20 15:11:30,794][ceph23][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-20 15:11:30,795][ceph23][WARNING] DEBUG:ceph-disk:Mounting /dev/vdb1 on /var/lib/ceph/tmp/mnt.AJqMRT with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-20 15:11:30,795][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdb1 /var/lib/ceph/tmp/mnt.AJqMRT
[2016-07-20 15:11:30,795][ceph23][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.AJqMRT
[2016-07-20 15:11:30,795][ceph23][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.AJqMRT/journal -> /dev/disk/by-partuuid/0a2a1b9c-2f96-4e23-91c6-f4c12d92b53e
[2016-07-20 15:11:30,811][ceph23][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.AJqMRT
[2016-07-20 15:11:30,811][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.AJqMRT
[2016-07-20 15:11:30,842][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdb
[2016-07-20 15:11:31,909][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-20 15:11:31,909][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdb
[2016-07-20 15:11:31,909][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdb
[2016-07-20 15:11:38,683][ceph23][INFO  ] checking OSD status...
[2016-07-20 15:11:38,683][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:11:38,686][ceph23][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-20 15:11:38,902][ceph_deploy.osd][DEBUG ] Host ceph23 is now ready for osd use.
[2016-07-20 15:11:39,599][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-20 15:11:39,600][ceph23][DEBUG ] detect platform information from remote host
[2016-07-20 15:11:39,617][ceph23][DEBUG ] detect machine type
[2016-07-20 15:11:39,621][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:11:39,623][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:11:39,632][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:11:39,633][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-20 15:11:39,633][ceph_deploy.osd][DEBUG ] Preparing host ceph23 disk /dev/vdc journal None activate True
[2016-07-20 15:11:39,633][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:11:39,635][ceph23][INFO  ] Running command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /dev/vdc
[2016-07-20 15:11:39,702][ceph23][WARNING] DEBUG:ceph-disk:Zapping partition table on /dev/vdc
[2016-07-20 15:11:39,702][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --zap-all -- /dev/vdc
[2016-07-20 15:11:39,702][ceph23][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2016-07-20 15:11:39,703][ceph23][WARNING] backup header from main header.
[2016-07-20 15:11:39,703][ceph23][WARNING] 
[2016-07-20 15:11:39,703][ceph23][WARNING] Warning! Main and backup partition tables differ! Use the 'c' and 'e' options
[2016-07-20 15:11:39,703][ceph23][WARNING] on the recovery & transformation menu to examine the two tables.
[2016-07-20 15:11:39,704][ceph23][WARNING] 
[2016-07-20 15:11:39,704][ceph23][WARNING] Warning! One or more CRCs don't match. You should repair the disk!
[2016-07-20 15:11:39,704][ceph23][WARNING] 
[2016-07-20 15:11:40,770][ceph23][DEBUG ] ****************************************************************************
[2016-07-20 15:11:40,771][ceph23][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2016-07-20 15:11:40,771][ceph23][DEBUG ] verification and recovery are STRONGLY recommended.
[2016-07-20 15:11:40,771][ceph23][DEBUG ] ****************************************************************************
[2016-07-20 15:11:40,771][ceph23][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2016-07-20 15:11:40,771][ceph23][DEBUG ] other utilities.
[2016-07-20 15:11:40,771][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/vdc
[2016-07-20 15:11:41,787][ceph23][DEBUG ] Creating new GPT entries.
[2016-07-20 15:11:41,787][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-20 15:11:41,788][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on zapped device /dev/vdc
[2016-07-20 15:11:41,788][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-20 15:11:41,788][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2016-07-20 15:11:41,788][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2016-07-20 15:11:41,788][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2016-07-20 15:11:41,804][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2016-07-20 15:11:41,819][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_cryptsetup_parameters
[2016-07-20 15:11:41,835][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_key_size
[2016-07-20 15:11:41,843][ceph23][WARNING] INFO:ceph-disk:Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_dmcrypt_type
[2016-07-20 15:11:41,858][ceph23][WARNING] INFO:ceph-disk:Will colocate journal with data on /dev/vdc
[2016-07-20 15:11:41,858][ceph23][WARNING] DEBUG:ceph-disk:Creating journal partition num 2 size 5120 on /dev/vdc
[2016-07-20 15:11:41,858][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --new=2:0:5120M --change-name=2:ceph journal --partition-guid=2:49aff5a7-e366-455d-8e51-977b4d670967 --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/vdc
[2016-07-20 15:11:42,874][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-20 15:11:42,875][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-20 15:11:42,875][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-20 15:11:43,039][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-20 15:11:43,103][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/49aff5a7-e366-455d-8e51-977b4d670967
[2016-07-20 15:11:43,103][ceph23][WARNING] DEBUG:ceph-disk:Journal is GPT partition /dev/disk/by-partuuid/49aff5a7-e366-455d-8e51-977b4d670967
[2016-07-20 15:11:43,103][ceph23][WARNING] DEBUG:ceph-disk:Creating osd partition on /dev/vdc
[2016-07-20 15:11:43,103][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --largest-new=1 --change-name=1:ceph data --partition-guid=1:42814ddb-3bb1-4182-a996-d9f74802842d --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/vdc
[2016-07-20 15:11:44,119][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-20 15:11:44,120][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on created device /dev/vdc
[2016-07-20 15:11:44,120][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-20 15:11:44,384][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/udevadm settle
[2016-07-20 15:11:44,416][ceph23][WARNING] DEBUG:ceph-disk:Creating xfs fs on /dev/vdc1
[2016-07-20 15:11:44,416][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/mkfs -t xfs -f -i size=2048 -f -- /dev/vdc1
[2016-07-20 15:11:45,232][ceph23][DEBUG ] meta-data=/dev/vdc1              isize=2048   agcount=4, agsize=6225855 blks
[2016-07-20 15:11:45,232][ceph23][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=0
[2016-07-20 15:11:45,232][ceph23][DEBUG ] data     =                       bsize=4096   blocks=24903419, imaxpct=25
[2016-07-20 15:11:45,232][ceph23][DEBUG ]          =                       sunit=0      swidth=0 blks
[2016-07-20 15:11:45,232][ceph23][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0
[2016-07-20 15:11:45,232][ceph23][DEBUG ] log      =internal log           bsize=4096   blocks=12159, version=2
[2016-07-20 15:11:45,232][ceph23][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2016-07-20 15:11:45,232][ceph23][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2016-07-20 15:11:45,233][ceph23][WARNING] DEBUG:ceph-disk:Mounting /dev/vdc1 on /var/lib/ceph/tmp/mnt.6JJcIQ with options rw,noatime,inode64,logbsize=256k,delaylog
[2016-07-20 15:11:45,233][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/mount -t xfs -o rw,noatime,inode64,logbsize=256k,delaylog -- /dev/vdc1 /var/lib/ceph/tmp/mnt.6JJcIQ
[2016-07-20 15:11:45,233][ceph23][WARNING] DEBUG:ceph-disk:Preparing osd data dir /var/lib/ceph/tmp/mnt.6JJcIQ
[2016-07-20 15:11:45,233][ceph23][WARNING] DEBUG:ceph-disk:Creating symlink /var/lib/ceph/tmp/mnt.6JJcIQ/journal -> /dev/disk/by-partuuid/49aff5a7-e366-455d-8e51-977b4d670967
[2016-07-20 15:11:45,233][ceph23][WARNING] DEBUG:ceph-disk:Unmounting /var/lib/ceph/tmp/mnt.6JJcIQ
[2016-07-20 15:11:45,233][ceph23][WARNING] INFO:ceph-disk:Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.6JJcIQ
[2016-07-20 15:11:45,249][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/vdc
[2016-07-20 15:11:46,315][ceph23][DEBUG ] The operation has completed successfully.
[2016-07-20 15:11:46,315][ceph23][WARNING] DEBUG:ceph-disk:Calling partprobe on prepared device /dev/vdc
[2016-07-20 15:11:46,316][ceph23][WARNING] INFO:ceph-disk:Running command: /sbin/partprobe /dev/vdc
[2016-07-20 15:11:52,536][ceph23][INFO  ] checking OSD status...
[2016-07-20 15:11:52,536][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:11:52,541][ceph23][INFO  ] Running command: /usr/bin/ceph --cluster=ceph osd stat --format=json
[2016-07-20 15:11:52,756][ceph_deploy.osd][DEBUG ] Host ceph23 is now ready for osd use.
[2016-07-20 15:11:52,861][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:11:52,862][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf admin ceph21 ceph22 ceph23
[2016-07-20 15:11:52,862][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:11:52,862][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:11:52,862][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:11:52,862][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-20 15:11:52,862][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:11:52,862][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f843799a5a8>
[2016-07-20 15:11:52,863][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:11:52,863][ceph_deploy.cli][INFO  ]  client                        : ['ceph21', 'ceph22', 'ceph23']
[2016-07-20 15:11:52,863][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f84382bc7d0>
[2016-07-20 15:11:52,863][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:11:52,863][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:11:52,864][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph21
[2016-07-20 15:11:53,581][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 15:11:53,583][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 15:11:53,599][ceph21][DEBUG ] detect machine type
[2016-07-20 15:11:53,603][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:11:53,606][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:11:53,625][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:11:53,628][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph22
[2016-07-20 15:11:54,303][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-20 15:11:54,304][ceph22][DEBUG ] detect platform information from remote host
[2016-07-20 15:11:54,319][ceph22][DEBUG ] detect machine type
[2016-07-20 15:11:54,323][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:11:54,326][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:11:54,335][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:11:54,338][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph23
[2016-07-20 15:11:55,038][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-20 15:11:55,038][ceph23][DEBUG ] detect platform information from remote host
[2016-07-20 15:11:55,056][ceph23][DEBUG ] detect machine type
[2016-07-20 15:11:55,060][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:11:55,062][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:11:55,079][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:11:55,180][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:11:55,181][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf config push ceph21 ceph22 ceph23
[2016-07-20 15:11:55,181][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:11:55,181][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:11:55,181][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:11:55,181][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-20 15:11:55,182][ceph_deploy.cli][INFO  ]  subcommand                    : push
[2016-07-20 15:11:55,182][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:11:55,182][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7e74da9518>
[2016-07-20 15:11:55,182][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:11:55,182][ceph_deploy.cli][INFO  ]  client                        : ['ceph21', 'ceph22', 'ceph23']
[2016-07-20 15:11:55,182][ceph_deploy.cli][INFO  ]  func                          : <function config at 0x7f7e74df2938>
[2016-07-20 15:11:55,182][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:11:55,182][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:11:55,183][ceph_deploy.config][DEBUG ] Pushing config to ceph21
[2016-07-20 15:11:55,895][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 15:11:55,898][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 15:11:55,915][ceph21][DEBUG ] detect machine type
[2016-07-20 15:11:55,919][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:11:55,922][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:11:55,941][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:11:55,944][ceph_deploy.config][DEBUG ] Pushing config to ceph22
[2016-07-20 15:11:56,636][ceph22][DEBUG ] connected to host: ceph22 
[2016-07-20 15:11:56,637][ceph22][DEBUG ] detect platform information from remote host
[2016-07-20 15:11:56,653][ceph22][DEBUG ] detect machine type
[2016-07-20 15:11:56,657][ceph22][DEBUG ] find the location of an executable
[2016-07-20 15:11:56,660][ceph22][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:11:56,669][ceph22][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:11:56,671][ceph_deploy.config][DEBUG ] Pushing config to ceph23
[2016-07-20 15:11:57,373][ceph23][DEBUG ] connected to host: ceph23 
[2016-07-20 15:11:57,374][ceph23][DEBUG ] detect platform information from remote host
[2016-07-20 15:11:57,393][ceph23][DEBUG ] detect machine type
[2016-07-20 15:11:57,397][ceph23][DEBUG ] find the location of an executable
[2016-07-20 15:11:57,400][ceph23][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:11:57,417][ceph23][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:17:09,811][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:17:09,811][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf rgw create ceph21
[2016-07-20 15:17:09,811][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:17:09,811][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:17:09,811][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:17:09,811][ceph_deploy.cli][INFO  ]  rgw                           : [('ceph21', 'rgw.ceph21')]
[2016-07-20 15:17:09,811][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-20 15:17:09,811][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2016-07-20 15:17:09,812][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:17:09,812][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbc67125680>
[2016-07-20 15:17:09,812][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:17:09,812][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7fbc679ec6e0>
[2016-07-20 15:17:09,812][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:17:09,812][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:17:09,813][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts ceph21:rgw.ceph21
[2016-07-20 15:17:10,605][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 15:17:10,606][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 15:17:10,624][ceph21][DEBUG ] detect machine type
[2016-07-20 15:17:10,628][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:17:10,631][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:17:10,650][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 14.04 trusty
[2016-07-20 15:17:10,650][ceph_deploy.rgw][DEBUG ] remote host will use upstart
[2016-07-20 15:17:10,650][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to ceph21
[2016-07-20 15:17:10,651][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2016-07-20 15:17:10,654][ceph21][DEBUG ] create path recursively if it doesn't exist
[2016-07-20 15:17:10,657][ceph21][INFO  ] Running command: ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.ceph21 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.ceph21/keyring
[2016-07-20 15:17:11,577][ceph21][INFO  ] Running command: initctl emit radosgw cluster=ceph id=rgw.ceph21
[2016-07-20 15:17:11,597][ceph_deploy.rgw][INFO  ] The Ceph Object Gateway (RGW) is now running on host ceph21 and default port 7480
[2016-07-20 15:19:16,570][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf
[2016-07-20 15:19:16,571][ceph_deploy.cli][INFO  ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf config push ceph21
[2016-07-20 15:19:16,571][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2016-07-20 15:19:16,571][ceph_deploy.cli][INFO  ]  username                      : None
[2016-07-20 15:19:16,571][ceph_deploy.cli][INFO  ]  verbose                       : False
[2016-07-20 15:19:16,571][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2016-07-20 15:19:16,571][ceph_deploy.cli][INFO  ]  subcommand                    : push
[2016-07-20 15:19:16,571][ceph_deploy.cli][INFO  ]  quiet                         : False
[2016-07-20 15:19:16,572][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb8fe763518>
[2016-07-20 15:19:16,572][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2016-07-20 15:19:16,572][ceph_deploy.cli][INFO  ]  client                        : ['ceph21']
[2016-07-20 15:19:16,572][ceph_deploy.cli][INFO  ]  func                          : <function config at 0x7fb8fe7ac938>
[2016-07-20 15:19:16,572][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2016-07-20 15:19:16,572][ceph_deploy.cli][INFO  ]  default_release               : False
[2016-07-20 15:19:16,572][ceph_deploy.config][DEBUG ] Pushing config to ceph21
[2016-07-20 15:19:17,296][ceph21][DEBUG ] connected to host: ceph21 
[2016-07-20 15:19:17,297][ceph21][DEBUG ] detect platform information from remote host
[2016-07-20 15:19:17,315][ceph21][DEBUG ] detect machine type
[2016-07-20 15:19:17,319][ceph21][DEBUG ] find the location of an executable
[2016-07-20 15:19:17,321][ceph21][INFO  ] Running command: /sbin/initctl version
[2016-07-20 15:19:17,341][ceph21][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
